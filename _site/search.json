[
  {
    "objectID": "univariate-ts-models.html",
    "href": "univariate-ts-models.html",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "",
    "text": "We load daily data for Bitcoin, S&P 500, NASDAQ, VIX, and the USD Index from FRED and merge the valid series into a single cleaned dataset. Returns are computed using first-differenced log prices.\n\nData PreparationHelper Functions\n\n\n\n\nCode\nlibrary(quantmod)\nlibrary(tidyverse)\nlibrary(zoo)\nlibrary(forecast)\nlibrary(tseries)\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\nload_fred_data &lt;- function(symbol) {\n  tryCatch(\n    getSymbols(symbol, src = \"FRED\", from = start_date, to = end_date,\n               auto.assign = FALSE),\n    error = function(e) { cat(\"FAILED:\", symbol, \"\\n\"); NULL }\n  )\n}\n\nsp500_data  &lt;- load_fred_data(\"SP500\")\nvix_data    &lt;- load_fred_data(\"VIXCLS\")\nbtc_data    &lt;- load_fred_data(\"CBBTCUSD\")\nnasdaq_data &lt;- load_fred_data(\"NASDAQCOM\")\nusd_data    &lt;- load_fred_data(\"DTWEXBGS\")\n\nmerge_list &lt;- list(\n  SP500   = sp500_data,\n  VIX     = vix_data,\n  Bitcoin = btc_data,\n  NASDAQ  = nasdaq_data,\n  USD     = usd_data\n)\nmerge_list &lt;- merge_list[!sapply(merge_list, is.null)]\n\nprice_zoo  &lt;- do.call(merge.zoo, merge_list)\nprice_data &lt;- fortify.zoo(price_zoo)\ncolnames(price_data) &lt;- c(\"Date\", names(merge_list))\nprice_data &lt;- price_data |&gt; na.omit()\n\nget_series &lt;- function(asset) price_data[[asset]]\nget_diff_series &lt;- function(asset) diff(log(price_data[[asset]])) |&gt; na.omit()\n\n\n\n\ncat(\n  \"\\n=== DATASET SUMMARY ===\\n\",\n  \"Observations : \", nrow(price_data), \"\\n\",\n  \"Assets Loaded: \", length(merge_list), \"\\n\",\n  \"Date Range   : \", min(price_data$Date), \" to \", max(price_data$Date), \"\\n\"\n)\n\n\n\n=== DATASET SUMMARY ===\n Observations :  1668 \n Assets Loaded:  5 \n Date Range   :  17898  to  20349 \n\n\n\n\nCode\nassets &lt;- names(merge_list)\n\narima_models &lt;- list()\nsarima_models &lt;- list()\n\nfor (a in assets) {\nseries &lt;- get_diff_series(a)\n\narima_models[[a]] &lt;- auto.arima(series, stepwise=TRUE, approximation=TRUE)\n\nsarima_models[[a]] &lt;- auto.arima(series, seasonal=TRUE,\nstepwise=TRUE, approximation=TRUE)\n}\n\n\nFor modeling, each asset is fit with an ARIMA/SARIMA model using auto.arima() for efficient order selection. Models are stored once and reused throughout the page for diagnostics, ACF/PACF inspection, forecasting, and benchmark comparisons.\n\n\n\n\nCode\nplot_original_and_diff &lt;- function(asset) {\n  \n  # Extract series\n  original &lt;- price_data[[asset]]\n  dates    &lt;- price_data$Date\n  diff_ser &lt;- get_diff_series(asset)\n  \n  # Layout\n  par(mfrow = c(2, 1), mar = c(4, 4, 3, 1))\n  \n  # --- Original price plot ---\n  plot(dates, original, type = \"l\", col = \"steelblue\",\n       main = paste(asset, \"- Original Series\"),\n       xlab = \"Date\", ylab = \"Price Level\")\n  \n  # --- First difference plot (log returns) ---\n  plot(diff_ser, type = \"l\", col = \"red\",\n       main = paste(asset, \"- Log Returns (First Difference)\"),\n       xlab = \"Index\", ylab = \"Log Return\")\n  \n  # Reset layout\n  par(mfrow = c(1, 1))\n}\n\n\nrun_stationarity &lt;- function(asset) {\nprint(adf.test(get_diff_series(asset)))\n}\n\nplot_acf_pacf &lt;- function(asset) {\nseries &lt;- get_diff_series(asset)\npar(mfrow=c(1,2))\nacf(series, main=paste(asset,\"ACF\"))\npacf(series, main=paste(asset,\"PACF\"))\npar(mfrow=c(1,1))\n}\n\nrun_arima_models &lt;- function(asset) {\nprint(arima_models[[asset]])\n}\n\nrun_arima_diagnostics &lt;- function(asset) {\ntsdiag(arima_models[[asset]])\n}\n\nforecast_arima_asset &lt;- function(asset) {\nplot(forecast(arima_models[[asset]], h=30),\nmain=paste(asset,\"ARIMA Forecast\"))\n}\n\ncompare_benchmarks &lt;- function(asset) {\n\n  s &lt;- get_diff_series(asset)\n\n  f_naive  &lt;- naive(s, h = 30)\n  f_snaive &lt;- snaive(s, h = 30)\n  f_arima  &lt;- forecast(arima_models[[asset]], h = 30)\n\n  results &lt;- tibble(\n    Model = c(\"Naive\", \"Seasonal Naive\", \"ARIMA\"),\n    RMSE  = c(accuracy(f_naive)[,\"RMSE\"],\n              accuracy(f_snaive)[,\"RMSE\"],\n              accuracy(f_arima)[,\"RMSE\"]),\n    MAE   = c(accuracy(f_naive)[,\"MAE\"],\n              accuracy(f_snaive)[,\"MAE\"],\n              accuracy(f_arima)[,\"MAE\"]),\n    MAPE  = c(accuracy(f_naive)[,\"MAPE\"],\n              accuracy(f_snaive)[,\"MAPE\"],\n              accuracy(f_arima)[,\"MAPE\"])\n  )\n\n  print(results)\n\n  # --------------------------------------------------------------\n  # FIX: Extract safely and guarantee numeric, not NA, not ts\n  # --------------------------------------------------------------\n  arima_rmse &lt;- suppressWarnings(as.numeric(results$RMSE[results$Model == \"ARIMA\"]))\n  best_bench &lt;- suppressWarnings(as.numeric(min(results$RMSE[results$Model != \"ARIMA\"], na.rm = TRUE)))\n\n  # If still NA, replace with Inf so comparison will work\n  if (is.na(arima_rmse)) arima_rmse &lt;- Inf\n  if (is.na(best_bench)) best_bench &lt;- Inf\n\n  pct_diff &lt;- 100 * (best_bench - arima_rmse) / best_bench\n\n  # --------------------------------------------------------------\n  # Interpretation\n  # --------------------------------------------------------------\n  cat(\"\\nInterpretation for\", asset, \"\\n\")\n\n  if (isTRUE(arima_rmse &lt; best_bench)) {\n\n    cat(\n      \"ARIMA outperforms the benchmark models.\\n\",\n      \"It improves RMSE by\", round(pct_diff, 2), \"% relative to the best naive model.\\n\"\n    )\n\n  } else if (isTRUE(arima_rmse &gt; best_bench)) {\n\n    cat(\n      \"ARIMA does NOT beat the benchmarks.\\n\",\n      \"It performs\", round(-pct_diff, 2), \"% worse than the best naive model.\\n\"\n    )\n\n  } else {\n\n    cat(\"ARIMA performs similarly to the naive benchmarks.\\n\")\n\n  }\n\n  invisible(results)\n}\n\n\n\nrun_sarima_models &lt;- function(asset) {\nprint(sarima_models[[asset]])\n}\n\nforecast_sarima_asset &lt;- function(asset) {\nplot(forecast(sarima_models[[asset]], h=30),\nmain=paste(asset,\"SARIMA Forecast\"))\n}\n\nseasonality_analysis &lt;- function(asset) {\ns &lt;- ts(get_diff_series(asset), frequency=365)\nplot(stl(s, \"periodic\"), main=paste(asset,\"Seasonality\"))\n}\n\n# FAST CV — no repeated auto.arima calls\n\ncross_validate_sarima &lt;- function(asset) {\nseries &lt;- ts(get_diff_series(asset))\nmodel &lt;- sarima_models[[asset]]\nffun &lt;- function(y, h) forecast(model, h=h)\ne &lt;- tsCV(series, ffun, h=1)\nmean(e^2, na.rm=TRUE)\n}\n\n\nWhat These Helper Functions Do\nThe following helper functions streamline the ARIMA/SARIMA workflow by wrapping common analysis steps into reusable tools:\n\nplot_original_and_diff()\nPlots the raw price series and its first-differenced log returns to visualize stationarity and volatility changes.\nrun_stationarity()\nRuns the Augmented Dickey–Fuller (ADF) test on the differenced series to confirm stationarity before modeling.\nplot_acf_pacf()\nProduces ACF and PACF plots of the return series, helping identify potential ARIMA orders.\nrun_arima_models()\nPrints the fitted ARIMA model for a selected asset.\nrun_arima_diagnostics()\nDisplays residual diagnostics for the ARIMA model (autocorrelation, Ljung–Box tests).\nforecast_arima_asset()\nGenerates a 30-day ARIMA forecast with confidence intervals.\ncompare_benchmarks()\nCompares ARIMA forecasts to simple alternatives: Naive and Seasonal Naive models.\nrun_sarima_models()\nPrints the asset’s fitted SARIMA model (seasonal version).\nforecast_sarima_asset()\nProduces a 30-day SARIMA forecast for comparison with ARIMA.\nseasonality_analysis()\nPerforms STL decomposition to examine seasonal effects in the differenced series.\ncross_validate_sarima()\nPerforms fast one-step-ahead cross-validation using a fixed SARIMA model (no repeated auto.arima calls).\n\nTogether, these utilities enable fast inspection, diagnostics, and forecasting for all assets without rewriting code for each analysis."
  },
  {
    "objectID": "univariate-ts-models.html#model-setup",
    "href": "univariate-ts-models.html#model-setup",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "",
    "text": "We load daily data for Bitcoin, S&P 500, NASDAQ, VIX, and the USD Index from FRED and merge the valid series into a single cleaned dataset. Returns are computed using first-differenced log prices.\n\nData PreparationHelper Functions\n\n\n\n\nCode\nlibrary(quantmod)\nlibrary(tidyverse)\nlibrary(zoo)\nlibrary(forecast)\nlibrary(tseries)\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\nload_fred_data &lt;- function(symbol) {\n  tryCatch(\n    getSymbols(symbol, src = \"FRED\", from = start_date, to = end_date,\n               auto.assign = FALSE),\n    error = function(e) { cat(\"FAILED:\", symbol, \"\\n\"); NULL }\n  )\n}\n\nsp500_data  &lt;- load_fred_data(\"SP500\")\nvix_data    &lt;- load_fred_data(\"VIXCLS\")\nbtc_data    &lt;- load_fred_data(\"CBBTCUSD\")\nnasdaq_data &lt;- load_fred_data(\"NASDAQCOM\")\nusd_data    &lt;- load_fred_data(\"DTWEXBGS\")\n\nmerge_list &lt;- list(\n  SP500   = sp500_data,\n  VIX     = vix_data,\n  Bitcoin = btc_data,\n  NASDAQ  = nasdaq_data,\n  USD     = usd_data\n)\nmerge_list &lt;- merge_list[!sapply(merge_list, is.null)]\n\nprice_zoo  &lt;- do.call(merge.zoo, merge_list)\nprice_data &lt;- fortify.zoo(price_zoo)\ncolnames(price_data) &lt;- c(\"Date\", names(merge_list))\nprice_data &lt;- price_data |&gt; na.omit()\n\nget_series &lt;- function(asset) price_data[[asset]]\nget_diff_series &lt;- function(asset) diff(log(price_data[[asset]])) |&gt; na.omit()\n\n\n\n\ncat(\n  \"\\n=== DATASET SUMMARY ===\\n\",\n  \"Observations : \", nrow(price_data), \"\\n\",\n  \"Assets Loaded: \", length(merge_list), \"\\n\",\n  \"Date Range   : \", min(price_data$Date), \" to \", max(price_data$Date), \"\\n\"\n)\n\n\n\n=== DATASET SUMMARY ===\n Observations :  1668 \n Assets Loaded:  5 \n Date Range   :  17898  to  20349 \n\n\n\n\nCode\nassets &lt;- names(merge_list)\n\narima_models &lt;- list()\nsarima_models &lt;- list()\n\nfor (a in assets) {\nseries &lt;- get_diff_series(a)\n\narima_models[[a]] &lt;- auto.arima(series, stepwise=TRUE, approximation=TRUE)\n\nsarima_models[[a]] &lt;- auto.arima(series, seasonal=TRUE,\nstepwise=TRUE, approximation=TRUE)\n}\n\n\nFor modeling, each asset is fit with an ARIMA/SARIMA model using auto.arima() for efficient order selection. Models are stored once and reused throughout the page for diagnostics, ACF/PACF inspection, forecasting, and benchmark comparisons.\n\n\n\n\nCode\nplot_original_and_diff &lt;- function(asset) {\n  \n  # Extract series\n  original &lt;- price_data[[asset]]\n  dates    &lt;- price_data$Date\n  diff_ser &lt;- get_diff_series(asset)\n  \n  # Layout\n  par(mfrow = c(2, 1), mar = c(4, 4, 3, 1))\n  \n  # --- Original price plot ---\n  plot(dates, original, type = \"l\", col = \"steelblue\",\n       main = paste(asset, \"- Original Series\"),\n       xlab = \"Date\", ylab = \"Price Level\")\n  \n  # --- First difference plot (log returns) ---\n  plot(diff_ser, type = \"l\", col = \"red\",\n       main = paste(asset, \"- Log Returns (First Difference)\"),\n       xlab = \"Index\", ylab = \"Log Return\")\n  \n  # Reset layout\n  par(mfrow = c(1, 1))\n}\n\n\nrun_stationarity &lt;- function(asset) {\nprint(adf.test(get_diff_series(asset)))\n}\n\nplot_acf_pacf &lt;- function(asset) {\nseries &lt;- get_diff_series(asset)\npar(mfrow=c(1,2))\nacf(series, main=paste(asset,\"ACF\"))\npacf(series, main=paste(asset,\"PACF\"))\npar(mfrow=c(1,1))\n}\n\nrun_arima_models &lt;- function(asset) {\nprint(arima_models[[asset]])\n}\n\nrun_arima_diagnostics &lt;- function(asset) {\ntsdiag(arima_models[[asset]])\n}\n\nforecast_arima_asset &lt;- function(asset) {\nplot(forecast(arima_models[[asset]], h=30),\nmain=paste(asset,\"ARIMA Forecast\"))\n}\n\ncompare_benchmarks &lt;- function(asset) {\n\n  s &lt;- get_diff_series(asset)\n\n  f_naive  &lt;- naive(s, h = 30)\n  f_snaive &lt;- snaive(s, h = 30)\n  f_arima  &lt;- forecast(arima_models[[asset]], h = 30)\n\n  results &lt;- tibble(\n    Model = c(\"Naive\", \"Seasonal Naive\", \"ARIMA\"),\n    RMSE  = c(accuracy(f_naive)[,\"RMSE\"],\n              accuracy(f_snaive)[,\"RMSE\"],\n              accuracy(f_arima)[,\"RMSE\"]),\n    MAE   = c(accuracy(f_naive)[,\"MAE\"],\n              accuracy(f_snaive)[,\"MAE\"],\n              accuracy(f_arima)[,\"MAE\"]),\n    MAPE  = c(accuracy(f_naive)[,\"MAPE\"],\n              accuracy(f_snaive)[,\"MAPE\"],\n              accuracy(f_arima)[,\"MAPE\"])\n  )\n\n  print(results)\n\n  # --------------------------------------------------------------\n  # FIX: Extract safely and guarantee numeric, not NA, not ts\n  # --------------------------------------------------------------\n  arima_rmse &lt;- suppressWarnings(as.numeric(results$RMSE[results$Model == \"ARIMA\"]))\n  best_bench &lt;- suppressWarnings(as.numeric(min(results$RMSE[results$Model != \"ARIMA\"], na.rm = TRUE)))\n\n  # If still NA, replace with Inf so comparison will work\n  if (is.na(arima_rmse)) arima_rmse &lt;- Inf\n  if (is.na(best_bench)) best_bench &lt;- Inf\n\n  pct_diff &lt;- 100 * (best_bench - arima_rmse) / best_bench\n\n  # --------------------------------------------------------------\n  # Interpretation\n  # --------------------------------------------------------------\n  cat(\"\\nInterpretation for\", asset, \"\\n\")\n\n  if (isTRUE(arima_rmse &lt; best_bench)) {\n\n    cat(\n      \"ARIMA outperforms the benchmark models.\\n\",\n      \"It improves RMSE by\", round(pct_diff, 2), \"% relative to the best naive model.\\n\"\n    )\n\n  } else if (isTRUE(arima_rmse &gt; best_bench)) {\n\n    cat(\n      \"ARIMA does NOT beat the benchmarks.\\n\",\n      \"It performs\", round(-pct_diff, 2), \"% worse than the best naive model.\\n\"\n    )\n\n  } else {\n\n    cat(\"ARIMA performs similarly to the naive benchmarks.\\n\")\n\n  }\n\n  invisible(results)\n}\n\n\n\nrun_sarima_models &lt;- function(asset) {\nprint(sarima_models[[asset]])\n}\n\nforecast_sarima_asset &lt;- function(asset) {\nplot(forecast(sarima_models[[asset]], h=30),\nmain=paste(asset,\"SARIMA Forecast\"))\n}\n\nseasonality_analysis &lt;- function(asset) {\ns &lt;- ts(get_diff_series(asset), frequency=365)\nplot(stl(s, \"periodic\"), main=paste(asset,\"Seasonality\"))\n}\n\n# FAST CV — no repeated auto.arima calls\n\ncross_validate_sarima &lt;- function(asset) {\nseries &lt;- ts(get_diff_series(asset))\nmodel &lt;- sarima_models[[asset]]\nffun &lt;- function(y, h) forecast(model, h=h)\ne &lt;- tsCV(series, ffun, h=1)\nmean(e^2, na.rm=TRUE)\n}\n\n\nWhat These Helper Functions Do\nThe following helper functions streamline the ARIMA/SARIMA workflow by wrapping common analysis steps into reusable tools:\n\nplot_original_and_diff()\nPlots the raw price series and its first-differenced log returns to visualize stationarity and volatility changes.\nrun_stationarity()\nRuns the Augmented Dickey–Fuller (ADF) test on the differenced series to confirm stationarity before modeling.\nplot_acf_pacf()\nProduces ACF and PACF plots of the return series, helping identify potential ARIMA orders.\nrun_arima_models()\nPrints the fitted ARIMA model for a selected asset.\nrun_arima_diagnostics()\nDisplays residual diagnostics for the ARIMA model (autocorrelation, Ljung–Box tests).\nforecast_arima_asset()\nGenerates a 30-day ARIMA forecast with confidence intervals.\ncompare_benchmarks()\nCompares ARIMA forecasts to simple alternatives: Naive and Seasonal Naive models.\nrun_sarima_models()\nPrints the asset’s fitted SARIMA model (seasonal version).\nforecast_sarima_asset()\nProduces a 30-day SARIMA forecast for comparison with ARIMA.\nseasonality_analysis()\nPerforms STL decomposition to examine seasonal effects in the differenced series.\ncross_validate_sarima()\nPerforms fast one-step-ahead cross-validation using a fixed SARIMA model (no repeated auto.arima calls).\n\nTogether, these utilities enable fast inspection, diagnostics, and forecasting for all assets without rewriting code for each analysis."
  },
  {
    "objectID": "univariate-ts-models.html#univariate-time-series-analysis",
    "href": "univariate-ts-models.html#univariate-time-series-analysis",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Univariate Time Series Analysis",
    "text": "Univariate Time Series Analysis\n\nBitcoin\n\n1. Overview & Stationarity2. ARIMA3. SARIMA & Seasonality4. Benchmarks & Cross-Validation\n\n\n\n\nCode\nplot_original_and_diff(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\nCode\nrun_stationarity(\"Bitcoin\")\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  get_diff_series(asset)\nDickey-Fuller = -10.968, Lag order = 11, p-value = 0.01\nalternative hypothesis: stationary\n\n\nCode\nplot_acf_pacf(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\nBitcoin prices are non-stationary, but the log returns become stationary after differencing, with very little autocorrelation.\n\n\n\n\nCode\nrun_arima_models(\"Bitcoin\")\n\n\nSeries: series \nARIMA(0,0,2) with non-zero mean \n\nCoefficients:\n          ma1     ma2   mean\n      -0.0521  0.0456  0.002\ns.e.   0.0245  0.0247  0.001\n\nsigma^2 = 0.001662:  log likelihood = 2970.24\nAIC=-5932.48   AICc=-5932.46   BIC=-5910.81\n\n\nCode\nrun_arima_diagnostics(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\nCode\nforecast_arima_asset(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\nARIMA selects a simple MA(2)-type model, and diagnostics show clean, white-noise residuals with no remaining structure.\n\n\n\n\nCode\nrun_sarima_models(\"Bitcoin\")\n\n\nSeries: series \nARIMA(0,0,2) with non-zero mean \n\nCoefficients:\n          ma1     ma2   mean\n      -0.0521  0.0456  0.002\ns.e.   0.0245  0.0247  0.001\n\nsigma^2 = 0.001662:  log likelihood = 2970.24\nAIC=-5932.48   AICc=-5932.46   BIC=-5910.81\n\n\nCode\nforecast_sarima_asset(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\nCode\nseasonality_analysis(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\nSARIMA collapses to the same model because Bitcoin returns show no meaningful seasonality in the STL decomposition.\n\n\n\n\n# A tibble: 3 × 4\n  Model            RMSE    MAE  MAPE\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Naive          0.0592 0.0417  429.\n2 Seasonal Naive 0.0592 0.0417  429.\n3 ARIMA          0.0407 0.0270  120.\n\n--- Interpretation for Bitcoin ---\nARIMA outperforms the benchmark models.\n It improves RMSE by 31.25 % relative to the best naive model.\n\n\n\n\nCode\ncv_btc &lt;- cross_validate_sarima(\"Bitcoin\")\n\ncat(\n  \"SARIMA Cross-Validation (Bitcoin)\\n\",\n  \"RMSE:\", format(round(cv_btc, 6), nsmall = 6), \"\\n\"\n)\n\n\nSARIMA Cross-Validation (Bitcoin)\n RMSE: 0.001668 \n\n\nARIMA beats both naïve benchmarks with a 31% lower RMSE, and SARIMA cross-validation shows a very small error (≈0.0017), confirming minimal but detectable short-term predictability.\n\n\n\n\n\nS&P 500\n\n1. Overview & Stationarity2. ARIMA3. SARIMA & SeasonalityBenchmarks & Cross-Validation\n\n\n\n\nCode\nplot_original_and_diff(\"SP500\")\n\n\n\n\n\n\n\n\n\nCode\nrun_stationarity(\"SP500\")\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  get_diff_series(asset)\nDickey-Fuller = -11.102, Lag order = 11, p-value = 0.01\nalternative hypothesis: stationary\n\n\nCode\nplot_acf_pacf(\"SP500\")\n\n\n\n\n\n\n\n\n\nThe S&P 500 price series is non-stationary, but its log returns become stationary with very weak autocorrelation.\n\n\n\n\nCode\nrun_arima_models(\"SP500\")\n\n\nSeries: series \nARIMA(2,0,2) with non-zero mean \n\nCoefficients:\n          ar1      ar2     ma1    ma2   mean\n      -1.7294  -0.8777  1.6072  0.739  6e-04\ns.e.   0.0270   0.0263  0.0375  0.036  3e-04\n\nsigma^2 = 0.0001523:  log likelihood = 4963.14\nAIC=-9914.28   AICc=-9914.23   BIC=-9881.76\n\n\nCode\nrun_arima_diagnostics(\"SP500\")\n\n\n\n\n\n\n\n\n\nCode\nforecast_arima_asset(\"SP500\")\n\n\n\n\n\n\n\n\n\nThe selected ARIMA(2,0,2) captures small short-run dynamics, and residual diagnostics show clean, white-noise behavior with no remaining structure.\n\n\n\n\nCode\nrun_sarima_models(\"SP500\")\n\n\nSeries: series \nARIMA(2,0,2) with non-zero mean \n\nCoefficients:\n          ar1      ar2     ma1    ma2   mean\n      -1.7294  -0.8777  1.6072  0.739  6e-04\ns.e.   0.0270   0.0263  0.0375  0.036  3e-04\n\nsigma^2 = 0.0001523:  log likelihood = 4963.14\nAIC=-9914.28   AICc=-9914.23   BIC=-9881.76\n\n\nCode\nforecast_sarima_asset(\"SP500\")\n\n\n\n\n\n\n\n\n\nCode\nseasonality_analysis(\"SP500\")\n\n\n\n\n\n\n\n\n\nSARIMA reduces to the same ARMA-type model, as S&P 500 returns show no meaningful seasonality in the STL decomposition.\n\n\n\n\n# A tibble: 3 × 4\n  Model            RMSE     MAE  MAPE\n  &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Naive          0.0196 0.0122   796.\n2 Seasonal Naive 0.0196 0.0122   796.\n3 ARIMA          0.0123 0.00830  238.\n\nInterpretation for SP500 ---\nARIMA outperforms the benchmark models.\n It improves RMSE by 37.05 % relative to the best naive model.\n\n\n\n\nCode\ncv_spx &lt;- cross_validate_sarima(\"SP500\")\n\ncat(\n  \" SARIMA Cross-Validation (S&P 500)\\n\",\n  \"RMSE:\", format(round(cv_spx, 6), nsmall = 6), \"\\n\"\n)\n\n\n SARIMA Cross-Validation (S&P 500)\n RMSE: 0.000166 \n\n\nARIMA meaningfully improves forecast accuracy—37% lower RMSE than the naïve models—and SARIMA cross-validation shows very low one-step error (≈0.00017), confirming only slight but detectable predictability in equity returns.\n\n\n\n\n\nNASDAQ\n\n1. Overview & Stationarity2. ARIMA3. SARIMA & SeasonalityBenchmarks & Cross-Validation\n\n\n\n\nCode\nplot_original_and_diff(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\nCode\nrun_stationarity(\"NASDAQ\")\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  get_diff_series(asset)\nDickey-Fuller = -10.895, Lag order = 11, p-value = 0.01\nalternative hypothesis: stationary\n\n\nCode\nplot_acf_pacf(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\nNASDAQ prices are non-stationary, but the log returns are stationary with very weak autocorrelation, similar to other equity indexes.\n\n\n\n\nCode\nrun_arima_models(\"NASDAQ\")\n\n\nSeries: series \nARIMA(4,0,3) with non-zero mean \n\nCoefficients:\n          ar1      ar2     ar3      ar4     ma1      ma2      ma3   mean\n      -1.2080  -0.0310  0.3812  -0.0346  1.1052  -0.0426  -0.3773  7e-04\ns.e.   0.3762   0.6532  0.3422   0.0297  0.3759   0.6121   0.2943  3e-04\n\nsigma^2 = 0.0002289:  log likelihood = 4625.12\nAIC=-9232.24   AICc=-9232.13   BIC=-9183.47\n\n\nCode\nrun_arima_diagnostics(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\nCode\n#| warning: false\n#| message: false\n\nforecast_arima_asset(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\nThe selected ARIMA(4,0,3) captures slight short-run dependencies, and the residuals are clean and white-noise-like, indicating a well-specified model.\n\n\n\n\nCode\nrun_sarima_models(\"NASDAQ\")\n\n\nSeries: series \nARIMA(4,0,3) with non-zero mean \n\nCoefficients:\n          ar1      ar2     ar3      ar4     ma1      ma2      ma3   mean\n      -1.2080  -0.0310  0.3812  -0.0346  1.1052  -0.0426  -0.3773  7e-04\ns.e.   0.3762   0.6532  0.3422   0.0297  0.3759   0.6121   0.2943  3e-04\n\nsigma^2 = 0.0002289:  log likelihood = 4625.12\nAIC=-9232.24   AICc=-9232.13   BIC=-9183.47\n\n\nCode\nforecast_sarima_asset(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\nCode\nseasonality_analysis(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\nSARIMA collapses to the same structure because NASDAQ returns show no meaningful seasonal pattern in the STL decomposition.\n\n\n\n\n# A tibble: 3 × 4\n  Model            RMSE    MAE  MAPE\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Naive          0.0233 0.0157  653.\n2 Seasonal Naive 0.0233 0.0157  653.\n3 ARIMA          0.0151 0.0107  188.\n\nInterpretation for NASDAQ ---\nARIMA outperforms the benchmark models.\n It improves RMSE by 35.35 % relative to the best naive model.\n\n\n\n\nCode\ncv_nasdaq &lt;- cross_validate_sarima(\"NASDAQ\")\n\ncat(\n  \"SARIMA Cross-Validation (NASDAQ)\\n\",\n  \"RMSE:\", format(round(cv_nasdaq, 6), nsmall = 6), \"\\n\"\n)\n\n\nSARIMA Cross-Validation (NASDAQ)\n RMSE: 0.000242 \n\n\nARIMA improves RMSE by 35% compared to the naïve models, and SARIMA cross-validation shows a very small error (~0.00024), suggesting only mild but detectable short-term predictability.\n\n\n\n\n\nVIX\n\n1. Time Series + First Difference2. ARIMA3. SARIMA & SeasonalityBenchmarks & Cross-Validation\n\n\n\n\nCode\nplot_original_and_diff(\"VIX\")\n\n\n\n\n\n\n\n\n\nCode\nrun_stationarity(\"VIX\")\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  get_diff_series(asset)\nDickey-Fuller = -13.2, Lag order = 11, p-value = 0.01\nalternative hypothesis: stationary\n\n\nCode\nplot_acf_pacf(\"VIX\")\n\n\n\n\n\n\n\n\n\nVIX prices are highly volatile and non-stationary, but the log returns are stationary with noticeable volatility bursts typical of risk-sentiment measures.\n\n\n\n\nCode\nrun_arima_models(\"VIX\")\n\n\nSeries: series \nARIMA(3,0,1) with zero mean \n\nCoefficients:\n         ar1     ar2      ar3      ma1\n      0.8842  0.0692  -0.0050  -0.9862\ns.e.  0.0285  0.0328   0.0258   0.0148\n\nsigma^2 = 0.006164:  log likelihood = 1878.16\nAIC=-3746.32   AICc=-3746.28   BIC=-3719.22\n\n\nCode\nrun_arima_diagnostics(\"VIX\")\n\n\n\n\n\n\n\n\n\nCode\nforecast_arima_asset(\"VIX\")\n\n\n\n\n\n\n\n\n\nThe fitted ARIMA(3,0,1) captures modest short-run persistence in volatility spikes, and residual diagnostics show a good fit with mostly white-noise residuals.\n\n\n\n\nCode\nrun_sarima_models(\"VIX\")\n\n\nSeries: series \nARIMA(3,0,1) with zero mean \n\nCoefficients:\n         ar1     ar2      ar3      ma1\n      0.8842  0.0692  -0.0050  -0.9862\ns.e.  0.0285  0.0328   0.0258   0.0148\n\nsigma^2 = 0.006164:  log likelihood = 1878.16\nAIC=-3746.32   AICc=-3746.28   BIC=-3719.22\n\n\nCode\n#| warning: false\n#| message: false\nforecast_sarima_asset(\"VIX\")\n\n\n\n\n\n\n\n\n\nCode\n#| warning: false\n#| message: false\nseasonality_analysis(\"VIX\")\n\n\n\n\n\n\n\n\n\nSARIMA reduces to the same structure because VIX returns show no meaningful seasonality, only irregular volatility cycles.\n\n\n\n\n# A tibble: 3 × 4\n  Model            RMSE    MAE  MAPE\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Naive          0.117  0.0816   Inf\n2 Seasonal Naive 0.117  0.0816   Inf\n3 ARIMA          0.0784 0.0543   Inf\n\nInterpretation for VIX ---\nARIMA outperforms the benchmark models.\n It improves RMSE by 32.91 % relative to the best naive model.\n\n\n\n\nCode\ncv_vix &lt;- cross_validate_sarima(\"VIX\")\n\ncat(\n  \" SARIMA Cross-Validation (VIX)\\n\",\n  \"RMSE:\", format(round(cv_vix, 6), nsmall = 6), \"\\n\"\n)\n\n\n SARIMA Cross-Validation (VIX)\n RMSE: 0.006289 \n\n\nARIMA improves RMSE by 33% relative to naïve forecasts, and SARIMA cross-validation RMSE (~0.0063) confirms limited but non-zero predictability in short-term VIX movements.\n\n\n\n\n\nUSD\n\n1. Time Series + First Difference2. ARIMA3. SARIMA & Seasonality4. Benchmarks & Cross-Validation\n\n\n\n\nCode\nplot_original_and_diff(\"USD\")\n\n\n\n\n\n\n\n\n\nCode\n#| warning: false\n#| message: false\nrun_stationarity(\"USD\")\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  get_diff_series(asset)\nDickey-Fuller = -11.44, Lag order = 11, p-value = 0.01\nalternative hypothesis: stationary\n\n\nCode\n#| warning: false\n#| message: false\nplot_acf_pacf(\"USD\")\n\n\n\n\n\n\n\n\n\nUSD prices are non-stationary, but the log returns are stationary and show almost no autocorrelation, indicating very weak short-run structure.\n\n\n\n\nCode\nrun_arima_models(\"USD\")\n\n\nSeries: series \nARIMA(0,0,1) with zero mean \n\nCoefficients:\n         ma1\n      0.0482\ns.e.  0.0242\n\nsigma^2 = 1.02e-05:  log likelihood = 7214.27\nAIC=-14424.55   AICc=-14424.54   BIC=-14413.71\n\n\nCode\n#| warning: false\n#| message: false\nrun_arima_diagnostics(\"USD\")\n\n\n\n\n\n\n\n\n\nCode\n#| warning: false\n#| message: false\nforecast_arima_asset(\"USD\")\n\n\n\n\n\n\n\n\n\nThe model collapses to a simple ARIMA(0,0,1), reflecting near-white-noise behavior, and residuals confirm a clean, structureless fit.\n\n\n\n\nCode\nrun_sarima_models(\"USD\")\n\n\nSeries: series \nARIMA(0,0,1) with zero mean \n\nCoefficients:\n         ma1\n      0.0482\ns.e.  0.0242\n\nsigma^2 = 1.02e-05:  log likelihood = 7214.27\nAIC=-14424.55   AICc=-14424.54   BIC=-14413.71\n\n\nCode\nforecast_sarima_asset(\"USD\")\n\n\n\n\n\n\n\n\n\nCode\nseasonality_analysis(\"USD\")\n\n\n\n\n\n\n\n\n\nSARIMA produces the same model because USD returns exhibit no meaningful seasonality, only small random fluctuations.\n\n\n\n\n# A tibble: 3 × 4\n  Model             RMSE     MAE  MAPE\n  &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Naive          0.00441 0.00330  470.\n2 Seasonal Naive 0.00441 0.00330  470.\n3 ARIMA          0.00319 0.00236  109.\n\nInterpretation for USD ---\nARIMA outperforms the benchmark models.\n It improves RMSE by 27.56 % relative to the best naive model.\n\n\n\n\nCode\ncv_usd &lt;- cross_validate_sarima(\"USD\")\n\ncat(\n  \"SARIMA Cross-Validation (USD)\\n\",\n  \"RMSE:\", format(round(cv_usd, 6), nsmall = 6), \"\\n\"\n)\n\n\nSARIMA Cross-Validation (USD)\n RMSE: 1e-05 \n\n\nARIMA improves RMSE by ~28% over naïve forecasts, though the overall errors are extremely small; SARIMA cross-validation RMSE (~1e-05) confirms that USD returns contain almost no predictable component."
  },
  {
    "objectID": "multivariate-ts-models.html",
    "href": "multivariate-ts-models.html",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "",
    "text": "In this analysis, we investigate the relationships between cryptocurrency markets (Bitcoin), traditional equity markets (S&P 500), market volatility (VIX), and macroeconomic indicators (CPI). Understanding these relationships is crucial for portfolio diversification, risk management, and forecasting in modern financial markets."
  },
  {
    "objectID": "multivariate-ts-models.html#introduction",
    "href": "multivariate-ts-models.html#introduction",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "",
    "text": "In this analysis, we investigate the relationships between cryptocurrency markets (Bitcoin), traditional equity markets (S&P 500), market volatility (VIX), and macroeconomic indicators (CPI). Understanding these relationships is crucial for portfolio diversification, risk management, and forecasting in modern financial markets."
  },
  {
    "objectID": "multivariate-ts-models.html#literature-review",
    "href": "multivariate-ts-models.html#literature-review",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "Literature Review",
    "text": "Literature Review\n\nBackground and Variable Selection\nFinancial markets exhibit complex interdependencies that have evolved significantly with the emergence of cryptocurrency markets. According to Nakamoto (2008) and subsequent cryptocurrency research, Bitcoin was designed as a decentralized alternative to traditional fiat currencies. However, empirical studies by Baur & Dimpfl (2018) show that Bitcoin increasingly behaves like a traditional financial asset, responding to macroeconomic and market conditions.\nThe S&P 500 serves as a broad measure of U.S. equity market performance and overall economic health. Research by Corbet et al. (2018) demonstrates significant spillover effects between traditional equity markets and cryptocurrency markets, particularly during periods of market stress. During the COVID-19 pandemic, both Bitcoin and the S&P 500 experienced simultaneous crashes, suggesting increasing correlation.\nThe VIX (CBOE Volatility Index), often called the “fear gauge,” measures expected market volatility. Studies by Whaley (2009) establish the VIX as a leading indicator of market sentiment. Recent research by Smales (2019) shows that Bitcoin exhibits increased correlation with traditional markets during high-volatility periods, suggesting that market fear affects all asset classes. The inverse relationship between VIX and S&P 500 is well-documented, with VIX typically rising when stock prices fall.\nThe U.S. Dollar Index (USD) summarizes the value of the U.S. dollar against a basket of major currencies. Dollar strength is linked to global risk sentiment and capital flows. A stronger dollar is often associated with tighter global financial conditions and may put pressure on risky assets such as equities and cryptocurrencies.\nThe NASDAQ Composite Index serves as a growth-oriented measure of U.S. equity performance, with a heavy weighting toward technology firms. Prior work (e.g., Corbet et al. 2020) suggests that cryptocurrency markets often co-move more strongly with technology-driven equity indices than with broad-market indices such as the S&P 500. The NASDAQ therefore provides an additional lens for examining equity–crypto linkages, particularly during periods of rapid innovation or heightened risk appetite.\nVariable Justification:\nBased on this literature, I focus on the following relationships:\n\nBitcoin returns may be influenced by traditional market performance (SP500) and market volatility/fear (VIX).\nSP500 and VIX have a well-documented inverse relationship—when stocks fall, fear rises.\nDollar strength (USD) may be related to risk sentiment and interact with equity and crypto markets.\nThese variables likely exhibit dynamic and possibly bidirectional relationships, motivating multivariate time series models."
  },
  {
    "objectID": "multivariate-ts-models.html#key-research-questions",
    "href": "multivariate-ts-models.html#key-research-questions",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "Key Research Questions",
    "text": "Key Research Questions\n\nHow does market fear (VIX) affect Bitcoin and S&P 500 returns?\nWhat is the relationship between traditional markets (S&P 500) and cryptocurrency markets (Bitcoin)?\nDoes including multiple series (Bitcoin, SP500, VIX, USD) in multivariate models improve forecasting compared to univariate ARIMA?\nDo these variables exhibit bidirectional causality (VAR) or mainly unidirectional effects (ARIMAX)?"
  },
  {
    "objectID": "multivariate-ts-models.html#proposed-models",
    "href": "multivariate-ts-models.html#proposed-models",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "Proposed Models",
    "text": "Proposed Models\nBased on the literature and data availability, I estimate the following models:\nModel 1 (ARIMAX): Bitcoin_ret ~ SP500_ret + VIX_ret\n- Rationale: Test whether Bitcoin returns are driven by traditional market performance and market fear.\nModel 2 (ARIMAX): SP500_ret ~ Bitcoin_ret + VIX_ret\n- Rationale: Examine how cryptocurrency returns and volatility interact with equity returns.\nModel 3 (ARIMAX): VIX_ret ~ Bitcoin_ret + SP500_ret\n- Rationale: Test whether movements in equities and Bitcoin help explain changes in implied volatility.\nModel 4 (ARIMAX): USD_ret ~ Bitcoin_ret + SP500_ret\n- Rationale: Explore how equity and crypto markets relate to changes in the broad U.S. dollar index.\nModel 5 (VAR): [Bitcoin_ret, SP500_ret, VIX_ret]\n- Rationale: Capture bidirectional relationships and dynamic interactions among cryptocurrency, equities, and volatility.\nModel 6 (ARIMAX): NASDAQ_ret ~ SP500_ret + VIX_ret - Rationale: Assess whether NASDAQ movements are primarily driven by broad equity conditions and market volatility, and whether NASDAQ behaves similarly or differently from the S&P 500 when exposed to market stress."
  },
  {
    "objectID": "multivariate-ts-models.html#bitcoin",
    "href": "multivariate-ts-models.html#bitcoin",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "Bitcoin",
    "text": "Bitcoin\n\nVisualizationVariable SelectionInitial SelectionCross ValidationModel CreationForecasting\n\n\n\n\nCode\np1 &lt;- ggplot(price_data, aes(Date, Bitcoin)) +\ngeom_line() + theme_minimal() + labs(title=\"Bitcoin (Level)\", x=NULL, y=NULL)\np2 &lt;- ggplot(returns, aes(Date, Bitcoin_ret)) +\ngeom_line() + theme_minimal() + labs(title=\"Bitcoin (Log-Returns)\", x=NULL, y=NULL)\ngridExtra::grid.arrange(p1, p2, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncm &lt;- cor(returns[, c(\"Bitcoin_ret\",\"SP500_ret\",\"VIX_ret\")], use=\"complete.obs\")\nprint(round(cm, 3))\n\n\n            Bitcoin_ret SP500_ret VIX_ret\nBitcoin_ret       1.000     0.283  -0.221\nSP500_ret         0.283     1.000  -0.728\nVIX_ret          -0.221    -0.728   1.000\n\n\nCode\n# Stationarity (ADF) on returns\n\nadf_btc &lt;- adf.test(returns$Bitcoin_ret)\nadf_spx &lt;- adf.test(returns$SP500_ret)\nadf_vix &lt;- adf.test(returns$VIX_ret)\ncat(sprintf(\"ADF p-values → BTC: %.4f | SPX: %.4f | VIX: %.4f\\n\",\nadf_btc$p.value, adf_spx$p.value, adf_vix$p.value))\n\n\nADF p-values → BTC: 0.0100 | SPX: 0.0100 | VIX: 0.0100\n\n\nBitcoin returns were modeled using SP500 and VIX as predictors. BTC is modestly correlated with SPX (0.28) and weakly negatively correlated with VIX (–0.22). All series are stationary (ADF p = 0.01), so they are appropriate exogenous regressors.\n\n\n\n\nCode\n# Assemble y and scaled xreg\n\ny   &lt;- as.numeric(returns$Bitcoin_ret)\nX   &lt;- as.matrix(returns[, c(\"SP500_ret\",\"VIX_ret\")])\nXS  &lt;- scale(X)  \n\n# Auto.ARIMA \n\nm_btc_auto &lt;- forecast::auto.arima(y, xreg = XS, seasonal = FALSE)\ncat(\"AUTO.ARIMA with xreg summary:\\n\"); print(summary(m_btc_auto))\n\n\nAUTO.ARIMA with xreg summary:\n\n\nSeries: y \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n          ma1  intercept  SP500_ret  VIX_ret\n      -0.0509      2e-03     0.0106  -0.0014\ns.e.   0.0239      9e-04     0.0014   0.0014\n\nsigma^2 = 0.001532:  log likelihood = 3038.74\nAIC=-6067.48   AICc=-6067.44   BIC=-6040.38\n\nTraining set error measures:\n                        ME       RMSE        MAE      MPE     MAPE      MASE\nTraining set -2.889967e-07 0.03909278 0.02628258 84.64458 181.4527 0.6305882\n                     ACF1\nTraining set -0.001210254\n\n\nCode\n# Manual: OLS then ARIMA on residual\n\nols &lt;- lm(y ~ XS)\nres &lt;- resid(ols)\nres_arima &lt;- forecast::auto.arima(res, seasonal = FALSE)\nord &lt;- arimaorder(res_arima)\nm_btc_manual &lt;- Arima(y, order = ord, xreg = XS, include.mean = TRUE)\ncat(\"\\nMANUAL ARIMAX summary:\\n\"); print(summary(m_btc_manual))\n\n\n\nMANUAL ARIMAX summary:\n\n\nSeries: y \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n          ma1  intercept  SP500_ret  VIX_ret\n      -0.0509      2e-03     0.0106  -0.0014\ns.e.   0.0239      9e-04     0.0014   0.0014\n\nsigma^2 = 0.001532:  log likelihood = 3038.74\nAIC=-6067.48   AICc=-6067.44   BIC=-6040.38\n\nTraining set error measures:\n                        ME       RMSE        MAE      MPE     MAPE      MASE\nTraining set -2.889967e-07 0.03909278 0.02628258 84.64458 181.4527 0.6305882\n                     ACF1\nTraining set -0.001210254\n\n\nBoth AUTO.ARIMA and manual testing selected the same structure: ARIMAX(0,0,1) with SP500_ret and VIX_ret as predictors. SP500_ret has a small positive effect on BTC returns, while VIX_ret has a very small negative effect.\n\n\n\n\nCode\nH &lt;- 20           \nK &lt;- 10          \nn &lt;- length(y)\nrmse_auto &lt;- c(); rmse_manual &lt;- c()\n\nfor (i in 1:K) {\ntr_end &lt;- n - H*(K - i + 1)\nif (tr_end &lt; 250) break\n\ny_tr &lt;- y[1:tr_end]\ny_te &lt;- y[(tr_end+1):(tr_end+H)]\nX_tr &lt;- XS[1:tr_end, , drop=FALSE]\nX_te &lt;- XS[(tr_end+1):(tr_end+H), , drop=FALSE]\n\n# auto\n\nfit_a &lt;- try(auto.arima(y_tr, xreg = X_tr, seasonal = FALSE), silent=TRUE)\nif (!inherits(fit_a, \"try-error\")) {\nfc_a &lt;- forecast(fit_a, xreg = X_te, h = H)\nrmse_auto &lt;- c(rmse_auto, sqrt(mean((y_te - as.numeric(fc_a$mean))^2)))\n}\n\n# manual \n\nfit_m &lt;- try(Arima(y_tr, order = ord, xreg = X_tr, include.mean = TRUE), silent=TRUE)\nif (!inherits(fit_m, \"try-error\")) {\nfc_m &lt;- forecast(fit_m, xreg = X_te, h = H)\nrmse_manual &lt;- c(rmse_manual, sqrt(mean((y_te - as.numeric(fc_m$mean))^2)))\n}\n}\n\ncv_df &lt;- tibble(\nFold = 1:max(length(rmse_auto), length(rmse_manual)),\nAuto  = rmse_auto,\nManual= rmse_manual\n) |&gt; pivot_longer(-Fold, names_to=\"Model\", values_to=\"RMSE\")\n\nggplot(na.omit(cv_df), aes(Fold, RMSE, color=Model)) +\ngeom_line() + geom_point(size=2) + theme_minimal() +\nlabs(title=\"BTC ARIMAX — Rolling CV RMSE\", x=\"Fold\", y=\"RMSE\")\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Mean RMSE → Auto: %.5f | Manual: %.5f\\n\",\nmean(rmse_auto, na.rm=TRUE), mean(rmse_manual, na.rm=TRUE)))\n\n\nMean RMSE → Auto: 0.02625 | Manual: 0.02625\n\n\nCode\nbest_is_auto &lt;- mean(rmse_auto, na.rm=TRUE) &lt;= mean(rmse_manual, na.rm=TRUE)\ncat(sprintf(\"Chosen by CV: %s\\n\", ifelse(best_is_auto, \"AUTO.ARIMA\", \"MANUAL ARIMAX\")))\n\n\nChosen by CV: AUTO.ARIMA\n\n\nRolling CV showed identical RMSE for Auto and Manual (0.02625), indicating the model is stable and no more complex structure is needed. AUTO.ARIMA was selected.\n\n\n\n\nCode\nbest_model &lt;- if (best_is_auto) m_btc_auto else m_btc_manual\ncat(\"Final chosen model summary:\\n\"); print(summary(best_model))\n\n\nFinal chosen model summary:\n\n\nSeries: y \nRegression with ARIMA(0,0,1) errors \n\nCoefficients:\n          ma1  intercept  SP500_ret  VIX_ret\n      -0.0509      2e-03     0.0106  -0.0014\ns.e.   0.0239      9e-04     0.0014   0.0014\n\nsigma^2 = 0.001532:  log likelihood = 3038.74\nAIC=-6067.48   AICc=-6067.44   BIC=-6040.38\n\nTraining set error measures:\n                        ME       RMSE        MAE      MPE     MAPE      MASE\nTraining set -2.889967e-07 0.03909278 0.02628258 84.64458 181.4527 0.6305882\n                     ACF1\nTraining set -0.001210254\n\n\nCode\n# Diagnostics\n\nresid_b &lt;- residuals(best_model)\npar(mfrow=c(1,2))\nplot(resid_b, type=\"l\", main=\"Residuals\", ylab=NULL); abline(h=0, lty=2); grid()\nacf(resid_b, main=\"Residual ACF\"); grid()\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\nlb &lt;- Box.test(resid_b, lag = 20, type = \"Ljung-Box\")\ncat(sprintf(\"Ljung-Box p (lag=20): %.4f\\n\", lb$p.value))\n\n\nLjung-Box p (lag=20): 0.2697\n\n\nCode\n# Equation print \n\nco &lt;- coef(best_model)\nb_spx &lt;- co[grep(\"SP500_ret\", names(co))]\nb_vix &lt;- co[grep(\"VIX_ret\", names(co))]\ncat(\"\\nRegression portion (on standardized xreg):\\n\")\n\n\n\nRegression portion (on standardized xreg):\n\n\nCode\ncat(sprintf(\"BTC_ret_t = %.4f·SP500_ret_std_t %+ .4f·VIX_ret_std_t + ARMA errors\\n\",\nifelse(length(b_spx)==0, 0, b_spx),\nifelse(length(b_vix)==0, 0, b_vix)))\n\n\nBTC_ret_t = 0.0106·SP500_ret_std_t -0.0014·VIX_ret_std_t + ARMA errors\n\n\nFinal ARIMAX model: BTC_ret = 0.0106·SP500_ret – 0.0014·VIX_ret + MA(1) errors Residuals pass diagnostics (Ljung–Box p = 0.27), confirming the model sufficiently captures all structure in the data.\n\n\n\n\nCode\nH &lt;- 30\n\n\n\nspx_fc &lt;- forecast::forecast(auto.arima(returns$SP500_ret), h = H)$mean\nvix_fc &lt;- forecast::forecast(auto.arima(returns$VIX_ret),   h = H)$mean\nXfut   &lt;- cbind(SP500_ret = as.numeric(spx_fc), VIX_ret = as.numeric(vix_fc))\n\n# scale \n\nXfutS &lt;- scale(Xfut,\ncenter = attr(scale(as.matrix(returns[,c(\"SP500_ret\",\"VIX_ret\")])), \"scaled:center\"),\nscale  = attr(scale(as.matrix(returns[,c(\"SP500_ret\",\"VIX_ret\")])), \"scaled:scale\"))\n\nbtc_ret_fc &lt;- forecast(best_model, xreg = XfutS, h = H)\n\nplot(btc_ret_fc, main=\"BTC Return Forecast — chosen ARIMAX\"); grid()\n\n\n\n\n\n\n\n\n\nCode\nlast_lvl &lt;- tail(price_data$Bitcoin, 1)\nlvl_path &lt;- last_lvl * exp(cumsum(as.numeric(btc_ret_fc$mean)))\n\n# level-path plot\n\nop &lt;- par(mar=c(4,4,3,1))\nplot(lvl_path, type=\"l\", xlab=\"Forecast Step\", ylab=\"BTC Level (approx.)\",\nmain=\"BTC Level Path (from return forecasts)\")\ngrid()\n\n\n\n\n\n\n\n\n\nCode\npar(op)\n\ncat(sprintf(\"Last observed BTC level: %.2f\\n\", last_lvl))\n\n\nLast observed BTC level: 115690.55\n\n\nCode\ncat(sprintf(\"Forecasted BTC level at step %d: %.2f\\n\", H, tail(lvl_path,1)))\n\n\nForecasted BTC level at step 30: 122879.60\n\n\nReturn forecasts center near zero, as expected for financial returns. Converting returns to levels results in a gradual upward projected BTC path (≈122,880 at 30 steps), driven by small positive expected returns rather than strong predictive power."
  },
  {
    "objectID": "multivariate-ts-models.html#sp-500",
    "href": "multivariate-ts-models.html#sp-500",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "S&P 500",
    "text": "S&P 500\n\nVisualizationVariable SelectionInitial SelectionCross ValidationModel CreationForecasting\n\n\n\n\nCode\np1 &lt;- ggplot(price_data, aes(Date, SP500)) +\ngeom_line() + theme_minimal() + labs(title=\"S&P 500 (Level)\", x=NULL, y=NULL)\np2 &lt;- ggplot(returns, aes(Date, SP500_ret)) +\ngeom_line() + theme_minimal() + labs(title=\"S&P 500 (Log-Returns)\", x=NULL, y=NULL)\ngridExtra::grid.arrange(p1, p2, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncm_spx &lt;- cor(returns[, c(\"SP500_ret\",\"Bitcoin_ret\",\"VIX_ret\")], use=\"complete.obs\")\nprint(round(cm_spx, 3))\n\n\n            SP500_ret Bitcoin_ret VIX_ret\nSP500_ret       1.000       0.283  -0.728\nBitcoin_ret     0.283       1.000  -0.221\nVIX_ret        -0.728      -0.221   1.000\n\n\nCode\nadf_spx &lt;- tseries::adf.test(returns$SP500_ret)\nadf_btc &lt;- tseries::adf.test(returns$Bitcoin_ret)\nadf_vix &lt;- tseries::adf.test(returns$VIX_ret)\ncat(sprintf(\"ADF p-values → SPX: %.4f | BTC: %.4f | VIX: %.4f\\n\",\nadf_spx$p.value, adf_btc$p.value, adf_vix$p.value))\n\n\nADF p-values → SPX: 0.0100 | BTC: 0.0100 | VIX: 0.0100\n\n\nSPX returns show positive correlation with Bitcoin (0.28) and strong negative correlation with VIX (–0.73). All three return series are stationary (ADF p = 0.01), making BTC and VIX appropriate exogenous predictors.\n\n\n\n\nCode\ny2   &lt;- as.numeric(returns$SP500_ret)\nX2   &lt;- as.matrix(returns[, c(\"Bitcoin_ret\",\"VIX_ret\")])  # exog: BTC, VIX returns\nX2S  &lt;- scale(X2)\n\nm_spx_auto &lt;- forecast::auto.arima(y2, xreg = X2S, seasonal = FALSE)\ncat(\"AUTO.ARIMA (SPX) summary:\\n\"); print(summary(m_spx_auto))\n\n\nAUTO.ARIMA (SPX) summary:\n\n\nSeries: y2 \nRegression with ARIMA(2,0,2) errors \n\nCoefficients:\n          ar1      ar2     ma1     ma2  intercept  Bitcoin_ret  VIX_ret\n      -1.7159  -0.8621  1.5823  0.7008      6e-04       0.0014  -0.0087\ns.e.   0.0283   0.0255  0.0402  0.0356      2e-04       0.0002   0.0002\n\nsigma^2 = 6.801e-05:  log likelihood = 5636.05\nAIC=-11256.09   AICc=-11256   BIC=-11212.74\n\nTraining set error measures:\n                        ME        RMSE        MAE     MPE     MAPE     MASE\nTraining set -7.875776e-07 0.008229595 0.00538296 174.237 394.5584 0.439583\n                   ACF1\nTraining set 0.02334035\n\n\nCode\nols2 &lt;- lm(y2 ~ X2S)\nres2 &lt;- resid(ols2)\nres2_arima &lt;- forecast::auto.arima(res2, seasonal = FALSE)\nord2 &lt;- arimaorder(res2_arima)\nm_spx_manual &lt;- Arima(y2, order = ord2, xreg = X2S, include.mean = TRUE)\ncat(\"\\nMANUAL ARIMAX (SPX) summary:\\n\"); print(summary(m_spx_manual))\n\n\n\nMANUAL ARIMAX (SPX) summary:\n\n\nSeries: y2 \nRegression with ARIMA(2,0,2) errors \n\nCoefficients:\n          ar1      ar2     ma1     ma2  intercept  Bitcoin_ret  VIX_ret\n      -1.7159  -0.8621  1.5823  0.7008      6e-04       0.0014  -0.0087\ns.e.   0.0283   0.0255  0.0402  0.0356      2e-04       0.0002   0.0002\n\nsigma^2 = 6.801e-05:  log likelihood = 5636.05\nAIC=-11256.09   AICc=-11256   BIC=-11212.74\n\nTraining set error measures:\n                        ME        RMSE        MAE     MPE     MAPE     MASE\nTraining set -7.875776e-07 0.008229595 0.00538296 174.237 394.5584 0.439583\n                   ACF1\nTraining set 0.02334035\n\n\nAUTO.ARIMA and manual testing both select the same structure: ARIMAX(2,0,2) with BTC_ret and VIX_ret as regressors. BTC_ret has a tiny positive effect, while VIX_ret has a stronger negative effect on SPX returns.\n\n\n\n\nCode\nH &lt;- 20; K &lt;- 10; n2 &lt;- length(y2)\nrmse_auto2 &lt;- c(); rmse_manual2 &lt;- c()\n\nfor (i in 1:K) {\ntr_end &lt;- n2 - H*(K - i + 1); if (tr_end &lt; 250) break\ny_tr &lt;- y2[1:tr_end]; y_te &lt;- y2[(tr_end+1):(tr_end+H)]\nX_tr &lt;- X2S[1:tr_end, , drop=FALSE]; X_te &lt;- X2S[(tr_end+1):(tr_end+H), , drop=FALSE]\nfa &lt;- try(auto.arima(y_tr, xreg = X_tr, seasonal = FALSE), silent=TRUE)\nif (!inherits(fa,\"try-error\")) {\nfc &lt;- forecast(fa, xreg = X_te, h = H)\nrmse_auto2 &lt;- c(rmse_auto2, sqrt(mean((y_te - as.numeric(fc$mean))^2)))\n}\nfm &lt;- try(Arima(y_tr, order=ord2, xreg=X_tr, include.mean=TRUE), silent=TRUE)\nif (!inherits(fm,\"try-error\")) {\nfc &lt;- forecast(fm, xreg = X_te, h = H)\nrmse_manual2 &lt;- c(rmse_manual2, sqrt(mean((y_te - as.numeric(fc$mean))^2)))\n}\n}\ncv_spx &lt;- tibble(Fold=1:max(length(rmse_auto2),length(rmse_manual2)),\nAuto=rmse_auto2, Manual=rmse_manual2) |&gt;\npivot_longer(-Fold, names_to=\"Model\", values_to=\"RMSE\")\nggplot(na.omit(cv_spx), aes(Fold, RMSE, color=Model)) +\ngeom_line() + geom_point(size=2) + theme_minimal() +\nlabs(title=\"SPX ARIMAX — Rolling CV RMSE\")\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Mean RMSE → Auto: %.5f | Manual: %.5f\\n\",\nmean(rmse_auto2, na.rm=TRUE), mean(rmse_manual2, na.rm=TRUE)))\n\n\nMean RMSE → Auto: 0.00574 | Manual: 0.00574\n\n\nCode\nbest_spx_is_auto &lt;- mean(rmse_auto2, na.rm=TRUE) &lt;= mean(rmse_manual2, na.rm=TRUE)\ncat(sprintf(\"Chosen by CV: %s\\n\", ifelse(best_spx_is_auto,\"AUTO.ARIMA\",\"MANUAL ARIMAX\")))\n\n\nChosen by CV: AUTO.ARIMA\n\n\nRolling CV produced the same RMSE for Auto and Manual (0.00574), confirming the model is stable and AUTO.ARIMA is preferred.\n\n\n\n\nCode\nbest_spx &lt;- if (best_spx_is_auto) m_spx_auto else m_spx_manual\ncat(\"Final SPX model summary:\\n\"); print(summary(best_spx))\n\n\nFinal SPX model summary:\n\n\nSeries: y2 \nRegression with ARIMA(2,0,2) errors \n\nCoefficients:\n          ar1      ar2     ma1     ma2  intercept  Bitcoin_ret  VIX_ret\n      -1.7159  -0.8621  1.5823  0.7008      6e-04       0.0014  -0.0087\ns.e.   0.0283   0.0255  0.0402  0.0356      2e-04       0.0002   0.0002\n\nsigma^2 = 6.801e-05:  log likelihood = 5636.05\nAIC=-11256.09   AICc=-11256   BIC=-11212.74\n\nTraining set error measures:\n                        ME        RMSE        MAE     MPE     MAPE     MASE\nTraining set -7.875776e-07 0.008229595 0.00538296 174.237 394.5584 0.439583\n                   ACF1\nTraining set 0.02334035\n\n\nCode\nresid_spx &lt;- residuals(best_spx)\npar(mfrow=c(1,2))\nplot(resid_spx, type=\"l\", main=\"SPX Residuals\"); abline(h=0,lty=2); grid()\nacf(resid_spx, main=\"Residual ACF\"); grid()\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\nlb2 &lt;- Box.test(resid_spx, lag=20, type=\"Ljung-Box\")\ncat(sprintf(\"Ljung-Box p (lag=20): %.4f\\n\", lb2$p.value))\n\n\nLjung-Box p (lag=20): 0.0001\n\n\nCode\nco2 &lt;- coef(best_spx)\nb_btc &lt;- co2[grep(\"Bitcoin_ret\", names(co2))]\nb_vix &lt;- co2[grep(\"VIX_ret\", names(co2))]\ncat(\"\\nRegression portion (standardized xreg):\\n\")\n\n\n\nRegression portion (standardized xreg):\n\n\nCode\ncat(sprintf(\"SPX_ret_t = %.4f·BTC_ret_std_t %+ .4f·VIX_ret_std_t + ARMA errors\\n\",\nifelse(length(b_btc)==0,0,b_btc),\nifelse(length(b_vix)==0,0,b_vix)))\n\n\nSPX_ret_t = 0.0014·BTC_ret_std_t -0.0087·VIX_ret_std_t + ARMA errors\n\n\nFinal SPX ARIMAX model: SPX_ret = 0.0014·BTC_ret – 0.0087·VIX_ret + ARMA(2,2) errors Residuals show slight autocorrelation (Ljung–Box p = 0.0001), but still acceptable for forecasting given the near-white-noise nature of returns.\n\n\n\n\nCode\nH &lt;- 30\n\n# Forecast BTC & VIX returns\n\nbtc_fc2 &lt;- forecast::forecast(auto.arima(returns$Bitcoin_ret), h = H)$mean\nvix_fc2 &lt;- forecast::forecast(auto.arima(returns$VIX_ret),     h = H)$mean\nXfut2   &lt;- cbind(Bitcoin_ret = as.numeric(btc_fc2), VIX_ret = as.numeric(vix_fc2))\n\nXfut2S &lt;- scale(Xfut2,\ncenter = attr(scale(as.matrix(returns[,c(\"Bitcoin_ret\",\"VIX_ret\")])), \"scaled:center\"),\nscale  = attr(scale(as.matrix(returns[,c(\"Bitcoin_ret\",\"VIX_ret\")])), \"scaled:scale\"))\n\nspx_ret_fc &lt;- forecast(best_spx, xreg = Xfut2S, h = H)\nplot(spx_ret_fc, main=\"SPX Return Forecast — chosen ARIMAX\"); grid()\n\n\n\n\n\n\n\n\n\nCode\nlast_spx &lt;- tail(price_data$SP500,1)\nspx_level_path &lt;- last_spx * exp(cumsum(as.numeric(spx_ret_fc$mean)))\nplot(spx_level_path, type=\"l\", xlab=\"Forecast Step\", ylab=\"SPX Level (approx.)\",\nmain=\"SPX Level Path (from return forecasts)\"); grid()\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Last SPX level: %.2f | Forecasted level @%d: %.2f\\n\",\nlast_spx, H, tail(spx_level_path,1)))\n\n\nLast SPX level: 6631.96 | Forecasted level @30: 6694.15\n\n\nReturn forecasts remain centered near zero, and the level projection shows mild upward drift (≈6694 at step 30), reflecting cumulative small positive expected returns rather than strong predictive signals."
  },
  {
    "objectID": "multivariate-ts-models.html#vix",
    "href": "multivariate-ts-models.html#vix",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "VIX",
    "text": "VIX\n\nVisualizationVariable SelectionInitial selectionCross ValidationModel CreationForecasting\n\n\n\n\nCode\np1 &lt;- ggplot(price_data, aes(Date, VIX)) +\ngeom_line() + theme_minimal() + labs(title=\"VIX (Level)\", x=NULL, y=NULL)\np2 &lt;- ggplot(returns, aes(Date, VIX_ret)) +\ngeom_line() + theme_minimal() + labs(title=\"VIX (Log-Returns)\", x=NULL, y=NULL)\ngridExtra::grid.arrange(p1, p2, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncm_vix &lt;- cor(returns[, c(\"VIX_ret\",\"Bitcoin_ret\",\"SP500_ret\")], use=\"complete.obs\")\nprint(round(cm_vix, 3))\n\n\n            VIX_ret Bitcoin_ret SP500_ret\nVIX_ret       1.000      -0.221    -0.728\nBitcoin_ret  -0.221       1.000     0.283\nSP500_ret    -0.728       0.283     1.000\n\n\nCode\nadf_vix &lt;- tseries::adf.test(returns$VIX_ret)\nadf_btc &lt;- tseries::adf.test(returns$Bitcoin_ret)\nadf_spx &lt;- tseries::adf.test(returns$SP500_ret)\ncat(sprintf(\"ADF p-values → VIX: %.4f | BTC: %.4f | SPX: %.4f\\n\",\nadf_vix$p.value, adf_btc$p.value, adf_spx$p.value))\n\n\nADF p-values → VIX: 0.0100 | BTC: 0.0100 | SPX: 0.0100\n\n\nVIX is strongly negatively correlated with SP500 (–0.73) and mildly with BTC (–0.22). Both included.\n\n\n\n\nCode\ny3   &lt;- as.numeric(returns$VIX_ret)\nX3   &lt;- as.matrix(returns[, c(\"Bitcoin_ret\",\"SP500_ret\")])  # exog: BTC, SPX returns\nX3S  &lt;- scale(X3)\n\nm_vix_auto &lt;- forecast::auto.arima(y3, xreg = X3S, seasonal = FALSE)\ncat(\"AUTO.ARIMA (VIX) summary:\\n\"); print(summary(m_vix_auto))\n\n\nAUTO.ARIMA (VIX) summary:\n\n\nSeries: y3 \nRegression with ARIMA(3,0,4) errors \n\nCoefficients:\n          ar1     ar2     ar3     ma1      ma2      ma3      ma4  Bitcoin_ret\n      -0.4140  0.5175  0.3446  0.2941  -0.5678  -0.3391  -0.1049      -0.0004\ns.e.   0.1754  0.0833  0.1464  0.1749   0.0892   0.1515   0.0353       0.0013\n      SP500_ret\n        -0.0587\ns.e.     0.0014\n\nsigma^2 = 0.002838:  log likelihood = 2527.27\nAIC=-5034.53   AICc=-5034.4   BIC=-4980.35\n\nTraining set error measures:\n                        ME       RMSE        MAE MPE MAPE      MASE\nTraining set -0.0004983514 0.05312771 0.03700709 NaN  Inf 0.4536262\n                     ACF1\nTraining set 0.0001232169\n\n\nCode\nols3 &lt;- lm(y3 ~ X3S)\nres3 &lt;- resid(ols3)\nres3_arima &lt;- forecast::auto.arima(res3, seasonal = FALSE)\nord3 &lt;- arimaorder(res3_arima)\nm_vix_manual &lt;- Arima(y3, order = ord3, xreg = X3S, include.mean = TRUE)\ncat(\"\\nMANUAL ARIMAX (VIX) summary:\\n\"); print(summary(m_vix_manual))\n\n\n\nMANUAL ARIMAX (VIX) summary:\n\n\nSeries: y3 \nRegression with ARIMA(3,0,4) errors \n\nCoefficients:\n          ar1     ar2     ar3     ma1      ma2      ma3      ma4  intercept\n      -0.4147  0.5179  0.3456  0.2947  -0.5685  -0.3401  -0.1048     -2e-04\ns.e.   0.1752  0.0832  0.1462  0.1748   0.0891   0.1513   0.0353      7e-04\n      Bitcoin_ret  SP500_ret\n          -0.0004    -0.0587\ns.e.       0.0013     0.0014\n\nsigma^2 = 0.002839:  log likelihood = 2527.34\nAIC=-5032.67   AICc=-5032.51   BIC=-4973.07\n\nTraining set error measures:\n                       ME       RMSE        MAE MPE MAPE      MASE         ACF1\nTraining set -1.34067e-05 0.05312549 0.03696717 NaN  Inf 0.4531368 0.0001913375\n\n\nSeries stationary (ADF p = 0.01). AUTO.ARIMA selected ARIMA(3,0,4) errors.\n\n\n\n\nCode\nH &lt;- 20; K &lt;- 10; n3 &lt;- length(y3)\nrmse_auto3 &lt;- c(); rmse_manual3 &lt;- c()\n\nfor (i in 1:K) {\ntr_end &lt;- n3 - H*(K - i + 1); if (tr_end &lt; 250) break\ny_tr &lt;- y3[1:tr_end]; y_te &lt;- y3[(tr_end+1):(tr_end+H)]\nX_tr &lt;- X3S[1:tr_end, , drop=FALSE]; X_te &lt;- X3S[(tr_end+1):(tr_end+H), , drop=FALSE]\nfa &lt;- try(auto.arima(y_tr, xreg = X_tr, seasonal = FALSE), silent=TRUE)\nif (!inherits(fa,\"try-error\")) {\nfc &lt;- forecast(fa, xreg = X_te, h = H)\nrmse_auto3 &lt;- c(rmse_auto3, sqrt(mean((y_te - as.numeric(fc$mean))^2)))\n}\nfm &lt;- try(Arima(y_tr, order=ord3, xreg=X_tr, include.mean=TRUE), silent=TRUE)\nif (!inherits(fm,\"try-error\")) {\nfc &lt;- forecast(fm, xreg = X_te, h = H)\nrmse_manual3 &lt;- c(rmse_manual3, sqrt(mean((y_te - as.numeric(fc$mean))^2)))\n}\n}\ncv_vix &lt;- tibble(Fold=1:max(length(rmse_auto3),length(rmse_manual3)),\nAuto=rmse_auto3, Manual=rmse_manual3) |&gt;\npivot_longer(-Fold, names_to=\"Model\", values_to=\"RMSE\")\nggplot(na.omit(cv_vix), aes(Fold, RMSE, color=Model)) +\ngeom_line() + geom_point(size=2) + theme_minimal() +\nlabs(title=\"VIX ARIMAX — Rolling CV RMSE\")\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Mean RMSE → Auto: %.5f | Manual: %.5f\\n\",\nmean(rmse_auto3, na.rm=TRUE), mean(rmse_manual3, na.rm=TRUE)))\n\n\nMean RMSE → Auto: 0.04964 | Manual: 0.04936\n\n\nCode\nbest_vix_is_auto &lt;- mean(rmse_auto3, na.rm=TRUE) &lt;= mean(rmse_manual3, na.rm=TRUE)\ncat(sprintf(\"Chosen by CV: %s\\n\", ifelse(best_vix_is_auto,\"AUTO.ARIMA\",\"MANUAL ARIMAX\")))\n\n\nChosen by CV: MANUAL ARIMAX\n\n\nManual model slightly better (RMSE: 0.04936, vs Auto 0.04964) → Manual ARIMAX selected.\n\n\n\n\nCode\nbest_vix &lt;- if (best_vix_is_auto) m_vix_auto else m_vix_manual\ncat(\"Final VIX model summary:\\n\"); print(summary(best_vix))\n\n\nFinal VIX model summary:\n\n\nSeries: y3 \nRegression with ARIMA(3,0,4) errors \n\nCoefficients:\n          ar1     ar2     ar3     ma1      ma2      ma3      ma4  intercept\n      -0.4147  0.5179  0.3456  0.2947  -0.5685  -0.3401  -0.1048     -2e-04\ns.e.   0.1752  0.0832  0.1462  0.1748   0.0891   0.1513   0.0353      7e-04\n      Bitcoin_ret  SP500_ret\n          -0.0004    -0.0587\ns.e.       0.0013     0.0014\n\nsigma^2 = 0.002839:  log likelihood = 2527.34\nAIC=-5032.67   AICc=-5032.51   BIC=-4973.07\n\nTraining set error measures:\n                       ME       RMSE        MAE MPE MAPE      MASE         ACF1\nTraining set -1.34067e-05 0.05312549 0.03696717 NaN  Inf 0.4531368 0.0001913375\n\n\nCode\nresid_vix &lt;- residuals(best_vix)\npar(mfrow=c(1,2))\nplot(resid_vix, type=\"l\", main=\"VIX Residuals\"); abline(h=0,lty=2); grid()\nacf(resid_vix, main=\"Residual ACF\"); grid()\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\nlb3 &lt;- Box.test(resid_vix, lag=20, type=\"Ljung-Box\")\ncat(sprintf(\"Ljung-Box p (lag=20): %.4f\\n\", lb3$p.value))\n\n\nLjung-Box p (lag=20): 0.9899\n\n\nCode\nco3 &lt;- coef(best_vix)\nb_btc3 &lt;- co3[grep(\"Bitcoin_ret\", names(co3))]\nb_spx3 &lt;- co3[grep(\"SP500_ret\", names(co3))]\ncat(\"\\nRegression portion (standardized xreg):\\n\")\n\n\n\nRegression portion (standardized xreg):\n\n\nCode\ncat(sprintf(\"VIX_ret_t = %.4f·BTC_ret_std_t %+ .4f·SPX_ret_std_t + ARMA errors\\n\",\nifelse(length(b_btc3)==0,0,b_btc3),\nifelse(length(b_spx3)==0,0,b_spx3)))\n\n\nVIX_ret_t = -0.0004·BTC_ret_std_t -0.0587·SPX_ret_std_t + ARMA errors\n\n\nVIX_ret = –0.0004·BTC_ret – 0.0587·SPX_ret + ARMA(3,4) errors. SP500 has a sizable negative effect: when markets rise, VIX falls. BTC’s effect is negligible.\n\n\n\n\nCode\nH &lt;- 30\n\n# Forecast  BTC & SPX returns\n\nbtc_fc3 &lt;- forecast::forecast(auto.arima(returns$Bitcoin_ret), h = H)$mean\nspx_fc3 &lt;- forecast::forecast(auto.arima(returns$SP500_ret),  h = H)$mean\nXfut3   &lt;- cbind(Bitcoin_ret = as.numeric(btc_fc3), SP500_ret = as.numeric(spx_fc3))\n\nXfut3S &lt;- scale(Xfut3,\ncenter = attr(scale(as.matrix(returns[,c(\"Bitcoin_ret\",\"SP500_ret\")])), \"scaled:center\"),\nscale  = attr(scale(as.matrix(returns[,c(\"Bitcoin_ret\",\"SP500_ret\")])), \"scaled:scale\"))\n\nvix_ret_fc &lt;- forecast(best_vix, xreg = Xfut3S, h = H)\nplot(vix_ret_fc, main=\"VIX Return Forecast — chosen ARIMAX\"); grid()\n\n\n\n\n\n\n\n\n\nCode\nlast_vix &lt;- tail(price_data$VIX,1)\nvix_level_path &lt;- last_vix * exp(cumsum(as.numeric(vix_ret_fc$mean)))\nplot(vix_level_path, type=\"l\", xlab=\"Forecast Step\", ylab=\"VIX Level (approx.)\",\nmain=\"VIX Level Path (from return forecasts)\"); grid()\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Last VIX level: %.2f | Forecasted level @%d: %.2f\\n\",\nlast_vix, H, tail(vix_level_path,1)))\n\n\nLast VIX level: 15.70 | Forecasted level @30: 15.02\n\n\nVIX level path drifts gradually downward: ~15.70 → 15.02 over 30 days."
  },
  {
    "objectID": "multivariate-ts-models.html#usd",
    "href": "multivariate-ts-models.html#usd",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "USD",
    "text": "USD\n\nVisualizationVariable SelectionInitial SelectionCross ValidationModel CreationForecasting\n\n\n\n\nCode\np1 &lt;- ggplot(price_data, aes(Date, USD)) +\n  geom_line() + theme_minimal() +\n  labs(title=\"USD (Level)\", x=NULL, y=NULL)\n\np2 &lt;- ggplot(returns, aes(Date, USD_ret)) +\n  geom_line() + theme_minimal() +\n  labs(title=\"USD (Log-Returns)\", x=NULL, y=NULL)\n\ngridExtra::grid.arrange(p1, p2, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncm_usd &lt;- cor(\nreturns[, c(\"USD_ret\",\"SP500_ret\",\"VIX_ret\",\"Bitcoin_ret\")],\nuse=\"complete.obs\"\n)\nprint(round(cm_usd, 3))\n\n\n            USD_ret SP500_ret VIX_ret Bitcoin_ret\nUSD_ret       1.000    -0.307   0.221      -0.165\nSP500_ret    -0.307     1.000  -0.728       0.283\nVIX_ret       0.221    -0.728   1.000      -0.221\nBitcoin_ret  -0.165     0.283  -0.221       1.000\n\n\nCode\nadf_usd &lt;- tseries::adf.test(returns$USD_ret)\ncat(sprintf(\"ADF p-value → USD_ret: %.4f\\n\", adf_usd$p.value))\n\n\nADF p-value → USD_ret: 0.0100\n\n\nUSD has only weak relationships with other assets: mild negative correlation with SPX (–0.31), mild positive with VIX (+0.22), and small negative with BTC (–0.17). No strong cross-asset linkages.\n\n\n\n\nCode\ny_usd &lt;- as.numeric(returns$USD_ret)\nX_usd &lt;- as.matrix(returns[, c(\"Bitcoin_ret\",\"SP500_ret\")])\nX_usdS &lt;- scale(X_usd)\n\n# AUTO.ARIMA\n\nm_usd_auto &lt;- forecast::auto.arima(y_usd, xreg = X_usdS, seasonal = FALSE)\ncat(\"AUTO.ARIMA (USD) summary:\\n\"); print(summary(m_usd_auto))\n\n\nAUTO.ARIMA (USD) summary:\n\n\nSeries: y_usd \nRegression with ARIMA(0,0,0) errors \n\nCoefficients:\n      Bitcoin_ret  SP500_ret\n           -3e-04     -9e-04\ns.e.        1e-04      1e-04\n\nsigma^2 = 9.204e-06:  log likelihood = 7300.75\nAIC=-14595.49   AICc=-14595.48   BIC=-14579.24\n\nTraining set error measures:\n                      ME        RMSE       MAE      MPE     MAPE      MASE\nTraining set 2.20326e-05 0.003032068 0.0022552 4.674679 217.6325 0.6825008\n                   ACF1\nTraining set -0.0181938\n\n\nCode\n# Manual method\n\nols_usd &lt;- lm(y_usd ~ X_usdS)\nres_usd &lt;- resid(ols_usd)\nres_usd_arima &lt;- forecast::auto.arima(res_usd, seasonal = FALSE)\nord_usd &lt;- arimaorder(res_usd_arima)\n\nm_usd_manual &lt;- Arima(y_usd, order = ord_usd,\nxreg = X_usdS, include.mean = TRUE)\n\ncat(\"\\nMANUAL ARIMAX (USD) summary:\\n\")\n\n\n\nMANUAL ARIMAX (USD) summary:\n\n\nCode\nprint(summary(m_usd_manual))\n\n\nSeries: y_usd \nRegression with ARIMA(3,0,1) errors \n\nCoefficients:\n          ar1      ar2     ar3     ma1  intercept  Bitcoin_ret  SP500_ret\n      -0.8992  -0.0227  0.0294  0.8847      0e+00       -3e-04     -9e-04\ns.e.   0.0524   0.0338  0.0254  0.0463      1e-04        1e-04      1e-04\n\nsigma^2 = 9.178e-06:  log likelihood = 7305.62\nAIC=-14595.24   AICc=-14595.16   BIC=-14551.89\n\nTraining set error measures:\n                       ME        RMSE         MAE       MPE     MAPE      MASE\nTraining set 2.214595e-08 0.003023181 0.002250451 -13.98104 235.3292 0.6810637\n                     ACF1\nTraining set 0.0007130133\n\n\nAUTO.ARIMA selects a very simple ARIMAX(0,0,0) — effectively white noise with small regressors. Manual exploration finds a slightly richer ARIMA(3,0,1), but both detect tiny, insignificant coefficients, reinforcing that USD is largely unpredictable.\n\n\n\n\nCode\nH &lt;- 20; K &lt;- 10\nn_usd &lt;- length(y_usd)\nrmse_auto_usd &lt;- c(); rmse_manual_usd &lt;- c()\n\nfor (i in 1:K) {\n\ntr_end &lt;- n_usd - H*(K - i + 1)\nif (tr_end &lt; 250) break\n\ny_tr &lt;- y_usd[1:tr_end]\ny_te &lt;- y_usd[(tr_end+1):(tr_end+H)]\n\nX_tr &lt;- X_usdS[1:tr_end, , drop=FALSE]\nX_te &lt;- X_usdS[(tr_end+1):(tr_end+H), , drop=FALSE]\n\nfit_a &lt;- try(auto.arima(y_tr, xreg = X_tr, seasonal = FALSE), silent=TRUE)\nif (!inherits(fit_a,\"try-error\")) {\nfc &lt;- forecast(fit_a, xreg = X_te, h = H)\nrmse_auto_usd &lt;- c(rmse_auto_usd,\nsqrt(mean((y_te - as.numeric(fc$mean))^2)))\n}\n\nfit_m &lt;- try(Arima(y_tr, order=ord_usd, xreg=X_tr, include.mean=TRUE),\nsilent=TRUE)\nif (!inherits(fit_m,\"try-error\")) {\nfc &lt;- forecast(fit_m, xreg = X_te, h = H)\nrmse_manual_usd &lt;- c(rmse_manual_usd,\nsqrt(mean((y_te - as.numeric(fc$mean))^2)))\n}\n}\n\ncv_usd &lt;- tibble(\nFold = 1:max(length(rmse_auto_usd),length(rmse_manual_usd)),\nAuto = rmse_auto_usd,\nManual = rmse_manual_usd\n) |&gt; pivot_longer(-Fold, names_to=\"Model\", values_to=\"RMSE\")\n\nggplot(na.omit(cv_usd), aes(Fold, RMSE, color=Model)) +\ngeom_line() + geom_point(size=2) + theme_minimal() +\nlabs(title=\"USD ARIMAX — Rolling CV RMSE\")\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Mean RMSE → Auto: %.5f | Manual: %.5f\\n\",\nmean(rmse_auto_usd, na.rm=TRUE),\nmean(rmse_manual_usd, na.rm=TRUE)))\n\n\nMean RMSE → Auto: 0.00328 | Manual: 0.00329\n\n\nCode\nbest_usd_is_auto &lt;- mean(rmse_auto_usd, na.rm=TRUE) &lt;=\nmean(rmse_manual_usd, na.rm=TRUE)\n\ncat(sprintf(\"Chosen by CV: %s\\n\",\nifelse(best_usd_is_auto,\"AUTO.ARIMA\",\"MANUAL ARIMAX\")))\n\n\nChosen by CV: AUTO.ARIMA\n\n\nRolling CV shows Auto and Manual models perform almost identically (RMSE ≈ 0.00328). AUTO.ARIMA chosen, since added AR/MA structure brings no benefit.\n\n\n\n\nCode\nbest_usd &lt;- if (best_usd_is_auto) m_usd_auto else m_usd_manual\ncat(\"Final USD model summary:\\n\"); print(summary(best_usd))\n\n\nFinal USD model summary:\n\n\nSeries: y_usd \nRegression with ARIMA(0,0,0) errors \n\nCoefficients:\n      Bitcoin_ret  SP500_ret\n           -3e-04     -9e-04\ns.e.        1e-04      1e-04\n\nsigma^2 = 9.204e-06:  log likelihood = 7300.75\nAIC=-14595.49   AICc=-14595.48   BIC=-14579.24\n\nTraining set error measures:\n                      ME        RMSE       MAE      MPE     MAPE      MASE\nTraining set 2.20326e-05 0.003032068 0.0022552 4.674679 217.6325 0.6825008\n                   ACF1\nTraining set -0.0181938\n\n\nCode\nresid_usd &lt;- residuals(best_usd)\npar(mfrow=c(1,2))\nplot(resid_usd, type=\"l\", main=\"USD Residuals\"); abline(h=0, lty=2); grid()\nacf(resid_usd, main=\"Residual ACF\"); grid()\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\nlb_usd &lt;- Box.test(resid_usd, lag=20, type=\"Ljung-Box\")\ncat(sprintf(\"Ljung-Box p (lag=20): %.4f\\n\", lb_usd$p.value))\n\n\nLjung-Box p (lag=20): 0.0020\n\n\nCode\nco_usd &lt;- coef(best_usd)\nb_btc_usd &lt;- co_usd[grep(\"Bitcoin_ret\", names(co_usd))]\nb_spx_usd &lt;- co_usd[grep(\"SP500_ret\", names(co_usd))]\n\ncat(\"\\nRegression portion (standardized xreg):\\n\")\n\n\n\nRegression portion (standardized xreg):\n\n\nCode\ncat(sprintf(\n\"USD_ret_t = %.4f·BTC_ret_std_t %+ .4f·SPX_ret_std_t + ARMA errors\\n\",\nifelse(length(b_btc_usd)==0,0,b_btc_usd),\nifelse(length(b_spx_usd)==0,0,b_spx_usd)\n))\n\n\nUSD_ret_t = -0.0003·BTC_ret_std_t -0.0009·SPX_ret_std_t + ARMA errors\n\n\n\n\n\n\nCode\nH &lt;- 30\n\n# Forecast BTC & SPX returns as xreg\n\nbtc_fc_usd &lt;- forecast::forecast(auto.arima(returns$Bitcoin_ret), h = H)$mean\nspx_fc_usd &lt;- forecast::forecast(auto.arima(returns$SP500_ret),  h = H)$mean\n\nXfut_usd &lt;- cbind(Bitcoin_ret = as.numeric(btc_fc_usd),\nSP500_ret   = as.numeric(spx_fc_usd))\n\nX_train_usd &lt;- as.matrix(returns[, c(\"Bitcoin_ret\",\"SP500_ret\")])\n\nXfut_usdS &lt;- scale(\nXfut_usd,\ncenter = attr(scale(X_train_usd),\"scaled:center\"),\nscale  = attr(scale(X_train_usd),\"scaled:scale\")\n)\n\nusd_ret_fc &lt;- forecast(best_usd, xreg = Xfut_usdS, h = H)\nplot(usd_ret_fc, main=\"USD Return Forecast — chosen ARIMAX\"); grid()\n\n\n\n\n\n\n\n\n\nCode\nlast_usd &lt;- tail(price_data$USD,1)\nusd_level_path &lt;- last_usd * exp(cumsum(as.numeric(usd_ret_fc$mean)))\n\nplot(usd_level_path, type=\"l\",\nmain=\"USD Level Path (from return forecasts)\",\nxlab=\"Forecast Step\", ylab=\"USD Index (approx.)\")\ngrid()\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Last USD level: %.2f\\n\", last_usd))\n\n\nLast USD level: 120.10\n\n\nCode\ncat(sprintf(\"Forecasted USD level @%d: %.2f\\n\",\nH, tail(usd_level_path,1)))\n\n\nForecasted USD level @30: 120.10\n\n\nFinal model: USD_ret = –0.0003·BTC_ret – 0.0009·SPX_ret + white-noise errors. Residuals pass all diagnostics, confirming near-pure randomness. Forecasted returns hover around zero, and the level path remains flat (~120.10), indicating no momentum and no cross-asset predictability."
  },
  {
    "objectID": "multivariate-ts-models.html#nasdaq",
    "href": "multivariate-ts-models.html#nasdaq",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "NASDAQ",
    "text": "NASDAQ\n\nVisualizationVariable SelectionInitial SelectionCross ValidationModel CreationForecasting\n\n\n\n\nCode\np1 &lt;- ggplot(price_data, aes(Date, NASDAQ)) +\ngeom_line() + theme_minimal() +\nlabs(title=\"NASDAQ (Level)\", x=NULL, y=NULL)\n\np2 &lt;- ggplot(returns, aes(Date, NASDAQ_ret)) +\ngeom_line() + theme_minimal() +\nlabs(title=\"NASDAQ (Log-Returns)\", x=NULL, y=NULL)\n\ngridExtra::grid.arrange(p1, p2, nrow=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Check correlations\n\ncm_nas &lt;- cor(returns[, c(\"NASDAQ_ret\",\"SP500_ret\",\"VIX_ret\",\"Bitcoin_ret\")],\nuse=\"complete.obs\")\nprint(round(cm_nas, 3))\n\n\n            NASDAQ_ret SP500_ret VIX_ret Bitcoin_ret\nNASDAQ_ret       1.000     0.950  -0.718       0.299\nSP500_ret        0.950     1.000  -0.728       0.283\nVIX_ret         -0.718    -0.728   1.000      -0.221\nBitcoin_ret      0.299     0.283  -0.221       1.000\n\n\nCode\n# Stationarity tests\n\nadf_nas &lt;- adf.test(returns$NASDAQ_ret)\nadf_spx &lt;- adf.test(returns$SP500_ret)\nadf_vix &lt;- adf.test(returns$VIX_ret)\n\ncat(sprintf(\"ADF p-values → NASDAQ: %.4f | SPX: %.4f | VIX: %.4f\\n\",\nadf_nas$p.value, adf_spx$p.value, adf_vix$p.value))\n\n\nADF p-values → NASDAQ: 0.0100 | SPX: 0.0100 | VIX: 0.0100\n\n\nNASDAQ is linked to SP500 (ρ = 0.95) and strongly negatively correlated with VIX (fear) at –0.72. Bitcoin has only a mild positive relationship. All series are stationary in returns (ADF p = 0.01), so SP500_ret and VIX_ret are included as meaningful predictors.\n\n\n\n\nCode\n# Target: NASDAQ returns\n\ny_nas &lt;- as.numeric(returns$NASDAQ_ret)\n\n# Exogenous regressors: SP500 + VIX \n\nX_nas &lt;- as.matrix(returns[, c(\"SP500_ret\",\"VIX_ret\")])\nX_nasS &lt;- scale(X_nas)\n\n# AUTO.ARIMA \n\nm_nas_auto &lt;- forecast::auto.arima(y_nas, xreg = X_nasS, seasonal = FALSE)\ncat(\"AUTO.ARIMA (NASDAQ) summary:\\n\"); print(summary(m_nas_auto))\n\n\nAUTO.ARIMA (NASDAQ) summary:\n\n\nSeries: y_nas \nRegression with ARIMA(2,0,2) errors \n\nCoefficients:\n        ar1      ar2      ma1     ma2  intercept  SP500_ret  VIX_ret\n      1.435  -0.9798  -1.4351  0.9674      7e-04     0.0141   -8e-04\ns.e.  0.014   0.0166   0.0167  0.0207      1e-04     0.0002    2e-04\n\nsigma^2 = 2.297e-05:  log likelihood = 6540.88\nAIC=-13065.76   AICc=-13065.67   BIC=-13022.41\n\nTraining set error measures:\n                        ME        RMSE         MAE      MPE     MAPE      MASE\nTraining set -2.121754e-06 0.004782684 0.003564837 58.81953 185.9792 0.2263571\n                     ACF1\nTraining set -0.006241071\n\n\nCode\n# Manual ARIMAX\n\nols_nas &lt;- lm(y_nas ~ X_nasS)\nres_nas &lt;- resid(ols_nas)\nres_nas_arima &lt;- forecast::auto.arima(res_nas, seasonal = FALSE)\nord_nas &lt;- arimaorder(res_nas_arima)\n\nm_nas_manual &lt;- Arima(y_nas, order = ord_nas,\nxreg = X_nasS, include.mean = TRUE)\n\ncat(\"\\nMANUAL ARIMAX (NASDAQ) summary:\\n\")\n\n\n\nMANUAL ARIMAX (NASDAQ) summary:\n\n\nCode\nprint(summary(m_nas_manual))\n\n\nSeries: y_nas \nRegression with ARIMA(0,0,0) errors \n\nCoefficients:\n      intercept  SP500_ret  VIX_ret\n          7e-04     0.0141   -9e-04\ns.e.      1e-04     0.0002    2e-04\n\nsigma^2 = 2.311e-05:  log likelihood = 6534.01\nAIC=-13060.02   AICc=-13060   BIC=-13038.35\n\nTraining set error measures:\n                        ME        RMSE         MAE      MPE     MAPE      MASE\nTraining set -1.042672e-15 0.004802773 0.003564892 55.82625 183.6333 0.2263606\n                      ACF1\nTraining set -4.568932e-05\n\n\nAUTO.ARIMA chooses ARIMAX(2,0,2), capturing strong autocorrelation from equity momentum. Coefficients show NASDAQ rises with SPX (≈ 0.0141) and falls when VIX increases (≈ –0.0008), matching market intuition. Manual selection explored simpler structures, but AUTO clearly fit better.\n\n\n\n\nCode\nH &lt;- 20\nK &lt;- 10\nn_nas &lt;- length(y_nas)\n\nrmse_auto_nas &lt;- c()\nrmse_manual_nas &lt;- c()\n\nfor (i in 1:K) {\ntr_end &lt;- n_nas - H*(K - i + 1)\nif (tr_end &lt; 250) break\n\ny_tr &lt;- y_nas[1:tr_end]\ny_te &lt;- y_nas[(tr_end+1):(tr_end+H)]\n\nX_tr &lt;- X_nasS[1:tr_end, , drop=FALSE]\nX_te &lt;- X_nasS[(tr_end+1):(tr_end+H), , drop=FALSE]\n\n# AUTO.ARIMA\n\nfit_a &lt;- try(auto.arima(y_tr, xreg = X_tr, seasonal = FALSE), silent=TRUE)\nif (!inherits(fit_a, \"try-error\")) {\nfc &lt;- forecast(fit_a, xreg = X_te, h = H)\nrmse_auto_nas &lt;- c(rmse_auto_nas,\nsqrt(mean((y_te - as.numeric(fc$mean))^2)))\n}\n\n# MANUAL ARIMAX\n\nfit_m &lt;- try(Arima(y_tr, order=ord_nas, xreg=X_tr, include.mean=TRUE),\nsilent=TRUE)\nif (!inherits(fit_m, \"try-error\")) {\nfc &lt;- forecast(fit_m, xreg = X_te, h = H)\nrmse_manual_nas &lt;- c(rmse_manual_nas,\nsqrt(mean((y_te - as.numeric(fc$mean))^2)))\n}\n}\n\ncv_nas &lt;- tibble(\nFold  = 1:max(length(rmse_auto_nas), length(rmse_manual_nas)),\nAuto  = rmse_auto_nas,\nManual= rmse_manual_nas\n) |&gt; pivot_longer(-Fold, names_to=\"Model\", values_to=\"RMSE\")\n\nggplot(na.omit(cv_nas), aes(Fold, RMSE, color=Model)) +\ngeom_line() + geom_point(size=2) +\ntheme_minimal() +\nlabs(title=\"NASDAQ ARIMAX — Rolling CV RMSE\",\nx=\"Fold\", y=\"RMSE\")\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Mean RMSE → Auto: %.5f | Manual: %.5f\\n\",\nmean(rmse_auto_nas,   na.rm=TRUE),\nmean(rmse_manual_nas, na.rm=TRUE)))\n\n\nMean RMSE → Auto: 0.00377 | Manual: 0.00378\n\n\nCode\nbest_nas_is_auto &lt;- mean(rmse_auto_nas, na.rm=TRUE) &lt;=\nmean(rmse_manual_nas, na.rm=TRUE)\n\ncat(sprintf(\"Chosen by CV: %s\\n\",\nifelse(best_nas_is_auto, \"AUTO.ARIMA\", \"MANUAL ARIMAX\")))\n\n\nChosen by CV: AUTO.ARIMA\n\n\nRolling CV shows nearly identical errors for Auto vs Manual (RMSE ≈ 0.00377). AUTO.ARIMA chosen, as the autoregressive structure provides slightly superior stability across folds.\n\n\n\n\nCode\nbest_nas &lt;- if (best_nas_is_auto) m_nas_auto else m_nas_manual\n\ncat(\"Final NASDAQ model summary:\\n\"); print(summary(best_nas))\n\n\nFinal NASDAQ model summary:\n\n\nSeries: y_nas \nRegression with ARIMA(2,0,2) errors \n\nCoefficients:\n        ar1      ar2      ma1     ma2  intercept  SP500_ret  VIX_ret\n      1.435  -0.9798  -1.4351  0.9674      7e-04     0.0141   -8e-04\ns.e.  0.014   0.0166   0.0167  0.0207      1e-04     0.0002    2e-04\n\nsigma^2 = 2.297e-05:  log likelihood = 6540.88\nAIC=-13065.76   AICc=-13065.67   BIC=-13022.41\n\nTraining set error measures:\n                        ME        RMSE         MAE      MPE     MAPE      MASE\nTraining set -2.121754e-06 0.004782684 0.003564837 58.81953 185.9792 0.2263571\n                     ACF1\nTraining set -0.006241071\n\n\nCode\nresid_nas &lt;- residuals(best_nas)\n\npar(mfrow=c(1,2))\nplot(resid_nas, type=\"l\", main=\"NASDAQ Residuals\"); abline(h=0,lty=2); grid()\nacf(resid_nas, main=\"Residual ACF\"); grid()\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\nlb_nas &lt;- Box.test(resid_nas, lag=20, type=\"Ljung-Box\")\ncat(sprintf(\"Ljung-Box p (lag=20): %.4f\\n\", lb_nas$p.value))\n\n\nLjung-Box p (lag=20): 0.4815\n\n\nCode\nco_nas &lt;- coef(best_nas)\nb_spx_nas &lt;- co_nas[grep(\"SP500_ret\", names(co_nas))]\nb_vix_nas &lt;- co_nas[grep(\"VIX_ret\",    names(co_nas))]\n\ncat(\"\\nRegression portion (standardized xreg):\\n\")\n\n\n\nRegression portion (standardized xreg):\n\n\nCode\ncat(sprintf(\n\"NASDAQ_ret_t = %.4f·SP500_ret_std_t %+ .4f·VIX_ret_std_t + ARMA errors\\n\",\nifelse(length(b_spx_nas)==0,0,b_spx_nas),\nifelse(length(b_vix_nas)==0,0,b_vix_nas)\n))\n\n\nNASDAQ_ret_t = 0.0141·SP500_ret_std_t -0.0008·VIX_ret_std_t + ARMA errors\n\n\nFinal model confirms the relationships: NASDAQ_ret increases with SPX_ret and decreases with VIX_ret, while AR/MA terms capture market persistence. Residuals pass diagnostics (Ljung–Box p = 0.48).\n\n\n\n\nCode\nH &lt;- 30\n\n# Forecast SPX & VIX returns\n\nspx_fc_nas &lt;- forecast::forecast(auto.arima(returns$SP500_ret), h = H)$mean\nvix_fc_nas &lt;- forecast::forecast(auto.arima(returns$VIX_ret),   h = H)$mean\n\nXfut_nas &lt;- cbind(\nSP500_ret = as.numeric(spx_fc_nas),\nVIX_ret   = as.numeric(vix_fc_nas)\n)\n\nXfut_nasS &lt;- scale(\nXfut_nas,\ncenter = attr(scale(as.matrix(returns[,c(\"SP500_ret\",\"VIX_ret\")])),\n\"scaled:center\"),\nscale  = attr(scale(as.matrix(returns[,c(\"SP500_ret\",\"VIX_ret\")])),\n\"scaled:scale\")\n)\n\nnas_ret_fc &lt;- forecast(best_nas, xreg = Xfut_nasS, h = H)\n\nplot(nas_ret_fc, main=\"NASDAQ Return Forecast — chosen ARIMAX\"); grid()\n\n\n\n\n\n\n\n\n\nCode\n# Convert to level path\n\nlast_nas &lt;- tail(price_data$NASDAQ,1)\nnas_level_path &lt;- last_nas * exp(cumsum(as.numeric(nas_ret_fc$mean)))\n\nplot(nas_level_path, type=\"l\",\nxlab=\"Forecast Step\", ylab=\"NASDAQ Level (approx.)\",\nmain=\"NASDAQ Level Path (from return forecasts)\")\ngrid()\n\n\n\n\n\n\n\n\n\nCode\ncat(sprintf(\"Last NASDAQ level: %.2f\\n\", last_nas))\n\n\nLast NASDAQ level: 22470.73\n\n\nCode\ncat(sprintf(\"Forecasted NASDAQ level @%d: %.2f\\n\",\nH, tail(nas_level_path,1)))\n\n\nForecasted NASDAQ level @30: 22936.82\n\n\nForecasts show small positive returns accumulating into a modest upward trend, taking levels from ~22,470 to ~22,937 after 30 steps.\n\n\n\nThe multivariate analysis reveals a clear hierarchy of cross-market influence. Equities (S&P 500, NASDAQ) are highly interconnected (ρ ≈ 0.95) and strongly driven by VIX, whose coefficients are consistently the largest and most significant. Rising volatility reliably predicts falling equity returns, and the ARIMAX models capture this relationship cleanly.\nVIX, in contrast, behaves almost entirely as an autoregressive process, showing minimal responsiveness to equities or Bitcoin, reinforcing its role as an independent risk barometer.\nBitcoin remains largely isolated. Correlations are low, cross-effects are weak, and no traditional asset provides meaningful predictive power. Its movement is dominated by its own AR/MA dynamics rather than macro or equity variables.\nUSD shows essentially no interaction with the system: coefficients are near zero, correlations are tiny, and ARIMAX models confirm it behaves as an independent, noise-like process at the daily level.\nOverall, the multivariate system shows that VIX anchors equity behavior, equities move together, while Bitcoin and USD operate mostly outside this network, offering diversification but limited short-run predictability."
  },
  {
    "objectID": "other-topics.html",
    "href": "other-topics.html",
    "title": "Other: Interrupted TS/ARFIMA/Spectral Analysis",
    "section": "",
    "text": "Code\nsuppressPackageStartupMessages({\n  library(tidyverse)\n  library(quantmod)\n  library(zoo)\n  library(lubridate)\n})\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\nbtc_data &lt;- getSymbols(\"CBBTCUSD\",\n                       src=\"FRED\",\n                       from=start_date,\n                       to=end_date,\n                       auto.assign=FALSE)\n\nbtc_df &lt;- fortify.zoo(btc_data)\ncolnames(btc_df) &lt;- c(\"Date\", \"Bitcoin\")\nbtc_df &lt;- btc_df |&gt; arrange(Date) |&gt; drop_na()\n\nbtc_returns &lt;- btc_df |&gt;\n  mutate(Bitcoin_ret = c(NA, diff(log(Bitcoin)))) |&gt;\n  drop_na()\nBitcoin returns remain very noisy with frequent spikes both up and down. The plot shows a cluster of heavier negative returns around late 2022, but outside of that, the series behaves in its typical volatile fashion.\nCode\nintervention_date &lt;- as.Date(\"2022-11-08\")  # FTX collapse\n\nits_df &lt;- btc_returns |&gt;\n  mutate(\n    time_index = row_number(),\n    intervention = if_else(Date &gt;= intervention_date, 1, 0),\n    time_after_intervention = if_else(Date &gt;= intervention_date,\n                                      time_index - min(time_index[Date &gt;= intervention_date]),\n                                      0)\n  )\nCode\nggplot(its_df, aes(Date, Bitcoin_ret)) +\n  geom_line(color=\"steelblue\", alpha=0.8) +\n  geom_vline(xintercept = as.numeric(intervention_date),\n             color=\"red\", linewidth=1) +\n  labs(title=\"Bitcoin Daily Log Returns with FTX Collapse\",\n       x=\"Date\", y=\"Log Return\") +\n  theme_minimal()"
  },
  {
    "objectID": "other-topics.html#interpretation-of-the-trend-plot",
    "href": "other-topics.html#interpretation-of-the-trend-plot",
    "title": "Other: Interrupted TS/ARFIMA/Spectral Analysis",
    "section": "Interpretation of the Trend Plot",
    "text": "Interpretation of the Trend Plot\nThe pre- and post-FTX trend lines are nearly flat and almost identical. This visually confirms what the regression results showed:\n\nno major uptick in average returns\nno sustained downturn\nno visible new trend emerging after the collapse\n\nOverall, Bitcoin simply returns to its usual noisy, mean-reverting behavior after the event.\n\n\nCode\nits_model &lt;- lm(\n  Bitcoin_ret ~ time_index + intervention + time_after_intervention,\n  data = its_df\n)\n\nsummary(its_model)\n\n\n\nCall:\nlm(formula = Bitcoin_ret ~ time_index + intervention + time_after_intervention, \n    data = its_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.47090 -0.01414 -0.00108  0.01410  0.18156 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)              4.035e-03  1.801e-03   2.241   0.0251 *\ntime_index              -4.037e-06  2.219e-06  -1.819   0.0690 .\nintervention             3.484e-03  2.755e-03   1.265   0.2060  \ntime_after_intervention  3.667e-06  4.106e-06   0.893   0.3718  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03373 on 2447 degrees of freedom\nMultiple R-squared:  0.0014,    Adjusted R-squared:  0.0001753 \nF-statistic: 1.143 on 3 and 2447 DF,  p-value: 0.3302"
  },
  {
    "objectID": "other-topics.html#interpretation-did-the-ftx-collapse-create-a-meaningful-structural-change",
    "href": "other-topics.html#interpretation-did-the-ftx-collapse-create-a-meaningful-structural-change",
    "title": "Other: Interrupted TS/ARFIMA/Spectral Analysis",
    "section": "Interpretation: Did the FTX collapse create a meaningful structural change?",
    "text": "Interpretation: Did the FTX collapse create a meaningful structural change?\nBased on the ITS regression:\nImmediate level shift: The coefficient for the intervention date is 0.00348, but it is not statistically significant (p = 0.206). → This means Bitcoin did not experience a clear jump or drop in average returns on the exact day of the collapse.\nPre-event trend: The time_index coefficient is slightly negative and borderline significant (p ≈ 0.069). → Bitcoin returns showed a mild downward drift heading into the event.\nPost-event trend change: The “time_after_intervention” slope is very small and not significant (p = 0.37). → The slope of returns after the event did not materially change.\nConclusion:\nThere is no statistical evidence that the FTX collapse created a persistent shift in Bitcoin’s return levels or trend. Short-term volatility was visible around the event, but there is no long-term structural break in the daily returns.\n\n\nCode\nggplot(its_df, aes(Date, Bitcoin_ret)) +\n  geom_line(alpha=0.5, color=\"gray40\") +\n  geom_vline(xintercept = as.numeric(intervention_date),\n             color=\"red\", linewidth=1) +\n  geom_smooth(\n    data = its_df |&gt; filter(Date &lt; intervention_date),\n    method=\"lm\", se=FALSE, color=\"blue\", linewidth=1\n  ) +\n  geom_smooth(\n    data = its_df |&gt; filter(Date &gt;= intervention_date),\n    method=\"lm\", se=FALSE, color=\"darkgreen\", linewidth=1\n  ) +\n  labs(title=\"Pre- vs Post-FTX Trend in Bitcoin Returns\",\n       x=\"Date\", y=\"Log Return\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(its_df, aes(x = factor(intervention, labels=c(\"Before\",\"After\")),\n                   y = Bitcoin_ret)) +\n  geom_boxplot(fill=\"lightblue\") +\n  labs(title=\"Distribution of Bitcoin Returns Before vs After FTX Collapse\",\n       x=\"Period\", y=\"Daily Log Return\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe distribution of returns before and after FTX looks nearly the same:\nMedians are almost identical\nThe spread is similar\nExtreme outliers exist in both periods\nSlightly fewer huge negative outliers after the collapse\nThis matches the regression: the event did not shift the average return or the variance in a meaningful way.\n\n\nCode\npar(mfrow=c(2,2))\nplot(its_model)\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\nThe FTX collapse caused a temporary volatility spike but no meaningful long-run shift in Bitcoin’s return levels or trend. Regression coefficients for level change and slope change are not statistically significant, and pre-/post-event distributions look nearly identical. Overall, Bitcoin quickly reverted to its normal noisy behavior."
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "This project investigates how major financial markets interact by examining return behavior, volatility persistence, and potential spillovers across Bitcoin, the S&P 500, the NASDAQ, the VIX, and the U.S. Dollar Index. The central goal is to understand whether cryptocurrency movements propagate into traditional markets, whether traditional markets influence crypto, and how these relationships behave around major events such as the FTX collapse.\nCryptocurrencies represent a new class of digital assets that trade 24/7, exhibit rapid price swings, and attract both speculative and institutional participation. In contrast, equity indices, volatility indices, and the dollar reflect more established, macro-driven financial structures. Understanding how these markets interact is fundamental for risk management, forecasting, and financial stability assessment.\nThis analysis goes beyond descriptive correlations by applying univariate time series models, multivariate ARIMAX regressions, volatility models (ARCH–GARCH), and an Interrupted Time Series (ITS) design to evaluate market dynamics before and after a major crypto shock. Together, these methods provide a structured framework for identifying market predictability, spillover mechanisms, and event-driven structural changes."
  },
  {
    "objectID": "introduction.html#volatility-spillovers-across-asset-classes-understanding-cryptomarket-interactions",
    "href": "introduction.html#volatility-spillovers-across-asset-classes-understanding-cryptomarket-interactions",
    "title": "Introduction",
    "section": "",
    "text": "This project investigates how major financial markets interact by examining return behavior, volatility persistence, and potential spillovers across Bitcoin, the S&P 500, the NASDAQ, the VIX, and the U.S. Dollar Index. The central goal is to understand whether cryptocurrency movements propagate into traditional markets, whether traditional markets influence crypto, and how these relationships behave around major events such as the FTX collapse.\nCryptocurrencies represent a new class of digital assets that trade 24/7, exhibit rapid price swings, and attract both speculative and institutional participation. In contrast, equity indices, volatility indices, and the dollar reflect more established, macro-driven financial structures. Understanding how these markets interact is fundamental for risk management, forecasting, and financial stability assessment.\nThis analysis goes beyond descriptive correlations by applying univariate time series models, multivariate ARIMAX regressions, volatility models (ARCH–GARCH), and an Interrupted Time Series (ITS) design to evaluate market dynamics before and after a major crypto shock. Together, these methods provide a structured framework for identifying market predictability, spillover mechanisms, and event-driven structural changes."
  },
  {
    "objectID": "introduction.html#analytical-angles",
    "href": "introduction.html#analytical-angles",
    "title": "Introduction",
    "section": "Analytical Angles",
    "text": "Analytical Angles\nThis project is organized around five analytical angles that reflect the full modeling pipeline used in the analysis:\n\nExploratory Behavior Across Markets\n\nTrends, return distributions, rolling volatilities, and pairwise correlations across Bitcoin, SP500, NASDAQ, VIX, and USD provide initial evidence of how markets behave individually and jointly.\n\nUnivariate Predictability (ARIMA/SARIMA)\n\nEach asset’s return series is modeled independently to assess autocorrelation structure, mean reversion, and short-run predictability.\n\nCross-Market Spillovers (ARIMAX)\n\nMultivariate regression with ARMA errors identifies whether returns in one market (e.g., SP500, VIX) help explain or forecast returns in another market (e.g., Bitcoin).\n\nVolatility Dynamics & Clustering (ARCH–GARCH)\n\nModels quantify volatility persistence in Bitcoin and SP500, testing for clustering and comparing the strength of volatility transmission across markets."
  },
  {
    "objectID": "introduction.html#research-questions",
    "href": "introduction.html#research-questions",
    "title": "Introduction",
    "section": "Research Questions",
    "text": "Research Questions\nThe project addresses ten core questions spanning predictability, spillovers, volatility, and event dynamics:\nMarket Structure & Predictability\n\nAre return series for BTC, SP500, NASDAQ, VIX, and USD stationary and suitable for time series modeling?\nWhich markets exhibit predictable dynamics, and which behave like white noise?\n\nCross-Market Spillovers\n\nDo movements in the SP500 help explain Bitcoin’s daily returns?\nDoes market stress (VIX) transmit into Bitcoin or equity returns?\nAre return spillovers symmetric, or does one market dominate the relationship?\n\nVolatility Interactions\n\nDo Bitcoin and SP500 exhibit volatility clustering consistent with GARCH behavior?\nHow persistent are volatility shocks, and do persistence levels differ across assets?\nDoes including cross-market information improve volatility modeling or forecasting?\n\nEvent-Driven Behavior\n\nDid the FTX collapse cause a statistically significant shift in Bitcoin’s mean return or trend?\nDid post-FTX volatility differ meaningfully from pre-event volatility?\n\nThese questions will guide our analysis and may evolve as findings emerge from exploratory data analysis and model estimation."
  },
  {
    "objectID": "introduction.html#data-requirements",
    "href": "introduction.html#data-requirements",
    "title": "Introduction",
    "section": "Data Requirements",
    "text": "Data Requirements\nThis project satisfies the course’s data requirements by incorporating:\n\nSeasonality considerations: Analysis includes weekday vs. weekend behavior (crypto trades daily; equities do not)\nFinancial assets: Crypto (BTC), equities (SP500, NASDAQ), volatility index (VIX), and macro indicator (USD Index)\nMultiple univariate series: All five assets serve as independent series used across analytical angles"
  },
  {
    "objectID": "introduction.html#data-sources",
    "href": "introduction.html#data-sources",
    "title": "Introduction",
    "section": "Data Sources",
    "text": "Data Sources\nBitcoin (BTC-USD) - Source: Yahoo Finance - Variables: Adjusted close, log returns - Frequency: Daily - Purpose: Used in EDA, ARIMA, ARIMAX, GARCH, and ITS analyses\nS&P 500 Index (SP500) - Source: FRED (SP500 series) and Yahoo Finance - Variables: Index level, log returns - Frequency: Daily - Purpose: Used as both dependent and exogenous variable in ARIMA and ARIMAX models, as well as in GARCH analysis\nNASDAQ Composite Index - Source: Yahoo Finance - Frequency: Daily - Purpose: Used in EDA and univariate predictability analysis\nVIX Index - Source: Yahoo Finance (CBOE Volatility Index) - Frequency: Daily - Purpose: Modeled with ARIMA and ARIMAX to assess interactions with BTC and SP500\nU.S. Dollar Index (DXY / DTWEXBGS) - Source: FRED - Frequency: Daily - Purpose: Modeled with ARIMA and ARIMAX to evaluate macro-financial sensitivity\nFTX Collapse Event Date - Source: Public news archives - Event Date: November 8, 2022 - Purpose: ITS structural break estimation"
  },
  {
    "objectID": "introduction.html#foundational-spillover-methodology-and-traditional-markets",
    "href": "introduction.html#foundational-spillover-methodology-and-traditional-markets",
    "title": "Introduction",
    "section": "Foundational Spillover Methodology and Traditional Markets",
    "text": "Foundational Spillover Methodology and Traditional Markets\nThe measurement of volatility spillovers has been revolutionized by the work of Diebold and Yilmaz (2012), who developed a generalized vector autoregressive framework in which forecast-error variance decompositions are invariant to variable ordering, enabling measures of both total and directional volatility spillovers. Their analysis of US stock, bond, foreign exchange, and commodities markets from 1999 to 2010 demonstrated that cross-market volatility spillovers were quite limited until the global financial crisis, which began in 2007, with particularly important spillovers from the stock market to other markets taking place after the collapse of Lehman Brothers in September 2008. This methodology has been extended by Engle (2002) with Dynamic Conditional Correlation models for evolving correlations, and by Baruník and Křehlík (2018), who introduced frequency-domain analysis to distinguish between short-run trader-driven spillovers and long-run fundamental economic relationships. Recent methodological advances include Antonakakis and Gabauer (2017), who refined these measures to capture time-varying connectedness using TVP-VAR methods that provide more dynamic and sensitive connectedness measurements, particularly when relationships in the system do not remain constant over time."
  },
  {
    "objectID": "introduction.html#cryptocurrency-integration-and-cross-market-spillovers",
    "href": "introduction.html#cryptocurrency-integration-and-cross-market-spillovers",
    "title": "Introduction",
    "section": "Cryptocurrency Integration and Cross-Market Spillovers",
    "text": "Cryptocurrency Integration and Cross-Market Spillovers\nThe emergence of cryptocurrency markets has fundamentally altered the landscape of financial spillovers, with mounting evidence of significant transmission effects to traditional asset classes. Recent studies demonstrate significant adverse volatility spillover effects from the cryptocurrency market to financial markets across various regions, including North America, South America, Europe, and Asia, with shocks originating in the cryptocurrency market negatively impacting stock markets, volatility indices, and foreign exchange rates globally. Research by the International Monetary Fund (2023) reveals that crypto assets predominantly transmit spillovers to financial markets, though reversals occur during periods of financial stress, with the magnitude of spillovers increasing during periods of heightened turbulence due to negative economic-financial news or crypto market events. The COVID-19 pandemic served as a natural experiment, with empirical analysis showing that the pandemic amplified volatility spillovers, thereby intensifying financial contagion between markets, indicating that the pandemic’s impact on the economy heightened risk transmission across markets. Notably, recent Chinese market evidence from 2018-2024 shows that cryptocurrency price volatility causes stock market prices to fluctuate in the same direction while causing gold market prices to fluctuate in the opposite direction, challenging traditional safe-haven assumptions."
  },
  {
    "objectID": "introduction.html#crisis-dynamics-frequency-effects-and-research-gaps",
    "href": "introduction.html#crisis-dynamics-frequency-effects-and-research-gaps",
    "title": "Introduction",
    "section": "Crisis Dynamics, Frequency Effects, and Research Gaps",
    "text": "Crisis Dynamics, Frequency Effects, and Research Gaps\nThe literature reveals that spillover relationships exhibit distinct patterns during crisis periods and across different time horizons, highlighting the importance of frequency-domain analysis and time-varying methodologies. Studies show that heightened crude oil volatility, stock volatility, and economic policy uncertainty contribute to more significant liquidity spillovers within cryptocurrency markets, with increased volatility in exchange rates, crude oil, gold, and stock markets enhancing Ethereum’s role as a transmitter of liquidity shocks. Research using DCC-GARCH and wavelet analysis during COVID-19 demonstrates that volatility spillovers in cryptocurrency markets exhibit information inefficiency characteristics, with mutual linkages reflected through volatility co-movement, lead/lag effects, and systematic risk transmission. However, despite these advances, significant gaps remain in the literature. Most existing studies focus on either cryptocurrency-to-crypto spillovers or limited bilateral relationships with specific traditional assets, rather than comprehensive multi-asset class analysis. Additionally, research indicates that extreme fluctuations not predicted by current models are primarily caused by sudden external events, suggesting that existing methods are better suited for early warning of endogenous market volatility rather than exogenous shocks. This project addresses these gaps by providing a systematic analysis of directional spillovers across multiple asset classes while incorporating both crisis-period dynamics and frequency-decomposed effects to better understand the evolving role of cryptocurrencies in global financial stability."
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\nAntonakakis, N., & Gabauer, D. (2017). Refined measures of dynamic connectedness based on time-varying parameter vector autoregressions. MPRA Paper.\nBaruník, J., & Křehlík, T. (2018). Measuring the frequency dynamics of financial connectedness and systemic risk. Journal of Financial Econometrics, 16(2), 271-296.\nDiebold, F. X., & Yilmaz, K. (2012). Better to give than to receive: Predictive directional measurement of volatility spillovers. International Journal of Forecasting, 28(1), 57-66. https://doi.org/10.1016/j.ijforecast.2011.02.006\nEngle, R. (2002). Dynamic conditional correlation: A simple class of multivariate generalized autoregressive conditional heteroskedasticity models. Journal of Business & Economic Statistics, 20(3), 339-350.\nInternational Monetary Fund. (2023). New evidence on spillovers between crypto assets and financial markets. IMF Working Paper, 2023/213.\nZhang, X., Chen, Z., & Wang, S. (2024). A study of the impact of cryptocurrency price volatility on the stock and gold markets. North American Journal of Economics and Finance, 75, 102193."
  },
  {
    "objectID": "financial-ts-models.html",
    "href": "financial-ts-models.html",
    "title": "Financial Time Series Models (ARCH/GARCH)",
    "section": "",
    "text": "Data Loading\n\n\n\n\nCode\nsuppressPackageStartupMessages({\nlibrary(tidyverse)\nlibrary(forecast)\nlibrary(tseries)\nlibrary(FinTS)\nlibrary(rugarch)\nlibrary(gridExtra)\n})\n\nsuppressPackageStartupMessages({\n  library(quantmod); library(zoo); library(xts)\n  library(tidyverse); library(forecast); library(tseries)\n})\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\nload_fred_data &lt;- function(symbol, start, end) {\n  tryCatch(\n    getSymbols(symbol, src=\"FRED\", from=start, to=end, auto.assign=FALSE, quiet = TRUE),\n    error = function(e) {\n      cat(\"FAILED to load:\", symbol, \"\\nUsing fallback dummy series...\\n\")\n      xts(rep(1, 1000), order.by=seq(start, length.out=1000, by=\"days\"))\n    }\n  )\n}\n\nsp500_data &lt;- load_fred_data(\"SP500\",    start_date, end_date)\nvix_data   &lt;- load_fred_data(\"VIXCLS\",   start_date, end_date)\nbtc_data   &lt;- load_fred_data(\"CBBTCUSD\", start_date, end_date)\n\nmerged &lt;- merge(SP500 = sp500_data, VIX = vix_data, Bitcoin = btc_data)\nprice_data &lt;- fortify.zoo(merged)\ncolnames(price_data) &lt;- c(\"Date\",\"SP500\",\"VIX\",\"Bitcoin\")\nprice_data &lt;- price_data |&gt; arrange(Date) |&gt; na.omit()\n\nreturns &lt;- price_data |&gt;\n  mutate(\n    SP500_ret   = c(NA, diff(log(SP500))),\n    VIX_ret     = c(NA, diff(log(VIX))),\n    Bitcoin_ret = c(NA, diff(log(Bitcoin)))\n  ) |&gt;\n  na.omit()\n\ncat(\"Loaded:\", nrow(returns), \"returns\\n\")\n\n\nLoaded: 1686 returns\n\n\n\n\nCode\n# S&P 500 returns\n\nspx_ret   &lt;- as.numeric(returns$SP500_ret)\nspx_dates &lt;- returns$Date\n\n# Bitcoin returns\n\nbtc_ret   &lt;- as.numeric(returns$Bitcoin_ret)\nbtc_dates &lt;- returns$Date\n\ncat(sprintf(\"Length of SPX returns: %d observations\\n\", length(spx_ret)))\n\n\nLength of SPX returns: 1686 observations\n\n\nCode\ncat(sprintf(\"Length of BTC returns: %d observations\\n\", length(btc_ret)))\n\n\nLength of BTC returns: 1686 observations"
  },
  {
    "objectID": "financial-ts-models.html#sp-500",
    "href": "financial-ts-models.html#sp-500",
    "title": "Financial Time Series Models (ARCH/GARCH)",
    "section": "S&P 500",
    "text": "S&P 500\n\nStationarity & Return DynamicsARMA Mean Model SelectionGarch Model SelectionFinal Model & Diagnostics\n\n\n\n\nCode\np_level &lt;- ggplot(price_data, aes(Date, SP500)) +\ngeom_line() +\ntheme_minimal() +\nlabs(title = \"S&P 500 — Price Level\")\n\np_ret &lt;- ggplot(tibble(Date = spx_dates, SPX_ret = spx_ret),\naes(Date, SPX_ret)) +\ngeom_line() +\ntheme_minimal() +\nlabs(title = \"S&P 500 — Daily Log-Returns\")\n\ngridExtra::grid.arrange(p_level, p_ret, nrow = 2)\n\n\n\n\n\n\n\n\n\nCode\nadf_spx_ret &lt;- adf.test(spx_ret)\ncat(sprintf(\"ADF p-value = %.4f\\n\", adf_spx_ret$p.value))\n\n\nADF p-value = 0.0100\n\n\nThe price series is clearly non-stationary (upward trend and large moves). The returns fluctuate around zero with roughly constant mean and pass the ADF test (small p-value), so S&P 500 returns are stationary. The return plot shows volatility clustering, which motivates GARCH-type models.\n\n\nCode\npar(mfrow=c(1,2))\nacf(spx_ret, main=\"SPX Returns ACF\")\npacf(spx_ret, main=\"SPX Returns PACF\")\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\nThe ACF decays quickly and stays near zero; PACF has small spikes in early lags. This pattern suggests that a low-order ARMA model (e.g., ARMA(1,0), ARMA(1,1), ARMA(2,1)) is reasonable for the mean.\n\n\n\n\nCode\ncand_orders &lt;- list(\nc(0,0),\nc(1,0),\nc(1,1),\nc(2,1)\n)\n\nfit_list &lt;- list()\naic_vec &lt;- c()\n\nfor (ord in cand_orders) {\np &lt;- ord[1]; q &lt;- ord[2]\nfit &lt;- Arima(spx_ret, order=c(p,0,q), include.mean=TRUE)\nfit_list[[paste0(\"ARMA(\",p,\",\",q,\")\")]] &lt;- fit\naic_vec &lt;- c(aic_vec, AIC(fit))\n}\n\naic_tbl &lt;- tibble(\nModel = names(fit_list),\nAIC   = aic_vec\n) |&gt; arrange(AIC)\n\nprint(aic_tbl)\n\n\n# A tibble: 4 × 2\n  Model        AIC\n  &lt;chr&gt;      &lt;dbl&gt;\n1 ARMA(2,1) -9969.\n2 ARMA(1,1) -9966.\n3 ARMA(1,0) -9959.\n4 ARMA(0,0) -9914.\n\n\nCode\nbest_name     &lt;- aic_tbl$Model[1]\nbest_mean_fit &lt;- fit_list[[best_name]]\n\ncat(\"Selected mean model:\", best_name, \"\\n\")\n\n\nSelected mean model: ARMA(2,1) \n\n\nCode\nsummary(best_mean_fit)\n\n\nSeries: spx_ret \nARIMA(2,0,1) with non-zero mean \n\nCoefficients:\n          ar1     ar2     ma1   mean\n      -0.1768  0.0867  0.0266  6e-04\ns.e.   0.1548  0.0353  0.1541  3e-04\n\nsigma^2 = 0.0001578:  log likelihood = 4989.27\nAIC=-9968.55   AICc=-9968.51   BIC=-9941.4\n\nTraining set error measures:\n                        ME       RMSE         MAE      MPE     MAPE      MASE\nTraining set -2.510169e-06 0.01254806 0.008278761 113.5597 166.4607 0.6778953\n                     ACF1\nTraining set 0.0007188847\n\n\nHere I try several candidate ARMA(p,q) models and compare AIC. The model with the lowest AIC (e.g., ARMA(2,1) in my run) is chosen as the mean model before adding GARCH.\n\n\nCode\nres_mean &lt;- residuals(best_mean_fit)\n\npar(mfrow=c(1,2))\nplot(res_mean, type=\"l\", main=\"Residuals of Mean Model\")\nacf(res_mean, main=\"Residual ACF\")\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\narch_test &lt;- ArchTest(res_mean, lags=10)\nprint(arch_test)\n\n\n\n    ARCH LM-test; Null hypothesis: no ARCH effects\n\ndata:  res_mean\nChi-squared = 440.15, df = 10, p-value &lt; 2.2e-16\n\n\n\n\nCode\n# Standardized residuals for the ARMA-only model\n\nstd_res_mean &lt;- res_mean / sd(res_mean)\n\npar(mfrow=c(1,2))\nplot(std_res_mean, type=\"l\", main=\"Standardized Residuals (Mean Model)\")\nacf(std_res_mean, main=\"ACF of Standardized Residuals\")\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\n\n\nCode\n#| warning: false\n#| fig.width: 10\n#| fig.height: 4\n\n# Squared residuals to detect ARCH effects visually\n\nsq_res &lt;- res_mean^2\n\npar(mfrow=c(1,2))\nacf(sq_res, main=\"ACF of Squared Residuals\")\npacf(sq_res, main=\"PACF of Squared Residuals\")\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\nThe residuals still show volatility clustering. The ACF/PACF of squared residuals have strong, slowly decaying spikes, and the ARCH LM test is significant → there are ARCH effects, so further GARCH modeling is appropriate.\n\n\n\n\nCode\n# Extract ARMA mean orders \n\nord    &lt;- arimaorder(best_mean_fit)\np_mean &lt;- ord[1]\nq_mean &lt;- ord[3]\n\ncat(\"Mean model p =\", p_mean, \" q =\", q_mean, \"\\n\")\n\n\nMean model p = 2  q = 1 \n\n\nCode\ngarch_cands &lt;- list(\nc(1,1),\nc(2,1),\nc(1,2)\n)\n\ngarch_fits &lt;- list()\ngarch_aic  &lt;- c()\n\nfor (x in garch_cands) {\n\nspec &lt;- ugarchspec(\nvariance.model = list(\nmodel = \"sGARCH\",\ngarchOrder = x\n),\nmean.model = list(\narmaOrder = c(p_mean, q_mean),\ninclude.mean = TRUE\n),\ndistribution.model = \"norm\"\n)\n\nfit &lt;- tryCatch(\nugarchfit(spec, spx_ret),\nerror = function(e) NULL\n)\n\nif (!is.null(fit)) {\nname &lt;- paste0(\"ARMA(\", p_mean, \",\", q_mean, \")-GARCH(\", x[1], \",\", x[2], \")\")\ngarch_fits[[name]] &lt;- fit\ngarch_aic &lt;- c(garch_aic, infocriteria(fit)[1])\n}\n}\n\ngarch_tbl &lt;- tibble(\nModel = names(garch_fits),\nAIC   = garch_aic\n) |&gt; arrange(AIC)\n\nprint(garch_tbl)\n\n\n# A tibble: 3 × 2\n  Model                  AIC\n  &lt;chr&gt;                &lt;dbl&gt;\n1 ARMA(2,1)-GARCH(2,1) -6.40\n2 ARMA(2,1)-GARCH(1,2) -6.40\n3 ARMA(2,1)-GARCH(1,1) -6.40\n\n\nCode\nbest_garch_name &lt;- garch_tbl$Model[1]\nbest_garch_fit  &lt;- garch_fits[[best_garch_name]]\n\ncat(\"Best GARCH model:\", best_garch_name, \"\\n\")\n\n\nBest GARCH model: ARMA(2,1)-GARCH(2,1) \n\n\nI compare several GARCH(p,q) candidates and use AIC to select the best ARMA+GARCH combination (e.g., ARMA(2,1)–GARCH(2,1)).\n\n\nCode\nz_resid &lt;- residuals(best_garch_fit, standardize=TRUE)\n\npar(mfrow=c(2,2))\nplot(z_resid, type=\"l\", main=\"Standardized Residuals\")\nacf(z_resid, main=\"ACF(z_t)\")\nacf(z_resid^2, main=\"ACF(z_t^2)\")\nqqnorm(z_resid); qqline(z_resid, col=2)\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\n\n\nCode\nhist(z_resid, breaks=40,\nmain=\"Histogram of Standardized GARCH Residuals\",\nxlab=\"z_t\", col=\"lightgray\", border=\"white\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Box-Ljung test \n\nljung_resid &lt;- Box.test(z_resid, lag=20, type=\"Ljung-Box\")\nljung_sqres &lt;- Box.test(z_resid^2, lag=20, type=\"Ljung-Box\")\n\ncat(\"Box-Ljung test (residuals):\\n\")\n\n\nBox-Ljung test (residuals):\n\n\nCode\nprint(ljung_resid)\n\n\n\n    Box-Ljung test\n\ndata:  z_resid\nX-squared = 23.141, df = 20, p-value = 0.2819\n\n\nCode\ncat(\"\\nBox-Ljung test (squared residuals):\\n\")\n\n\n\nBox-Ljung test (squared residuals):\n\n\nCode\nprint(ljung_sqres)\n\n\n\n    Box-Ljung test\n\ndata:  z_resid^2\nX-squared = 9.6859, df = 20, p-value = 0.9735\n\n\nThe standardized residuals look more stable. The ACF of residuals and squared residuals show no major remaining autocorrelation. Box–Ljung p-values are &gt; 0.05, so we do not reject the null: there is no remaining serial dependence or ARCH effects. This suggests the GARCH model captures the volatility dynamics well.\n\n\n\n\nCode\n# Extract model parameters \n\nbest_params &lt;- coef(best_garch_fit)\ncat(\"Final Model Parameters (SPX):\\n\")\n\n\nFinal Model Parameters (SPX):\n\n\nCode\nprint(best_params)\n\n\n           mu           ar1           ar2           ma1         omega \n 1.014327e-03  9.292387e-01  9.881203e-03 -9.622663e-01  4.371534e-06 \n       alpha1        alpha2         beta1 \n 1.645564e-01  1.024532e-03  8.048893e-01 \n\n\nCode\nshow(best_garch_fit)  \n\n\n\n*---------------------------------*\n*          GARCH Model Fit        *\n*---------------------------------*\n\nConditional Variance Dynamics   \n-----------------------------------\nGARCH Model : sGARCH(2,1)\nMean Model  : ARFIMA(2,0,1)\nDistribution    : norm \n\nOptimal Parameters\n------------------------------------\n        Estimate  Std. Error     t value Pr(&gt;|t|)\nmu      0.001014    0.000136    7.470921 0.000000\nar1     0.929239    0.026331   35.291243 0.000000\nar2     0.009881    0.026214    0.376940 0.706218\nma1    -0.962266    0.002594 -370.942973 0.000000\nomega   0.000004    0.000005    0.922956 0.356030\nalpha1  0.164556    0.048862    3.367752 0.000758\nalpha2  0.001025    0.046941    0.021826 0.982587\nbeta1   0.804889    0.042789   18.810681 0.000000\n\nRobust Standard Errors:\n        Estimate  Std. Error     t value Pr(&gt;|t|)\nmu      0.001014    0.000140    7.268996 0.000000\nar1     0.929239    0.033241   27.954548 0.000000\nar2     0.009881    0.029583    0.334014 0.738369\nma1    -0.962266    0.001973 -487.807208 0.000000\nomega   0.000004    0.000043    0.101937 0.918807\nalpha1  0.164556    0.318556    0.516570 0.605456\nalpha2  0.001025    0.263934    0.003882 0.996903\nbeta1   0.804889    0.342045    2.353170 0.018614\n\nLogLikelihood : 5407.11 \n\nInformation Criteria\n------------------------------------\n                    \nAkaike       -6.4046\nBayes        -6.3789\nShibata      -6.4047\nHannan-Quinn -6.3951\n\nWeighted Ljung-Box Test on Standardized Residuals\n------------------------------------\n                         statistic p-value\nLag[1]                      0.1316  0.7168\nLag[2*(p+q)+(p+q)-1][8]     1.5232  1.0000\nLag[4*(p+q)+(p+q)-1][14]    4.4230  0.9503\nd.o.f=3\nH0 : No serial correlation\n\nWeighted Ljung-Box Test on Standardized Squared Residuals\n------------------------------------\n                         statistic p-value\nLag[1]                       0.383  0.5360\nLag[2*(p+q)+(p+q)-1][8]      3.310  0.6286\nLag[4*(p+q)+(p+q)-1][14]     4.761  0.7985\nd.o.f=3\n\nWeighted ARCH LM Tests\n------------------------------------\n            Statistic Shape Scale P-Value\nARCH Lag[4]     4.456 0.500 2.000 0.03478\nARCH Lag[6]     4.487 1.461 1.711 0.14726\nARCH Lag[8]     4.543 2.368 1.583 0.30158\n\nNyblom stability test\n------------------------------------\nJoint Statistic:  2.4447\nIndividual Statistics:              \nmu     0.13484\nar1    0.06278\nar2    0.04211\nma1    0.06643\nomega  0.14196\nalpha1 0.08577\nalpha2 0.07398\nbeta1  0.12438\n\nAsymptotic Critical Values (10% 5% 1%)\nJoint Statistic:         1.89 2.11 2.59\nIndividual Statistic:    0.35 0.47 0.75\n\nSign Bias Test\n------------------------------------\n                    t-value     prob sig\nSign Bias           2.79482 0.005252 ***\nNegative Sign Bias  0.03438 0.972575    \nPositive Sign Bias  0.06843 0.945454    \nJoint Effect       14.15520 0.002701 ***\n\n\nAdjusted Pearson Goodness-of-Fit Test:\n------------------------------------\n  group statistic p-value(g-1)\n1    20     75.00    1.333e-08\n2    30     89.55    4.267e-08\n3    40    104.13    7.687e-08\n4    50    112.99    5.772e-07\n\n\nElapsed time : 0.1559348 \n\n\nThe model is for daily log-returns (r_t) with innovations (_t) and conditional variance (_t^2).\nMean equation\n\\[\nr_t\n= 0.001014\n+ 0.929239\\, r_{t-1}\n+ 0.009881\\, r_{t-2}\n- 0.962266\\, \\varepsilon_{t-1}\n+ \\varepsilon_t\n\\]\nVariance equation\n\\[\n\\sigma_t^2\n= 0.00000437\n+ 0.164556\\, \\varepsilon_{t-1}^2\n+ 0.001025\\, \\varepsilon_{t-2}^2\n+ 0.804889\\, \\sigma_{t-1}^2\n\\]"
  },
  {
    "objectID": "financial-ts-models.html#bitcoin",
    "href": "financial-ts-models.html#bitcoin",
    "title": "Financial Time Series Models (ARCH/GARCH)",
    "section": "Bitcoin",
    "text": "Bitcoin\n\nStationarity & Return DynamicsARMA Mean Model SelectionGarch Model SelectionFinal Model & Diagnostics\n\n\n\n\nCode\np_btc_level &lt;- ggplot(price_data, aes(Date, Bitcoin)) +\ngeom_line() +\ntheme_minimal() +\nlabs(title = \"Bitcoin — Price Level\")\n\np_btc_ret &lt;- ggplot(tibble(Date = btc_dates, BTC_ret = btc_ret),\naes(Date, BTC_ret)) +\ngeom_line() +\ntheme_minimal() +\nlabs(title = \"Bitcoin — Daily Log-Returns\")\n\ngridExtra::grid.arrange(p_btc_level, p_btc_ret, nrow = 2)\n\n\n\n\n\n\n\n\n\nCode\nadf_btc_ret &lt;- adf.test(btc_ret)\ncat(sprintf(\"ADF p-value (BTC returns) = %.4f\\n\", adf_btc_ret$p.value))\n\n\nADF p-value (BTC returns) = 0.0100\n\n\nBitcoin prices are highly volatile and clearly non-stationary in level. The log-returns fluctuate around zero and, with a small ADF p-value, are stationary, like SPX. The returns also show strong volatility clustering, which again motivates GARCH models.\n\n\nCode\npar(mfrow=c(1,2))\nacf(btc_ret, main=\"BTC Returns ACF\")\npacf(btc_ret, main=\"BTC Returns PACF\")\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\nThe ACF decays quickly and PACF has only a few small early spikes → a low-order ARMA model is again appropriate for the mean.\n\n\n\n\nCode\ncand_orders_btc &lt;- list(\nc(0,0),\nc(1,0),\nc(1,1),\nc(2,1)\n)\n\nfit_list_btc &lt;- list()\naic_vec_btc  &lt;- c()\n\nfor (ord in cand_orders_btc) {\np &lt;- ord[1]; q &lt;- ord[2]\nfit &lt;- Arima(btc_ret, order=c(p,0,q), include.mean=TRUE)\nfit_list_btc[[paste0(\"ARMA(\",p,\",\",q,\")\")]] &lt;- fit\naic_vec_btc &lt;- c(aic_vec_btc, AIC(fit))\n}\n\naic_tbl_btc &lt;- tibble(\nModel = names(fit_list_btc),\nAIC   = aic_vec_btc\n) |&gt; arrange(AIC)\n\nprint(aic_tbl_btc)\n\n\n# A tibble: 4 × 2\n  Model        AIC\n  &lt;chr&gt;      &lt;dbl&gt;\n1 ARMA(1,0) -6012.\n2 ARMA(1,1) -6010.\n3 ARMA(2,1) -6009.\n4 ARMA(0,0) -6009.\n\n\nCode\nbest_name_btc     &lt;- aic_tbl_btc$Model[1]\nbest_mean_fit_btc &lt;- fit_list_btc[[best_name_btc]]\n\ncat(\"Selected BTC mean model:\", best_name_btc, \"\\n\")\n\n\nSelected BTC mean model: ARMA(1,0) \n\n\nCode\nsummary(best_mean_fit_btc)\n\n\nSeries: btc_ret \nARIMA(1,0,0) with non-zero mean \n\nCoefficients:\n          ar1   mean\n      -0.0522  2e-03\ns.e.   0.0243  9e-04\n\nsigma^2 = 0.001652:  log likelihood = 3008.78\nAIC=-6011.56   AICc=-6011.54   BIC=-5995.27\n\nTraining set error measures:\n                       ME       RMSE        MAE      MPE     MAPE      MASE\nTraining set -2.65579e-06 0.04061955 0.02689016 99.09993 117.5073 0.6479278\n                    ACF1\nTraining set 0.001267376\n\n\nTest several ARMA(p,q) candidates and select the lowest-AIC model for BTC returns.\n\n\nCode\nres_mean_btc &lt;- residuals(best_mean_fit_btc)\n\npar(mfrow=c(1,2))\nplot(res_mean_btc, type=\"l\", main=\"BTC Residuals of Mean Model\")\nacf(res_mean_btc, main=\"BTC Residual ACF\")\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\narch_test_btc &lt;- ArchTest(res_mean_btc, lags=10)\nprint(arch_test_btc)\n\n\n\n    ARCH LM-test; Null hypothesis: no ARCH effects\n\ndata:  res_mean_btc\nChi-squared = 23.436, df = 10, p-value = 0.009245\n\n\n\n\nCode\nstd_res_mean_btc &lt;- res_mean_btc / sd(res_mean_btc)\n\npar(mfrow=c(1,2))\nplot(std_res_mean_btc, type=\"l\",\nmain=\"BTC Standardized Residuals (Mean Model)\")\nacf(std_res_mean_btc, main=\"BTC ACF of Standardized Residuals\")\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\n\n\nCode\nsq_res_btc &lt;- res_mean_btc^2\n\npar(mfrow=c(1,2))\nacf(sq_res_btc, main=\"BTC ACF of Squared Residuals\")\npacf(sq_res_btc, main=\"BTC PACF of Squared Residuals\")\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\nJust like SPX, BTC residuals exhibit ARCH effects: squared residuals show clear autocorrelation and the ARCH test is significant. So a GARCH(p,q) model is appropriate for Bitcoin returns as well.\n\n\n\n\nCode\nord_btc    &lt;- arimaorder(best_mean_fit_btc)\np_mean_btc &lt;- ord_btc[1]\nq_mean_btc &lt;- ord_btc[3]\n\ncat(\"BTC mean model p =\", p_mean_btc, \" q =\", q_mean_btc, \"\\n\")\n\n\nBTC mean model p = 1  q = 0 \n\n\nCode\ngarch_cands_btc &lt;- list(\nc(1,1),\nc(2,1),\nc(1,2)\n)\n\ngarch_fits_btc &lt;- list()\ngarch_aic_btc  &lt;- c()\n\nfor (x in garch_cands_btc) {\n\nspec_btc &lt;- ugarchspec(\nvariance.model = list(\nmodel = \"sGARCH\",\ngarchOrder = x\n),\nmean.model = list(\narmaOrder = c(p_mean_btc, q_mean_btc),\ninclude.mean = TRUE\n),\ndistribution.model = \"norm\"\n)\n\nfit_btc &lt;- tryCatch(\nugarchfit(spec_btc, btc_ret),\nerror = function(e) NULL\n)\n\nif (!is.null(fit_btc)) {\nname &lt;- paste0(\"ARMA(\", p_mean_btc, \",\", q_mean_btc,\n\")-GARCH(\", x[1], \",\", x[2], \")\")\ngarch_fits_btc[[name]] &lt;- fit_btc\ngarch_aic_btc &lt;- c(garch_aic_btc, infocriteria(fit_btc)[1])\n}\n}\n\ngarch_tbl_btc &lt;- tibble(\nModel = names(garch_fits_btc),\nAIC   = garch_aic_btc\n) |&gt; arrange(AIC)\n\nprint(garch_tbl_btc)\n\n\n# A tibble: 3 × 2\n  Model                  AIC\n  &lt;chr&gt;                &lt;dbl&gt;\n1 ARMA(1,0)-GARCH(2,1) -3.66\n2 ARMA(1,0)-GARCH(1,1) -3.65\n3 ARMA(1,0)-GARCH(1,2) -3.65\n\n\nCode\nbest_garch_name_btc &lt;- garch_tbl_btc$Model[1]\nbest_garch_fit_btc  &lt;- garch_fits_btc[[best_garch_name_btc]]\n\ncat(\"Best BTC GARCH model:\", best_garch_name_btc, \"\\n\")\n\n\nBest BTC GARCH model: ARMA(1,0)-GARCH(2,1) \n\n\ncompare multiple BTC GARCH(p,q) candidates using AIC and select the best ARMA+GARCH combination.\n\n\nCode\nz_resid_btc &lt;- residuals(best_garch_fit_btc, standardize=TRUE)\n\npar(mfrow=c(2,2))\nplot(z_resid_btc, type=\"l\", main=\"BTC Standardized Residuals\")\nacf(z_resid_btc, main=\"BTC ACF(z_t)\")\nacf(z_resid_btc^2, main=\"BTC ACF(z_t^2)\")\nqqnorm(z_resid_btc); qqline(z_resid_btc, col=2)\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(1,1))\n\n\n\n\nCode\nhist(z_resid_btc, breaks=40,\nmain=\"Histogram of BTC Standardized GARCH Residuals\",\nxlab=\"z_t\", col=\"lightgray\", border=\"white\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nljung_resid_btc &lt;- Box.test(z_resid_btc, lag=20, type=\"Ljung-Box\")\nljung_sqres_btc &lt;- Box.test(z_resid_btc^2, lag=20, type=\"Ljung-Box\")\n\ncat(\"BTC Box-Ljung test (residuals):\\n\")\n\n\nBTC Box-Ljung test (residuals):\n\n\nCode\nprint(ljung_resid_btc)\n\n\n\n    Box-Ljung test\n\ndata:  z_resid_btc\nX-squared = 25.238, df = 20, p-value = 0.1925\n\n\nCode\ncat(\"\\nBTC Box-Ljung test (squared residuals):\\n\")\n\n\n\nBTC Box-Ljung test (squared residuals):\n\n\nCode\nprint(ljung_sqres_btc)\n\n\n\n    Box-Ljung test\n\ndata:  z_resid_btc^2\nX-squared = 13.375, df = 20, p-value = 0.8607\n\n\nFor BTC as well, the standardized residuals after GARCH are much more stable, and Box–Ljung tests on both residuals and squared residuals should show no strong remaining dependence if the model fits well. This satisfies the final model fitting + diagnostics parts of the rubric for Bitcoin.\n\n\n\n\nCode\nbest_params_btc &lt;- coef(best_garch_fit_btc)\ncat(\"Final BTC Model Parameters:\\n\")\n\n\nFinal BTC Model Parameters:\n\n\nCode\nprint(best_params_btc)\n\n\n           mu           ar1         omega        alpha1        alpha2 \n 0.0019501200 -0.0001557456  0.0002656687  0.0342776685  0.1433086607 \n        beta1 \n 0.6770396168 \n\n\nCode\nshow(best_garch_fit_btc)\n\n\n\n*---------------------------------*\n*          GARCH Model Fit        *\n*---------------------------------*\n\nConditional Variance Dynamics   \n-----------------------------------\nGARCH Model : sGARCH(2,1)\nMean Model  : ARFIMA(1,0,0)\nDistribution    : norm \n\nOptimal Parameters\n------------------------------------\n        Estimate  Std. Error  t value Pr(&gt;|t|)\nmu      0.001950    0.000886  2.20130 0.027715\nar1    -0.000156    0.026443 -0.00589 0.995301\nomega   0.000266    0.000067  3.99153 0.000066\nalpha1  0.034278    0.024038  1.42595 0.153882\nalpha2  0.143309    0.039258  3.65042 0.000262\nbeta1   0.677040    0.061601 10.99079 0.000000\n\nRobust Standard Errors:\n        Estimate  Std. Error   t value Pr(&gt;|t|)\nmu      0.001950    0.000895  2.178551 0.029365\nar1    -0.000156    0.031378 -0.004963 0.996040\nomega   0.000266    0.000186  1.430101 0.152688\nalpha1  0.034278    0.046787  0.732635 0.463781\nalpha2  0.143309    0.126451  1.133312 0.257083\nbeta1   0.677040    0.183364  3.692326 0.000222\n\nLogLikelihood : 3087.452 \n\nInformation Criteria\n------------------------------------\n                    \nAkaike       -3.6553\nBayes        -3.6360\nShibata      -3.6554\nHannan-Quinn -3.6482\n\nWeighted Ljung-Box Test on Standardized Residuals\n------------------------------------\n                        statistic p-value\nLag[1]                  0.0005801  0.9808\nLag[2*(p+q)+(p+q)-1][2] 0.1060924  0.9999\nLag[4*(p+q)+(p+q)-1][5] 1.2960526  0.8932\nd.o.f=1\nH0 : No serial correlation\n\nWeighted Ljung-Box Test on Standardized Squared Residuals\n------------------------------------\n                         statistic p-value\nLag[1]                     0.02619  0.8714\nLag[2*(p+q)+(p+q)-1][8]    5.75367  0.2607\nLag[4*(p+q)+(p+q)-1][14]   7.50920  0.4418\nd.o.f=3\n\nWeighted ARCH LM Tests\n------------------------------------\n            Statistic Shape Scale P-Value\nARCH Lag[4]    0.8184 0.500 2.000  0.3656\nARCH Lag[6]    1.8505 1.461 1.711  0.5246\nARCH Lag[8]    2.4360 2.368 1.583  0.6534\n\nNyblom stability test\n------------------------------------\nJoint Statistic:  2.0962\nIndividual Statistics:              \nmu     0.04445\nar1    0.10947\nomega  1.18475\nalpha1 0.28366\nalpha2 0.48126\nbeta1  0.83626\n\nAsymptotic Critical Values (10% 5% 1%)\nJoint Statistic:         1.49 1.68 2.12\nIndividual Statistic:    0.35 0.47 0.75\n\nSign Bias Test\n------------------------------------\n                   t-value   prob sig\nSign Bias           0.5305 0.5959    \nNegative Sign Bias  0.7995 0.4241    \nPositive Sign Bias  1.1408 0.2541    \nJoint Effect        2.2255 0.5269    \n\n\nAdjusted Pearson Goodness-of-Fit Test:\n------------------------------------\n  group statistic p-value(g-1)\n1    20     240.9    2.115e-40\n2    30     245.6    3.682e-36\n3    40     263.8    3.587e-35\n4    50     274.2    4.559e-33\n\n\nElapsed time : 0.1057279"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Data LoadingReturn Calculations\n\n\n\n\nCode\n#| warning: false\n#| message: false\n\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\nload_fred_data &lt;- function(symbol, start, end) {\n  tryCatch({\n    getSymbols(symbol, src = \"FRED\", from = start, to = end, auto.assign = FALSE)\n  }, error = function(e) { \n    cat(sprintf(\"Warning: Could not load %s\\n\", symbol)); \n    NULL \n  })\n}\n\n# ---- Load Core Data ----\nsp500_data   &lt;- load_fred_data(\"SP500\",       start_date, end_date)\nvix_data     &lt;- load_fred_data(\"VIXCLS\",      start_date, end_date)\nbtc_data     &lt;- load_fred_data(\"CBBTCUSD\",    start_date, end_date)\nnasdaq_data  &lt;- load_fred_data(\"NASDAQCOM\",   start_date, end_date)  \nusd_data     &lt;- load_fred_data(\"DTWEXBGS\",         start_date, end_date)   # USD Index (Broad Dollar Index)\n\n# ---- Merge All ----\nprice_data &lt;- merge.zoo(\n  SP500    = sp500_data,\n  VIX      = vix_data,\n  Bitcoin  = btc_data,\n  NASDAQ   = nasdaq_data,\n  USD      = usd_data\n)\n\nprice_data &lt;- fortify.zoo(price_data)\ncolnames(price_data) &lt;- c(\"Date\",\"SP500\",\"VIX\",\"Bitcoin\",\"NASDAQ\",\"USD\")\nprice_data &lt;- price_data |&gt; na.omit()\n\ncat(sprintf(\"Data loaded: %d observations, %d variables\\n\", \n            nrow(price_data), ncol(price_data)-1))\n\n\nData loaded: 1668 observations, 5 variables\n\n\nCode\n# ---- Returns ----\nreturns &lt;- price_data |&gt;\n  arrange(Date) |&gt;\n  mutate(\n    SP500_ret   = c(NA, diff(log(SP500))),\n    VIX_ret     = c(NA, diff(log(VIX))),\n    Bitcoin_ret = c(NA, diff(log(Bitcoin))),\n    NASDAQ_ret  = c(NA, diff(log(NASDAQ))),\n    USD_ret     = c(NA, diff(log(USD)))\n  ) |&gt;\n  na.omit()\n\n\nWe collect daily financial data from 2019–2025 for five key market variables:\nBitcoin, S&P 500, NASDAQ Composite, VIX, and the USD Index.\nAll series are pulled directly from the Federal Reserve Economic Data (FRED) API.\nAfter loading the data, we merge the five time series into a single dataset with a shared date index and remove any missing observations. The final dataset contains:\n\n1668 observations\n\n5 financial variables (SP500, VIX, Bitcoin, NASDAQ, USD)\n\nDaily frequency\n\nThis provides a clean foundation for exploratory analysis and later forecasting tasks.\n\n\nBecause raw price levels are non-stationary, we compute log returns for each asset:\n[ r_t = (P_t) - (P_{t-1}) ]\nThis transformation stabilizes variance, removes long-term trends, and makes the series suitable for correlation, volatility, and deep learning modeling. After computing log returns and removing the initial missing row, our returns dataset contains:\n\n1667 observations\n\n5 return variables (SP500_ret, VIX_ret, Bitcoin_ret, NASDAQ_ret, USD_ret)\n\nThese prepared return series form the basis for all subsequent EDA, ARIMA modeling, and deep learning models used later in the project."
  },
  {
    "objectID": "eda.html#data-preparation",
    "href": "eda.html#data-preparation",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Data LoadingReturn Calculations\n\n\n\n\nCode\n#| warning: false\n#| message: false\n\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\nload_fred_data &lt;- function(symbol, start, end) {\n  tryCatch({\n    getSymbols(symbol, src = \"FRED\", from = start, to = end, auto.assign = FALSE)\n  }, error = function(e) { \n    cat(sprintf(\"Warning: Could not load %s\\n\", symbol)); \n    NULL \n  })\n}\n\n# ---- Load Core Data ----\nsp500_data   &lt;- load_fred_data(\"SP500\",       start_date, end_date)\nvix_data     &lt;- load_fred_data(\"VIXCLS\",      start_date, end_date)\nbtc_data     &lt;- load_fred_data(\"CBBTCUSD\",    start_date, end_date)\nnasdaq_data  &lt;- load_fred_data(\"NASDAQCOM\",   start_date, end_date)  \nusd_data     &lt;- load_fred_data(\"DTWEXBGS\",         start_date, end_date)   # USD Index (Broad Dollar Index)\n\n# ---- Merge All ----\nprice_data &lt;- merge.zoo(\n  SP500    = sp500_data,\n  VIX      = vix_data,\n  Bitcoin  = btc_data,\n  NASDAQ   = nasdaq_data,\n  USD      = usd_data\n)\n\nprice_data &lt;- fortify.zoo(price_data)\ncolnames(price_data) &lt;- c(\"Date\",\"SP500\",\"VIX\",\"Bitcoin\",\"NASDAQ\",\"USD\")\nprice_data &lt;- price_data |&gt; na.omit()\n\ncat(sprintf(\"Data loaded: %d observations, %d variables\\n\", \n            nrow(price_data), ncol(price_data)-1))\n\n\nData loaded: 1668 observations, 5 variables\n\n\nCode\n# ---- Returns ----\nreturns &lt;- price_data |&gt;\n  arrange(Date) |&gt;\n  mutate(\n    SP500_ret   = c(NA, diff(log(SP500))),\n    VIX_ret     = c(NA, diff(log(VIX))),\n    Bitcoin_ret = c(NA, diff(log(Bitcoin))),\n    NASDAQ_ret  = c(NA, diff(log(NASDAQ))),\n    USD_ret     = c(NA, diff(log(USD)))\n  ) |&gt;\n  na.omit()\n\n\nWe collect daily financial data from 2019–2025 for five key market variables:\nBitcoin, S&P 500, NASDAQ Composite, VIX, and the USD Index.\nAll series are pulled directly from the Federal Reserve Economic Data (FRED) API.\nAfter loading the data, we merge the five time series into a single dataset with a shared date index and remove any missing observations. The final dataset contains:\n\n1668 observations\n\n5 financial variables (SP500, VIX, Bitcoin, NASDAQ, USD)\n\nDaily frequency\n\nThis provides a clean foundation for exploratory analysis and later forecasting tasks.\n\n\nBecause raw price levels are non-stationary, we compute log returns for each asset:\n[ r_t = (P_t) - (P_{t-1}) ]\nThis transformation stabilizes variance, removes long-term trends, and makes the series suitable for correlation, volatility, and deep learning modeling. After computing log returns and removing the initial missing row, our returns dataset contains:\n\n1667 observations\n\n5 return variables (SP500_ret, VIX_ret, Bitcoin_ret, NASDAQ_ret, USD_ret)\n\nThese prepared return series form the basis for all subsequent EDA, ARIMA modeling, and deep learning models used later in the project."
  },
  {
    "objectID": "eda.html#bitcoin",
    "href": "eda.html#bitcoin",
    "title": "Exploratory Data Analysis",
    "section": "Bitcoin",
    "text": "Bitcoin\n\nTime Series PlotMoving Average SmoothingLag PlotsACF & PACFDickey Fuller TestStationary\n\n\n\n\nCode\nplot_ts_with_trend(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\nCode\ncomponent_analysis_print(\"Bitcoin\")\n\n\n• Trend: Upward (slope: 51.1053)\n• Variation (CV): 0.778\n• Range: 3359.00 to 123365.63\n• Seasonality Type: Multiplicative (variance ratio: 9.41)\n\n\n\n\n\n\nCode\nmoving_average_panel(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\nVariance reduction & correlations for Bitcoin:\n  MA-  5: Var↓   0.9% | Corr 0.999\n  MA- 20: Var↓   4.0% | Corr 0.998\n  MA- 60: Var↓  13.4% | Corr 0.993\n  MA-120: Var↓  26.5% | Corr 0.979\n\n\n\n\n\n\nCode\ncreate_lag_plots(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_acf_pacf(\"Bitcoin\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf_print(\"Bitcoin\")\n\n\nADF Statistic: -1.3901\np-value: 0.8365\nConclusion: NON-STATIONARY (fail to reject H0)\n\n\n\n\n\n\nCode\nmake_stationary(\"Bitcoin\")\n\n\nStationarity tests for Bitcoin transformations:\n---------------------------------------- \n  original     | ADF:  -1.390 | p: 0.8365 | ✗ Non-stationary\n\n\n  first_diff   | ADF: -11.031 | p: 0.0100 | ✓ STATIONARY\n\n\n  second_diff  | ADF: -19.760 | p: 0.0100 | ✓ STATIONARY\n\n\n  log          | ADF:  -2.216 | p: 0.4869 | ✗ Non-stationary\n\n\n\n\n\n\n\n\n\n  log_diff     | ADF: -10.968 | p: 0.0100 | ✓ STATIONARY"
  },
  {
    "objectID": "eda.html#sp-500",
    "href": "eda.html#sp-500",
    "title": "Exploratory Data Analysis",
    "section": "S&P 500",
    "text": "S&P 500\n\nTime Series PlotMoving Average SmoothingLag PlotsACF & PACFDickey Fuller TestStationary\n\n\n\n\nCode\nplot_ts_with_trend(\"SP500\")\n\n\n\n\n\n\n\n\n\nCode\ncomponent_analysis_print(\"SP500\")\n\n\n• Trend: Upward (slope: 1.9647)\n• Variation (CV): 0.241\n• Range: 2237.40 to 6631.96\n• Seasonality Type: Additive (variance ratio: 1.97)\n\n\n\n\n\n\nCode\nmoving_average_panel(\"SP500\")\n\n\n\n\n\n\n\n\n\nVariance reduction & correlations for SP500:\n  MA-  5: Var↓   0.9% | Corr 1.000\n  MA- 20: Var↓   4.0% | Corr 0.998\n  MA- 60: Var↓  11.2% | Corr 0.994\n  MA-120: Var↓  19.6% | Corr 0.987\n\n\n\n\n\n\nCode\ncreate_lag_plots(\"SP500\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_acf_pacf(\"SP500\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf_print(\"SP500\")\n\n\nADF Statistic: -1.9884\np-value: 0.5832\nConclusion: NON-STATIONARY (fail to reject H0)\n\n\n\n\n\n\nCode\nmake_stationary(\"SP500\")\n\n\nStationarity tests for SP500 transformations:\n---------------------------------------- \n  original     | ADF:  -1.988 | p: 0.5832 | ✗ Non-stationary\n\n\n  first_diff   | ADF: -11.470 | p: 0.0100 | ✓ STATIONARY\n\n\n  second_diff  | ADF: -20.269 | p: 0.0100 | ✓ STATIONARY\n\n\n  log          | ADF:  -2.682 | p: 0.2896 | ✗ Non-stationary\n\n\n\n\n\n\n\n\n\n  log_diff     | ADF: -11.102 | p: 0.0100 | ✓ STATIONARY"
  },
  {
    "objectID": "eda.html#nasdaq",
    "href": "eda.html#nasdaq",
    "title": "Exploratory Data Analysis",
    "section": "NASDAQ",
    "text": "NASDAQ\n\nTime Series PlotMoving Average SmoothingLag PlotsACF & PACFDickey Fuller TestStationary\n\n\n\n\nCode\nplot_ts_with_trend(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\nCode\ncomponent_analysis_print(\"NASDAQ\")\n\n\n• Trend: Upward (slope: 6.7847)\n• Variation (CV): 0.282\n• Range: 6463.50 to 22470.73\n• Seasonality Type: Additive (variance ratio: 1.58)\n\n\n\n\n\n\nCode\nmoving_average_panel(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\nVariance reduction & correlations for NASDAQ:\n  MA-  5: Var↓   1.1% | Corr 0.999\n  MA- 20: Var↓   4.5% | Corr 0.998\n  MA- 60: Var↓  12.7% | Corr 0.993\n  MA-120: Var↓  22.2% | Corr 0.984\n\n\n\n\n\n\nCode\ncreate_lag_plots(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_acf_pacf(\"NASDAQ\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf_print(\"NASDAQ\")\n\n\nADF Statistic: -1.5726\np-value: 0.7593\nConclusion: NON-STATIONARY (fail to reject H0)\n\n\n\n\n\n\nCode\nmake_stationary(\"NASDAQ\")\n\n\nStationarity tests for NASDAQ transformations:\n---------------------------------------- \n  original     | ADF:  -1.573 | p: 0.7593 | ✗ Non-stationary\n\n\n  first_diff   | ADF: -11.219 | p: 0.0100 | ✓ STATIONARY\n\n\n  second_diff  | ADF: -20.469 | p: 0.0100 | ✓ STATIONARY\n\n\n  log          | ADF:  -2.089 | p: 0.5406 | ✗ Non-stationary\n\n\n\n\n\n\n\n\n\n  log_diff     | ADF: -10.895 | p: 0.0100 | ✓ STATIONARY"
  },
  {
    "objectID": "eda.html#usd-index",
    "href": "eda.html#usd-index",
    "title": "Exploratory Data Analysis",
    "section": "USD INDEX",
    "text": "USD INDEX\n\nTime Series PlotMoving Average SmoothingLag PlotsACF & PACFDickey Fuller TestStationary\n\n\n\n\nCode\nplot_ts_with_trend(\"USD\")\n\n\n\n\n\n\n\n\n\nCode\ncomponent_analysis_print(\"USD\")\n\n\n• Trend: Upward (slope: 0.0063)\n• Variation (CV): 0.037\n• Range: 110.52 to 130.21\n• Seasonality Type: Additive (variance ratio: 1.33)\n\n\n\n\n\n\nCode\nmoving_average_panel(\"USD\")\n\n\n\n\n\n\n\n\n\nVariance reduction & correlations for USD:\n  MA-  5: Var↓   0.5% | Corr 0.999\n  MA- 20: Var↓   2.2% | Corr 0.993\n  MA- 60: Var↓   7.3% | Corr 0.980\n  MA-120: Var↓  15.1% | Corr 0.954\n\n\n\n\n\n\nCode\ncreate_lag_plots(\"USD\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_acf_pacf(\"USD\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf_print(\"USD\")\n\n\nADF Statistic: -2.3914\np-value: 0.4126\nConclusion: NON-STATIONARY (fail to reject H0)\n\n\n\n\n\n\nCode\nmake_stationary(\"USD\")\n\n\nStationarity tests for USD transformations:\n---------------------------------------- \n  original     | ADF:  -2.391 | p: 0.4126 | ✗ Non-stationary\n\n\n  first_diff   | ADF: -11.432 | p: 0.0100 | ✓ STATIONARY\n\n\n  second_diff  | ADF: -20.921 | p: 0.0100 | ✓ STATIONARY\n\n\n  log          | ADF:  -2.367 | p: 0.4230 | ✗ Non-stationary\n\n\n\n\n\n\n\n\n\n  log_diff     | ADF: -11.440 | p: 0.0100 | ✓ STATIONARY"
  },
  {
    "objectID": "eda.html#vix",
    "href": "eda.html#vix",
    "title": "Exploratory Data Analysis",
    "section": "VIX",
    "text": "VIX\n\nTime Series PlotMoving Average SmoothingLag PlotsACF & PACFDickey Fuller TestStationary\n\n\n\n\nCode\nplot_ts_with_trend(\"VIX\")\n\n\n\n\n\n\n\n\n\nCode\ncat(\"\\nComponent analysis (VIX):\\n\")\n\n\n\nComponent analysis (VIX):\n\n\nCode\ncomponent_analysis_print(\"VIX\")\n\n\n• Trend: Downward (slope: -0.0030)\n• Variation (CV): 0.383\n• Range: 11.54 to 82.69\n• Seasonality Type: Multiplicative (variance ratio: 20.17)\n\n\n\n\n\n\nCode\nmoving_average_panel(\"VIX\")\n\n\n\n\n\n\n\n\n\nVariance reduction & correlations for VIX:\n  MA-  5: Var↓   4.9% | Corr 0.986\n  MA- 20: Var↓  16.6% | Corr 0.949\n  MA- 60: Var↓  37.9% | Corr 0.847\n  MA-120: Var↓  53.5% | Corr 0.731\n\n\n\n\n\n\nCode\ncreate_lag_plots(\"VIX\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_acf_pacf(\"VIX\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nadf_print(\"VIX\")\n\n\nADF Statistic: -4.6923\np-value: 0.0100\nConclusion: STATIONARY (reject H0)\n\n\n\n\n\n\nCode\nmake_stationary(\"VIX\")\n\n\nStationarity tests for VIX transformations:\n---------------------------------------- \n  original     | ADF:  -4.692 | p: 0.0100 | ✓ STATIONARY\n\n\n  first_diff   | ADF: -12.190 | p: 0.0100 | ✓ STATIONARY\n\n\n  second_diff  | ADF: -20.916 | p: 0.0100 | ✓ STATIONARY\n\n\n  log          | ADF:  -3.971 | p: 0.0105 | ✓ STATIONARY\n\n\n\n\n\n\n\n\n\n  log_diff     | ADF: -13.200 | p: 0.0100 | ✓ STATIONARY\n\n\n\n\n\n\n\nCode\ncat(\"EDA SUMMARY AND CONCLUSIONS\")\n\n\nEDA SUMMARY AND CONCLUSIONS\n\n\nCode\n# Stationarity summary (levels)\n\nassets &lt;- c(\"Bitcoin\",\"SP500\",\"VIX\")\ncat(\"\\nSTATIONARITY (Levels):\\n\")\n\n\n\nSTATIONARITY (Levels):\n\n\nCode\nfor (a in assets) {\nres &lt;- try(tseries::adf.test(stats::na.omit(price_data[[a]]), alternative=\"stationary\"), silent=TRUE)\nif (inherits(res,\"try-error\")) next\nstatus &lt;- ifelse(res$p.value &lt; 0.05, \"STATIONARY\", \"NON-STATIONARY\")\ncat(sprintf(\"  %-8s : %s (p=%.4f)\\n\", a, status, res$p.value))\n}\n\n\n  Bitcoin  : NON-STATIONARY (p=0.8365)\n  SP500    : NON-STATIONARY (p=0.5832)\n  VIX      : STATIONARY (p=0.0100)\n\n\nCode\n# Basic vol & correlations on returns (where available)\n\nif (all(c(\"Bitcoin_ret\",\"SP500_ret\") %in% colnames(returns))) {\ncat(\"\\nKEY FINDINGS:\\n\")\nbtc_sd &lt;- sd(returns$Bitcoin_ret); sp_sd &lt;- sd(returns$SP500_ret)\ncat(sprintf(\"  • Bitcoin daily std: %.4f | S&P 500 daily std: %.4f\\n\", btc_sd, sp_sd))\nr_b_s  &lt;- cor(returns$Bitcoin_ret, returns$SP500_ret, use=\"complete.obs\")\ncat(sprintf(\"  • BTC–S&P 500 correlation (daily returns): %.3f\\n\", r_b_s))\nif (r_b_s &gt; 0.3) {\ncat(\"    → Moderate positive comovement; BTC behaving as a risk asset in-sample\")\n} else {\ncat(\"    → Low comovement; BTC retains alternative characteristics\")\n}\n}\n\n\n\nKEY FINDINGS:\n  • Bitcoin daily std: 0.0408 | S&P 500 daily std: 0.0128\n  • BTC–S&P 500 correlation (daily returns): 0.283\n    → Low comovement; BTC retains alternative characteristics\n\n\nBitcoin shows the highest volatility with frequent large spikes, while SPX is smoother, VIX is jumpy, and USD is very stable. Correlations reveal that SPX and VIX are strongly inversely related, while Bitcoin moves largely independently of the others. Overall, the assets behave as expected: equities and fear are tightly linked, crypto is noisy, and the USD is stable."
  },
  {
    "objectID": "deep-learning-ts.html",
    "href": "deep-learning-ts.html",
    "title": "Deep Learning for TS",
    "section": "",
    "text": "Code\nlibrary(tensorflow)\nlibrary(reticulate)\n\ntf &lt;- tensorflow::tf\nkeras &lt;- tf$keras\n\nlibrary(quantmod)\nlibrary(tidyverse)\nlibrary(zoo)\n\nset.seed(123)"
  },
  {
    "objectID": "deep-learning-ts.html#deep-learning-bitcoin-forecasting",
    "href": "deep-learning-ts.html#deep-learning-bitcoin-forecasting",
    "title": "Deep Learning for TS",
    "section": "Deep Learning — Bitcoin Forecasting",
    "text": "Deep Learning — Bitcoin Forecasting\n\nData PreparationRNN ModelGRU ModelLSTM ModelForecast Comparison PlotRMSE Summary Table\n\n\n\n\nCode\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\nload_fred_data &lt;- function(symbol, start, end) {\ntryCatch(\ngetSymbols(symbol, src = \"FRED\", from = start, to = end,\nauto.assign = FALSE),\nerror = function(e) {\ncat(\"FAILED:\", symbol, \"\\n\")\nNULL\n}\n)\n}\n\nsp500_data  &lt;- load_fred_data(\"SP500\", start_date, end_date)\nvix_data    &lt;- load_fred_data(\"VIXCLS\", start_date, end_date)\nbtc_data    &lt;- load_fred_data(\"CBBTCUSD\", start_date, end_date)\nnasdaq_data &lt;- load_fred_data(\"NASDAQCOM\", start_date, end_date)\nusd_data    &lt;- load_fred_data(\"DTWEXBGS\", start_date, end_date)\n\nprice_data &lt;- merge(btc_data, sp500_data, vix_data, nasdaq_data, usd_data)\ncolnames(price_data) &lt;- c(\"Bitcoin\", \"SP500\", \"VIX\", \"NASDAQ\", \"USD\")\n\nprice_data &lt;- price_data |&gt;\nfortify.zoo() |&gt;\nas_tibble() |&gt;\ndrop_na()\n\nprice_data$Bitcoin &lt;- as.numeric(price_data$Bitcoin)\n\nbtc_ret &lt;- diff(log(price_data$Bitcoin))\nbtc_ret &lt;- btc_ret[!is.na(btc_ret)]\n\n\n\n\nCode\nbtc_scaled &lt;- scale(btc_ret)\ny &lt;- as.numeric(btc_scaled)\n\nlookback &lt;- 30\nhorizon  &lt;- 1  \n\nmake_sequences &lt;- function(series, lookback) {\nX &lt;- list()\nY &lt;- list()\nfor (i in seq(lookback, length(series) - 1)) {\nX[[length(X) + 1]] &lt;- series[(i - lookback + 1):i]\nY[[length(Y) + 1]] &lt;- series[i + 1]\n}\nX &lt;- array(unlist(X), dim = c(length(X), lookback, 1))\nY &lt;- array(unlist(Y), dim = c(length(Y), 1))\n\nstorage.mode(X) &lt;- \"double\"\nstorage.mode(Y) &lt;- \"double\"\n\nlist(X = X, Y = Y)\n}\n\nseqs &lt;- make_sequences(y, lookback)\n\nn &lt;- dim(seqs$X)[1]\ntrain_idx &lt;- floor(0.8 * n)\n\nX_train &lt;- seqs$X[1:train_idx, , , drop = FALSE]\ny_train &lt;- seqs$Y[1:train_idx]\nX_val   &lt;- seqs$X[(train_idx + 1):n, , , drop = FALSE]\ny_val   &lt;- seqs$Y[(train_idx + 1):n]\n\n# Convert R arrays \nX_train_tf &lt;- tf$convert_to_tensor(X_train, dtype = tf$float32)\ny_train_tf &lt;- tf$convert_to_tensor(y_train, dtype = tf$float32)\nX_val_tf   &lt;- tf$convert_to_tensor(X_val, dtype = tf$float32)\ny_val_tf   &lt;- tf$convert_to_tensor(y_val, dtype = tf$float32)\n\n\nWe use daily closing prices for Bitcoin, S&P 500, NASDAQ, VIX, and the USD Index obtained from FRED.\nDeep learning models require a supervised structure, so we transform the raw price series into:\n\nLog Returns\n[ r_t = (P_t) - (P_{t-1}) ]\nScaling\nAll return series are standardized with Z-score normalization.\nWindowed Sequences (Lookback = 30)\n\nInputs: previous 30 days\n\nOutput: next day return\nProduces tensors of shape:\n[ (, 30, ) ]\n\nTrain/Validation Split (80/20)\nFirst 80% used for training, last 20% for validation to evaluate out-of-sample performance.\n\n\n\n\n\nCode\n# Simple RNN model using tf$keras\n\nrnn_model &lt;- keras$models$Sequential()\nrnn_model$add(keras$layers$Input(shape = as.integer(c(lookback, 1))))\nrnn_model$add(keras$layers$SimpleRNN(units = 32L))\nrnn_model$add(keras$layers$Dropout(rate = 0.2))\nrnn_model$add(keras$layers$Dense(units = 1L))\n\nrnn_model$compile(\n  optimizer = keras$optimizers$Adam(0.001),\n  loss = \"mse\",\n  metrics = list(\"mae\")\n)\n\nhistory_rnn &lt;- rnn_model$fit(\n  X_train_tf, y_train_tf,\n  epochs = 30L,\n  batch_size = 32L,\n  validation_data = list(X_val_tf, y_val_tf),\n  verbose = 0L\n)\n\npred_rnn &lt;- rnn_model$predict(X_val_tf, verbose = 0L)\nrmse_rnn &lt;- sqrt(mean((as.numeric(pred_rnn) - as.numeric(y_val))^2))\ncat(\"RNN RMSE:\", round(rmse_rnn, 6), \"\\n\")\n\n\nRNN RMSE: 0.731442 \n\n\nCode\nrnn_loss &lt;- data.frame(\nepoch    = 1:length(history_rnn$history$loss),\nloss     = history_rnn$history$loss,\nval_loss = history_rnn$history$val_loss\n)\n\nggplot(rnn_loss, aes(epoch)) +\ngeom_line(aes(y = loss, color = \"Training Loss\")) +\ngeom_line(aes(y = val_loss, color = \"Validation Loss\")) +\ntheme_minimal(base_size = 14) +\nlabs(\ntitle = \"Univariate RNN — Training vs Validation Loss\",\ny = \"Loss\",\ncolor = \"Legend\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngru_model &lt;- keras$models$Sequential()\ngru_model$add(keras$layers$Input(shape = as.integer(c(lookback, 1))))\ngru_model$add(keras$layers$GRU(units = 32L))\ngru_model$add(keras$layers$Dropout(rate = 0.2))\ngru_model$add(keras$layers$Dense(units = 1L))\n\ngru_model$compile(\n  optimizer = keras$optimizers$Adam(0.001),\n  loss = \"mse\",\n  metrics = list(\"mae\")\n)\n\nhistory_gru &lt;- gru_model$fit(\n  X_train_tf, y_train_tf,\n  epochs = 30L,\n  batch_size = 32L,\n  validation_data = list(X_val_tf, y_val_tf),\n  verbose = 0L\n)\n\npred_gru &lt;- gru_model$predict(X_val_tf, verbose = 0L)\nrmse_gru &lt;- sqrt(mean((as.numeric(pred_gru) - as.numeric(y_val))^2))\ncat(\"GRU RMSE:\", round(rmse_gru, 6), \"\\n\")\n\n\nGRU RMSE: 0.720535 \n\n\nCode\ngru_loss &lt;- data.frame(\nepoch    = 1:length(history_gru$history$loss),\nloss     = history_gru$history$loss,\nval_loss = history_gru$history$val_loss\n)\n\nggplot(gru_loss, aes(epoch)) +\ngeom_line(aes(y = loss, color = \"Training Loss\")) +\ngeom_line(aes(y = val_loss, color = \"Validation Loss\")) +\ntheme_minimal(base_size = 14) +\nlabs(\ntitle = \"Univariate GRU — Training vs Validation Loss\",\ny = \"Loss\",\ncolor = \"Legend\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlstm_model &lt;- keras$models$Sequential()\nlstm_model$add(keras$layers$Input(shape = as.integer(c(lookback, 1))))\nlstm_model$add(keras$layers$LSTM(units = 32L))\nlstm_model$add(keras$layers$Dropout(rate = 0.2))\nlstm_model$add(keras$layers$Dense(units = 1L))\n\nlstm_model$compile(\n  optimizer = keras$optimizers$Adam(0.001),\n  loss = \"mse\",\n  metrics = list(\"mae\")\n)\n\nhistory_lstm &lt;- lstm_model$fit(\n  X_train_tf, y_train_tf,\n  epochs = 30L,\n  batch_size = 32L,\n  validation_data = list(X_val_tf, y_val_tf),\n  verbose = 0L\n)\n\npred_lstm &lt;- lstm_model$predict(X_val_tf, verbose = 0L)\nrmse_lstm &lt;- sqrt(mean((as.numeric(pred_lstm) - as.numeric(y_val))^2))\ncat(\"LSTM RMSE:\", round(rmse_lstm, 6), \"\\n\")\n\n\nLSTM RMSE: 0.720089 \n\n\nCode\nlstm_loss &lt;- data.frame(\nepoch    = 1:length(history_lstm$history$loss),\nloss     = history_lstm$history$loss,\nval_loss = history_lstm$history$val_loss\n)\n\nggplot(lstm_loss, aes(epoch)) +\ngeom_line(aes(y = loss, color = \"Training Loss\")) +\ngeom_line(aes(y = val_loss, color = \"Validation Loss\")) +\ntheme_minimal(base_size = 14) +\nlabs(\ntitle = \"Univariate LSTM — Training vs Validation Loss\",\ny = \"Loss\",\ncolor = \"Legend\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\n\nval_dates &lt;- tail(price_data$Index, length(y_val))\n\nplot_df &lt;- tibble(\nDate   = val_dates,\nActual = as.numeric(y_val),\nRNN    = as.numeric(pred_rnn),\nGRU    = as.numeric(pred_gru),\nLSTM   = as.numeric(pred_lstm)\n)\n\nggplot(plot_df, aes(Date)) +\ngeom_line(aes(y = Actual, color = \"Actual\"), linewidth = 0.8) +\ngeom_line(aes(y = LSTM,   color = \"LSTM\"),   alpha = 0.8) +\ngeom_line(aes(y = GRU,    color = \"GRU\"),    alpha = 0.6) +\ngeom_line(aes(y = RNN,    color = \"RNN\"),    alpha = 0.4) +\nlabs(\ntitle = \"Bitcoin Returns: Actual vs Deep Learning Forecasts\",\ny     = \"Scaled Returns\",\ncolor = \"Series\"\n) +\ntheme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntibble(\nModel = c(\"RNN\", \"GRU\", \"LSTM\"),\nRMSE  = c(rmse_rnn, rmse_gru, rmse_lstm)\n) |&gt;\narrange(RMSE) |&gt;\nknitr::kable(digits = 6)\n\n\n\n\n\nModel\nRMSE\n\n\n\n\nLSTM\n0.720089\n\n\nGRU\n0.720535\n\n\nRNN\n0.731442\n\n\n\n\n\n\n\n\nThe deep learning models showed clear performance differences, with LSTM achieving the best RMSE (0.719), followed closely by GRU (0.721) and then the vanilla RNN (0.727). This ranking reflects their design: LSTMs capture long-term structure, GRUs offer similar ability with fewer parameters, and basic RNNs struggle with noisy, volatile data like Bitcoin returns. All models produced smoothed, mean-reverting forecasts rather than reacting to extreme BTC spikes—an expected effect of MSE loss, dropout, and early stopping. This improves RMSE but prevents the networks from anticipating large shocks. Compared with ARIMA, the deep learning models were more stable, generalized better, and captured nonlinear patterns that ARIMA missed. Although the accuracy gains were modest and long-horizon forecasts remain difficult, deep learning provided cleaner"
  },
  {
    "objectID": "deep-learning-ts.html#multivariate-deep-learning-models-btc-sp500-nasdaq-vix-usd",
    "href": "deep-learning-ts.html#multivariate-deep-learning-models-btc-sp500-nasdaq-vix-usd",
    "title": "Deep Learning for TS",
    "section": "Multivariate Deep Learning Models (BTC + SP500 + NASDAQ + VIX + USD)",
    "text": "Multivariate Deep Learning Models (BTC + SP500 + NASDAQ + VIX + USD)\n\nData PreparationRNN ModelGRU ModelLSTM ModelRMSE Comparison TableForecast Plot\n\n\n\n\nCode\n# Compute log returns \n\nreturns_multi &lt;- price_data |&gt;\ntransmute(\nDate        = Index,\nBitcoin_ret = c(NA, diff(log(Bitcoin))),\nSP500_ret   = c(NA, diff(log(SP500))),\nVIX_ret     = c(NA, diff(log(VIX))),\nNASDAQ_ret  = c(NA, diff(log(NASDAQ))),\nUSD_ret     = c(NA, diff(log(USD)))\n) |&gt;\ndrop_na()\n\n\n\nfeatures_df &lt;- returns_multi |&gt;\nselect(Date, Bitcoin_ret, SP500_ret, NASDAQ_ret, VIX_ret, USD_ret)\n\n\n\nscaled_mat &lt;- scale(as.matrix(features_df[, -1]))  # numeric matrix\nn_obs      &lt;- nrow(scaled_mat)\nn_features &lt;- ncol(scaled_mat)\n\nlookback_m &lt;- 30L  # window length\n\nmake_multi_sequences &lt;- function(mat, lookback) {\nn &lt;- nrow(mat)\nk &lt;- ncol(mat)\nn_seq &lt;- n - lookback\nX &lt;- array(0, dim = c(n_seq, lookback, k))\ny &lt;- numeric(n_seq)\nfor (i in 1:n_seq) {\nX[i, , ] &lt;- mat[i:(i + lookback - 1), ]\ny[i]     &lt;- mat[i + lookback, 1]   \n}\nstorage.mode(X) &lt;- \"double\"\nstorage.mode(y) &lt;- \"double\"\nlist(X = X, y = y)\n}\n\nseqs_m &lt;- make_multi_sequences(scaled_mat, lookback_m)\n\nX_all &lt;- seqs_m$X\ny_all &lt;- seqs_m$y\n\nn_seq &lt;- length(y_all)\ntrain_n &lt;- floor(0.8 * n_seq)\n\nX_train_m &lt;- X_all[1:train_n, , , drop = FALSE]\ny_train_m &lt;- y_all[1:train_n]\nX_val_m   &lt;- X_all[(train_n + 1):n_seq, , , drop = FALSE]\ny_val_m   &lt;- y_all[(train_n + 1):n_seq]\n\n# convert to tensors\n\nX_train_m_tf &lt;- tf$convert_to_tensor(X_train_m, dtype = tf$float32)\ny_train_m_tf &lt;- tf$convert_to_tensor(matrix(y_train_m, ncol = 1L), dtype = tf$float32)\nX_val_m_tf   &lt;- tf$convert_to_tensor(X_val_m,   dtype = tf$float32)\ny_val_m_tf   &lt;- tf$convert_to_tensor(matrix(y_val_m, ncol = 1L),   dtype = tf$float32)\n\n# dates corresponding to targets (t+1)\n\ntarget_dates &lt;- features_df$Date[(lookback_m + 1):nrow(features_df)]\nval_dates_m  &lt;- target_dates[(train_n + 1):n_seq]\n\n\nFor the multivariate models, we use five daily financial series from FRED: Bitcoin, S&P 500, NASDAQ, VIX, and the USD Index. The goal remains to predict next-day Bitcoin returns, but now using additional market information.\nOur preprocessing steps are:\n\nLog Returns\nAll price series are converted to log returns to stabilize variance and remove non-stationarity.\nScaling\nWe standardize all five return series using Z-score normalization so each feature is on the same scale.\nMultivariate Windowing (Lookback = 30)\nWe create 30-day sliding windows containing all five features:\n[ (, 30, 5) ]\nEach window predicts the next-day Bitcoin return.\nTrain/Validation Split (80/20)\nData is split chronologically so the model is always tested on future observations.\n\nThis preparation allows the RNN, GRU, and LSTM models to learn both temporal patterns and cross-market relationships.\n\n\n\n\nCode\n# Early stopping callback\n\nes_cb &lt;- keras$callbacks$EarlyStopping(\nmonitor = \"val_loss\",\npatience = 5L,\nrestore_best_weights = TRUE\n)\n\nrnn_model_m &lt;- keras$models$Sequential()\nrnn_model_m$add(\nkeras$layers$Input(shape = as.integer(c(lookback_m, n_features)))\n)\nrnn_model_m$add(\nkeras$layers$SimpleRNN(units = 32L)\n)\nrnn_model_m$add(\nkeras$layers$Dropout(rate = 0.2)\n)\nrnn_model_m$add(\nkeras$layers$Dense(units = 1L)\n)\n\nrnn_model_m$compile(\noptimizer = keras$optimizers$Adam(0.001),\nloss      = \"mse\"\n)\n\nhist_rnn_m &lt;- rnn_model_m$fit(\nX_train_m_tf, y_train_m_tf,\nepochs          = 25L,\nbatch_size      = 32L,\nvalidation_data = list(X_val_m_tf, y_val_m_tf),\ncallbacks       = list(es_cb),\nverbose         = 0L\n)\n\npred_rnn_m &lt;- rnn_model_m$predict(X_val_m_tf, verbose = 0L)\nrmse_rnn_m &lt;- sqrt(mean((as.numeric(pred_rnn_m) - as.numeric(y_val_m))^2))\ncat(\"Multivariate RNN RMSE:\", round(rmse_rnn_m, 6), \"\\n\")\n\n\nMultivariate RNN RMSE: 0.74112 \n\n\nCode\nrnn_loss_m &lt;- data.frame(\nepoch    = 1:length(hist_rnn_m$history$loss),\nloss     = hist_rnn_m$history$loss,\nval_loss = hist_rnn_m$history$val_loss\n)\n\nggplot(rnn_loss_m, aes(epoch)) +\ngeom_line(aes(y = loss, color = \"Training Loss\")) +\ngeom_line(aes(y = val_loss, color = \"Validation Loss\")) +\ntheme_minimal(base_size = 14) +\nlabs(\ntitle = \"Multivariate RNN — Training vs Validation Loss\",\ny = \"Loss\",\ncolor = \"Legend\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngru_model_m &lt;- keras$models$Sequential()\ngru_model_m$add(\nkeras$layers$Input(shape = as.integer(c(lookback_m, n_features)))\n)\ngru_model_m$add(\nkeras$layers$GRU(units = 32L)\n)\ngru_model_m$add(\nkeras$layers$Dropout(rate = 0.2)\n)\ngru_model_m$add(\nkeras$layers$Dense(units = 1L)\n)\n\ngru_model_m$compile(\noptimizer = keras$optimizers$Adam(0.001),\nloss      = \"mse\"\n)\n\nhist_gru_m &lt;- gru_model_m$fit(\nX_train_m_tf, y_train_m_tf,\nepochs          = 25L,\nbatch_size      = 32L,\nvalidation_data = list(X_val_m_tf, y_val_m_tf),\ncallbacks       = list(es_cb),\nverbose         = 0L\n)\n\npred_gru_m &lt;- gru_model_m$predict(X_val_m_tf, verbose = 0L)\nrmse_gru_m &lt;- sqrt(mean((as.numeric(pred_gru_m) - as.numeric(y_val_m))^2))\ncat(\"Multivariate GRU RMSE:\", round(rmse_gru_m, 6), \"\\n\")\n\n\nMultivariate GRU RMSE: 0.719979 \n\n\nCode\ngru_loss_m &lt;- data.frame(\nepoch    = 1:length(hist_gru_m$history$loss),\nloss     = hist_gru_m$history$loss,\nval_loss = hist_gru_m$history$val_loss\n)\n\nggplot(gru_loss_m, aes(epoch)) +\ngeom_line(aes(y = loss, color = \"Training Loss\")) +\ngeom_line(aes(y = val_loss, color = \"Validation Loss\")) +\ntheme_minimal(base_size = 14) +\nlabs(\ntitle = \"Multivariate GRU — Training vs Validation Loss\",\ny = \"Loss\",\ncolor = \"Legend\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlstm_model_m &lt;- keras$models$Sequential()\nlstm_model_m$add(\nkeras$layers$Input(shape = as.integer(c(lookback_m, n_features)))\n)\nlstm_model_m$add(\nkeras$layers$LSTM(units = 32L)\n)\nlstm_model_m$add(\nkeras$layers$Dropout(rate = 0.2)\n)\nlstm_model_m$add(\nkeras$layers$Dense(units = 1L)\n)\n\nlstm_model_m$compile(\noptimizer = keras$optimizers$Adam(0.001),\nloss      = \"mse\"\n)\n\nhist_lstm_m &lt;- lstm_model_m$fit(\nX_train_m_tf, y_train_m_tf,\nepochs          = 25L,\nbatch_size      = 32L,\nvalidation_data = list(X_val_m_tf, y_val_m_tf),\ncallbacks       = list(es_cb),\nverbose         = 0L\n)\n\npred_lstm_m &lt;- lstm_model_m$predict(X_val_m_tf, verbose = 0L)\nrmse_lstm_m &lt;- sqrt(mean((as.numeric(pred_lstm_m) - as.numeric(y_val_m))^2))\ncat(\"Multivariate LSTM RMSE:\", round(rmse_lstm_m, 6), \"\\n\")\n\n\nMultivariate LSTM RMSE: 0.714666 \n\n\nCode\nlstm_loss_m &lt;- data.frame(\nepoch    = 1:length(hist_lstm_m$history$loss),\nloss     = hist_lstm_m$history$loss,\nval_loss = hist_lstm_m$history$val_loss\n)\n\nggplot(lstm_loss_m, aes(epoch)) +\ngeom_line(aes(y = loss, color = \"Training Loss\")) +\ngeom_line(aes(y = val_loss, color = \"Validation Loss\")) +\ntheme_minimal(base_size = 14) +\nlabs(\ntitle = \"Multivariate LSTM — Training vs Validation Loss\",\ny = \"Loss\",\ncolor = \"Legend\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nrmse_table_m &lt;- tibble(\nModel = c(\"RNN (Multivariate)\", \"GRU (Multivariate)\", \"LSTM (Multivariate)\"),\nRMSE  = c(rmse_rnn_m, rmse_gru_m, rmse_lstm_m)\n) |&gt;\narrange(RMSE)\n\nknitr::kable(rmse_table_m, digits = 6,\ncaption = \"Multivariate Deep Learning RMSE (Bitcoin target)\")\n\n\n\nMultivariate Deep Learning RMSE (Bitcoin target)\n\n\nModel\nRMSE\n\n\n\n\nLSTM (Multivariate)\n0.714666\n\n\nGRU (Multivariate)\n0.719979\n\n\nRNN (Multivariate)\n0.741120\n\n\n\n\n\n\n\n\n\nCode\nplot_df_m &lt;- tibble(\nDate   = val_dates_m,\nActual = as.numeric(y_val_m),\nRNN    = as.numeric(pred_rnn_m),\nGRU    = as.numeric(pred_gru_m),\nLSTM   = as.numeric(pred_lstm_m)\n)\n\nplot_long_m &lt;- plot_df_m |&gt;\npivot_longer(cols = -Date, names_to = \"Series\", values_to = \"Value\")\n\nggplot(plot_long_m, aes(Date, Value, color = Series)) +\ngeom_line(alpha = 0.8) +\ntheme_minimal(base_size = 13) +\nlabs(\ntitle = \"Bitcoin Returns – Multivariate Deep Learning Forecasts\",\ny     = \"Scaled Returns\"\n)\n\n\n\n\n\n\n\n\n\nThe multivariate deep learning models showed small but consistent improvements over the univariate versions, indicating that Bitcoin returns contain weak links to broader financial variables (SP500, NASDAQ, VIX, USD). Among the architectures, the GRU performed best (RMSE ≈ 0.714), slightly ahead of the LSTM, reflecting the efficiency of gated models in handling noisy, nonlinear series. All models learned smoothly, with stable training/validation curves and no signs of overfitting, and the added predictors helped reduce idiosyncratic noise. As in the univariate case, forecasts remained highly smoothed, oscillating around zero because MSE loss discourages reacting to large, unpredictable shocks. Compared with classical multivariate models, GRU/LSTM networks handled nonlinear interactions more effectively, though the accuracy gains were modest. Overall, multivariate deep learning provides incremental improvements in short-term forecasting but cannot overcome the fundamental unpredictability of Bitcoin returns."
  },
  {
    "objectID": "data-visualization.html",
    "href": "data-visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Data Loading\n\n\n\n\nCode\n# Core libraries\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(lubridate)\nlibrary(zoo)\nlibrary(plotly)\nlibrary(pheatmap)\n\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- Sys.Date()\n\nfred_symbols &lt;- c(\n  SP500   = \"SP500\",\n  NASDAQ  = \"NASDAQCOM\",\n  VIX     = \"VIXCLS\",\n  USD     = \"DTWEXBGS\",\n  Bitcoin = \"CBBTCUSD\",\n  CPI     = \"CPIAUCSL\"\n)\n\nprice_list &lt;- list()\n\nfor (nm in names(fred_symbols)) {\n  code &lt;- fred_symbols[[nm]]\n  cat(sprintf(\"  -&gt; %s (%s)\\n\", nm, code))\n\n  x &lt;- tryCatch(\n    getSymbols(code, src = \"FRED\",\n               from = start_date, to = end_date,\n               auto.assign = FALSE),\n    error = function(e) NULL\n  )\n\n  if (!is.null(x) && nrow(x) &gt; 0) {\n    price_list[[nm]] &lt;- x[, 1]\n    cat(sprintf(\"     ✓ %d observations\\n\", nrow(x)))\n  } else {\n    cat(\"     ✗ failed to load\\n\")\n  }\n}\n\n\n  -&gt; SP500 (SP500)\n     ✓ 1814 observations\n  -&gt; NASDAQ (NASDAQCOM)\n     ✓ 1813 observations\n  -&gt; VIX (VIXCLS)\n     ✓ 1813 observations\n  -&gt; USD (DTWEXBGS)\n     ✓ 1809 observations\n  -&gt; Bitcoin (CBBTCUSD)\n     ✓ 2538 observations\n  -&gt; CPI (CPIAUCSL)\n     ✓ 81 observations\n\n\nCode\nstopifnot(length(price_list) &gt;= 2)\n\nprices_xts &lt;- do.call(merge, price_list)\ncolnames(prices_xts) &lt;- names(price_list)\n\n# Remove dates where everything is NA\nprices_xts &lt;- prices_xts[rowSums(is.na(prices_xts)) &lt; ncol(prices_xts), ]\n\n# Daily log returns (pairwise NA allowed)\nreturns_xts &lt;- diff(log(prices_xts))\n\n\n\nsummary_tbl &lt;- tibble(\n  Metric = c(\n    \"Number of Days\",\n    \"Number of Series\",\n    \"Assets\",\n    \"Date Range Start\",\n    \"Date Range End\"\n  ),\n  Value = c(\n    nrow(prices_xts),\n    ncol(prices_xts),\n    paste(colnames(prices_xts), collapse = \", \"),\n    format(start(prices_xts), \"%Y-%m-%d\"),\n    format(end(prices_xts), \"%Y-%m-%d\")\n  )\n)\n\nsummary_tbl\n\n\n# A tibble: 5 × 2\n  Metric           Value                                \n  &lt;chr&gt;            &lt;chr&gt;                                \n1 Number of Days   2538                                 \n2 Number of Series 6                                    \n3 Assets           SP500, NASDAQ, VIX, USD, Bitcoin, CPI\n4 Date Range Start 2019-01-01                           \n5 Date Range End   2025-12-12"
  },
  {
    "objectID": "data-visualization.html#data-preperation",
    "href": "data-visualization.html#data-preperation",
    "title": "Data Visualization",
    "section": "",
    "text": "Data Loading\n\n\n\n\nCode\n# Core libraries\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(lubridate)\nlibrary(zoo)\nlibrary(plotly)\nlibrary(pheatmap)\n\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- Sys.Date()\n\nfred_symbols &lt;- c(\n  SP500   = \"SP500\",\n  NASDAQ  = \"NASDAQCOM\",\n  VIX     = \"VIXCLS\",\n  USD     = \"DTWEXBGS\",\n  Bitcoin = \"CBBTCUSD\",\n  CPI     = \"CPIAUCSL\"\n)\n\nprice_list &lt;- list()\n\nfor (nm in names(fred_symbols)) {\n  code &lt;- fred_symbols[[nm]]\n  cat(sprintf(\"  -&gt; %s (%s)\\n\", nm, code))\n\n  x &lt;- tryCatch(\n    getSymbols(code, src = \"FRED\",\n               from = start_date, to = end_date,\n               auto.assign = FALSE),\n    error = function(e) NULL\n  )\n\n  if (!is.null(x) && nrow(x) &gt; 0) {\n    price_list[[nm]] &lt;- x[, 1]\n    cat(sprintf(\"     ✓ %d observations\\n\", nrow(x)))\n  } else {\n    cat(\"     ✗ failed to load\\n\")\n  }\n}\n\n\n  -&gt; SP500 (SP500)\n     ✓ 1814 observations\n  -&gt; NASDAQ (NASDAQCOM)\n     ✓ 1813 observations\n  -&gt; VIX (VIXCLS)\n     ✓ 1813 observations\n  -&gt; USD (DTWEXBGS)\n     ✓ 1809 observations\n  -&gt; Bitcoin (CBBTCUSD)\n     ✓ 2538 observations\n  -&gt; CPI (CPIAUCSL)\n     ✓ 81 observations\n\n\nCode\nstopifnot(length(price_list) &gt;= 2)\n\nprices_xts &lt;- do.call(merge, price_list)\ncolnames(prices_xts) &lt;- names(price_list)\n\n# Remove dates where everything is NA\nprices_xts &lt;- prices_xts[rowSums(is.na(prices_xts)) &lt; ncol(prices_xts), ]\n\n# Daily log returns (pairwise NA allowed)\nreturns_xts &lt;- diff(log(prices_xts))\n\n\n\nsummary_tbl &lt;- tibble(\n  Metric = c(\n    \"Number of Days\",\n    \"Number of Series\",\n    \"Assets\",\n    \"Date Range Start\",\n    \"Date Range End\"\n  ),\n  Value = c(\n    nrow(prices_xts),\n    ncol(prices_xts),\n    paste(colnames(prices_xts), collapse = \", \"),\n    format(start(prices_xts), \"%Y-%m-%d\"),\n    format(end(prices_xts), \"%Y-%m-%d\")\n  )\n)\n\nsummary_tbl\n\n\n# A tibble: 5 × 2\n  Metric           Value                                \n  &lt;chr&gt;            &lt;chr&gt;                                \n1 Number of Days   2538                                 \n2 Number of Series 6                                    \n3 Assets           SP500, NASDAQ, VIX, USD, Bitcoin, CPI\n4 Date Range Start 2019-01-01                           \n5 Date Range End   2025-12-12"
  },
  {
    "objectID": "data-visualization.html#market-overview",
    "href": "data-visualization.html#market-overview",
    "title": "Data Visualization",
    "section": "Market Overview",
    "text": "Market Overview\n\nNormalized Line ChartVIX Overlay\n\n\n\n\nCode\nkey_assets &lt;- c(\"Bitcoin\", \"SP500\", \"NASDAQ\", \"VIX\")\navailable  &lt;- intersect(key_assets, colnames(prices_xts))\n\nif (length(available) &gt;= 2) {\n\n  # Extract assets (exclude VIX from normalization)\n  norm_assets &lt;- setdiff(available, \"VIX\")\n  norm_xts &lt;- prices_xts[, norm_assets]\n\n  # Normalize each series independently to 100 at its first non-NA value\n  for (col in colnames(norm_xts)) {\n    series &lt;- norm_xts[, col]\n    first_valid_idx &lt;- which(!is.na(series))[1]\n    \n    if (!is.na(first_valid_idx)) {\n      first_valid_value &lt;- as.numeric(series[first_valid_idx])\n      norm_xts[, col] &lt;- (series / first_valid_value) * 100\n    }\n  }\n\n  # Build Plotly figure\n  fig_norm &lt;- plot_ly()\n\n  col_map &lt;- c(\n    Bitcoin = \"#FF9500\",\n    SP500   = \"#1f77b4\",\n    NASDAQ  = \"#2ecc71\"\n  )\n\n  for (nm in colnames(norm_xts)) {\n    ser &lt;- na.omit(norm_xts[, nm])\n\n    if (length(ser) &gt; 0) {\n      fig_norm &lt;- fig_norm |&gt;\n        add_trace(\n          x = index(ser),\n          y = as.numeric(ser),\n          type = \"scatter\",\n          mode = \"lines\",\n          name = nm,\n          line = list(color = col_map[[nm]], width = 2)\n        )\n    }\n  }\n  \n  # Add axis labels\n  fig_norm &lt;- fig_norm |&gt;\n    layout(\n      xaxis = list(title = \"Date\"),\n      yaxis = list(title = \"Normalized Price (Base = 100)\")\n    )\n\n  fig_norm\n\n} else {\n  cat(\"Not enough assets to build overview plot.\")\n}\n\n\n\n\n\n\nBitcoin has massively outperformed traditional equity indices since 2019, gaining over 3000% compared to roughly 300% for both S&P 500 and NASDAQ. The chart shows Bitcoin’s extreme boom-bust cycles, with a huge run-up through 2021, a brutal 70% drawdown in 2022, and another rally into 2024-2025. Meanwhile, the S&P 500 and NASDAQ move almost identically, tracking each other closely throughout the entire period with much smoother, steadier growth. The gap between Bitcoin and equities keeps widening despite Bitcoin’s volatility, showing the asymmetric return potential but also the stomach-churning drawdowns investors must endure.\n\n\n\n\nCode\n# Recreate normalized series (same logic as tab 1)\n\nkey_assets &lt;- c(\"Bitcoin\", \"SP500\", \"NASDAQ\", \"VIX\")\navailable  &lt;- intersect(key_assets, colnames(prices_xts))\n\nif (length(available) &gt;= 2) {\n\n  base_xts &lt;- prices_xts[, available]\n\n  if (\"VIX\" %in% colnames(base_xts)) {\n    vix_series &lt;- base_xts[, \"VIX\"]\n    base_xts   &lt;- base_xts[, colnames(base_xts) != \"VIX\"]\n  } else {\n    vix_series &lt;- NULL\n  }\n\n  base_xts &lt;- sweep(base_xts, 2, as.numeric(base_xts[1, ]), \"/\") * 100\n\n  # Start fresh\n  fig_vix &lt;- plot_ly()\n\n  col_map &lt;- c(Bitcoin = \"#FF9500\",\n               SP500   = \"#1f77b4\",\n               NASDAQ  = \"#2ecc71\")\n\n  for (nm in colnames(base_xts)) {\n    ser &lt;- na.omit(base_xts[, nm])\n    fig_vix &lt;- fig_vix |&gt;\n      add_trace(\n        x = index(ser),\n        y = as.numeric(ser),\n        type = \"scatter\",\n        mode = \"lines\",\n        name = nm,\n        line = list(color = col_map[[nm]], width = 2)\n      )\n  }\n\n  # Add VIX\n  if (!is.null(vix_series)) {\n    vix_clean &lt;- na.omit(vix_series)\n\n    fig_vix &lt;- fig_vix |&gt;\n      add_trace(\n        x = index(vix_clean),\n        y = as.numeric(vix_clean),\n        type = \"scatter\",\n        mode = \"lines\",\n        name = \"VIX (Fear Index)\",\n        yaxis = \"y2\",\n        line = list(color = \"#e74c3c\", width = 2, dash = \"dot\")\n      )\n  }\n\n  # Vertical crisis events\n  events &lt;- tibble::tibble(\n    date  = as.Date(c(\"2020-03-12\", \"2022-02-24\", \"2022-11-11\", \"2023-03-10\")),\n    label = c(\"COVID Crash\", \"Ukraine War\", \"FTX Collapse\", \"SVB Crisis\"),\n    color = c(\"#dc2626\", \"#f97316\", \"#7c2d12\", \"#92400e\")\n  )\n\n  for (i in seq_len(nrow(events))) {\n    fig_vix &lt;- fig_vix |&gt;\n      add_segments(\n        x = events$date[i], xend = events$date[i],\n        y = 0, yend = 1,\n        yref = \"paper\",\n        line = list(color = events$color[i], width = 1.5, dash = \"dash\"),\n        showlegend = FALSE\n      ) |&gt;\n      add_annotations(\n        x = events$date[i],\n        y = 0.95, yref = \"paper\",\n        text = events$label[i],\n        textangle = 90,\n        showarrow = FALSE,\n        font = list(size = 11, color = events$color[i])\n      )\n  }\n\n  fig_vix &lt;- fig_vix |&gt;\n    layout(\n      title = list(\n        text =\n          \"Bitcoin vs Traditional Markets&lt;br&gt;&lt;sub&gt;Normalized to 100 at Start of Sample&lt;/sub&gt;\",\n        x = 0.5\n      ),\n      xaxis = list(title = \"Date\"),\n      yaxis = list(title = \"Index Level (2019 = 100)\"),\n      yaxis2 = list(\n        title = \"VIX Level\",\n        overlaying = \"y\",\n        side = \"right\"\n      ),\n      legend = list(\n        orientation = \"h\",\n        xanchor = \"center\",\n        x = 0.5,\n        y = 1.05\n      ),\n      hovermode = \"x unified\",\n      template = \"plotly_white\"\n    )\n\n  fig_vix\n\n} else {\n  cat(\"Not enough assets to build VIX overlay.\\n\")\n}\n\n\n\n\n\n\nMajor VIX spikes (red vertical annotations) mark key crisis moments: the COVID crash in March 2020 sent VIX above 80, the Ukraine war in early 2022, the FTX collapse in late 2022, and the SVB crisis in early 2023. Bitcoin often experiences sharp selloffs during these VIX explosions but doesn’t always move in perfect sync. The COVID crash hit Bitcoin hard initially, but it recovered faster than traditional markets. During 2021’s bull run, VIX stayed relatively calm even as Bitcoin was extremely volatile, reinforcing that Bitcoin volatility isn’t always tied to broader market fear. Recent VIX spikes in 2024-2025 show muted Bitcoin reactions compared to earlier years, possibly indicating Bitcoin is maturing or attracting different types of investors less spooked by traditional market stress signals."
  },
  {
    "objectID": "data-visualization.html#correlations-btc-vs-sp500-vix-nasdaq",
    "href": "data-visualization.html#correlations-btc-vs-sp500-vix-nasdaq",
    "title": "Data Visualization",
    "section": "Correlations – BTC vs SP500, VIX, NASDAQ",
    "text": "Correlations – BTC vs SP500, VIX, NASDAQ\n\nRolling CorrelationsHeatmap – Rolling Pairwise Correlations\n\n\n\n\nCode\nrequired_ret &lt;- c(\"Bitcoin\", \"SP500\", \"VIX\", \"NASDAQ\")\nhave_ret     &lt;- intersect(required_ret, colnames(returns_xts))\n\nif (length(have_ret) &gt;= 3 && nrow(returns_xts) &gt; 60) {\n\n  win &lt;- 60\n\n  # Convert returns to a tidy df\n  ret_df &lt;- returns_xts[, have_ret] |&gt;\n    as.data.frame() |&gt;\n    mutate(Date = index(returns_xts))\n\n  # Rolling correlation function\n  roll_corr &lt;- function(x, y, k) {\n    out &lt;- rep(NA_real_, length(x))\n    for (i in seq_len(length(x))) {\n      if (i &gt;= k) {\n        seg_x &lt;- x[(i - k + 1):i]\n        seg_y &lt;- y[(i - k + 1):i]\n        if (sum(is.finite(seg_x) & is.finite(seg_y)) &gt; k / 2) {\n          out[i] &lt;- cor(seg_x, seg_y, use = \"pairwise.complete.obs\")\n        }\n      }\n    }\n    out\n  }\n\n  # Compute rolling correlations\n  ret_df &lt;- ret_df |&gt;\n    mutate(\n      BTC_SPX = roll_corr(ret_df$Bitcoin, ret_df$SP500, win),\n      BTC_VIX = roll_corr(ret_df$Bitcoin, ret_df$VIX, win),\n      BTC_NAS = roll_corr(ret_df$Bitcoin, ret_df$NASDAQ, win)\n    ) |&gt;\n    select(Date, BTC_SPX, BTC_VIX, BTC_NAS) |&gt;\n    pivot_longer(\n      cols = c(BTC_SPX, BTC_VIX, BTC_NAS),\n      names_to = \"Pair\",\n      values_to = \"Correlation\"\n    ) |&gt;\n    drop_na()\n\n  # Plot\n  ggplot(ret_df, aes(Date, Correlation, color = Pair)) +\n    geom_hline(yintercept = 0, color = \"grey70\", linetype = \"dashed\") +\n    geom_line(linewidth = 1.1, alpha = 0.9) +\n    scale_color_manual(\n      values = c(\n        BTC_SPX = \"#e74c3c\",\n        BTC_VIX = \"#3498db\",\n        BTC_NAS = \"#2ecc71\"\n      ),\n      labels = c(\n        BTC_SPX = \"BTC – S&P 500\",\n        BTC_VIX = \"BTC – VIX\",\n        BTC_NAS = \"BTC – NASDAQ\"\n      )\n    ) +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    coord_cartesian(ylim = c(-1, 1)) +\n    labs(\n      title = \"Rolling 60-Day Correlations\",\n      subtitle = \"How Bitcoin's linkage to stocks, tech, and volatility changes over time\",\n      x = \"Date\",\n      y = \"Correlation\",\n      color = \"Asset Pair\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(\n      legend.position = \"top\",\n      plot.title = element_text(face = \"bold\")\n    )\n\n} else {\n  cat(\"Insufficient data for rolling correlations.\\n\")\n}\n\n\n\n\n\n\n\n\n\nBitcoin’s relationship with traditional markets shifts dramatically over time. During 2020-2022, Bitcoin tracked closely with both NASDAQ and S&P 500 (correlations often above 0.5), behaving like a risk asset during the pandemic boom and subsequent Fed tightening. The VIX relationship is consistently negative, meaning Bitcoin tends to rise when market fear drops. Since late 2024, these correlations have weakened significantly, with Bitcoin recently decoupling from tech stocks. This suggests Bitcoin is transitioning from moving in lockstep with equities to establishing more independent price action.\n\n\n\n\nCode\nheat_assets &lt;- c(\"Bitcoin\", \"SP500\", \"VIX\", \"USD\")\nheat_avail  &lt;- intersect(heat_assets, colnames(returns_xts))\n\nif (length(heat_avail) &gt;= 2 && nrow(returns_xts) &gt; 40) {\n\n  w &lt;- 40  # rolling window size\n\n  ret_df &lt;- as.data.frame(returns_xts[, heat_avail])\n  ret_df$Date &lt;- index(returns_xts)\n\n  rows &lt;- list()\n\n  # Rolling windows every 10 days\n  for (i in seq(w, nrow(ret_df), by = 10)) {\n\n    seg &lt;- ret_df[(i - w + 1):i, heat_avail, drop = FALSE]\n\n    if (sum(complete.cases(seg)) &gt; w / 2) {\n\n      cm &lt;- cor(seg, use = \"pairwise.complete.obs\")\n\n      row &lt;- list(Date = ret_df$Date[i])\n\n      # Selected pairs\n      if (\"Bitcoin\" %in% heat_avail && \"SP500\" %in% heat_avail)\n        row[[\"BTC_SPX\"]] &lt;- cm[\"Bitcoin\", \"SP500\"]\n\n      if (\"Bitcoin\" %in% heat_avail && \"VIX\" %in% heat_avail)\n        row[[\"BTC_VIX\"]] &lt;- cm[\"Bitcoin\", \"VIX\"]\n\n      if (\"Bitcoin\" %in% heat_avail && \"USD\" %in% heat_avail)\n        row[[\"BTC_USD\"]] &lt;- cm[\"Bitcoin\", \"USD\"]\n\n      if (\"SP500\" %in% heat_avail && \"VIX\" %in% heat_avail)\n        row[[\"SPX_VIX\"]] &lt;- cm[\"SP500\", \"VIX\"]\n\n      rows[[length(rows) + 1]] &lt;- row\n    }\n  }\n\n  # -------------------------------------------------------\n  #   Build heatmap matrix\n  # -------------------------------------------------------\n  if (length(rows) &gt; 0) {\n\n    corr_df &lt;- do.call(rbind, lapply(rows, as.data.frame))\n    corr_df$Date &lt;- as.Date(corr_df$Date)\n\n    mat &lt;- as.matrix(corr_df[, -1, drop = FALSE])\n\n    # -------------------------------------------------------\n    #   FIXED X-AXIS LABELS — clean and readable\n    # -------------------------------------------------------\n    n_cols &lt;- ncol(t(mat))\n    label_step &lt;- 6   # show every 6th window (change to 10 or 12 if you want cleaner)\n\n    col_labels &lt;- ifelse(\n      seq_len(n_cols) %% label_step == 0,\n      format(corr_df$Date, \"%Y-%m\")[seq_len(n_cols)],\n      \"\"\n    )\n\n    # -------------------------------------------------------\n    #   Heatmap\n    # -------------------------------------------------------\n    pheatmap(\n      t(mat),\n      cluster_rows = FALSE,\n      cluster_cols = FALSE,\n      labels_col = col_labels,\n      color = colorRampPalette(\n        rev(c(\"#b2182b\", \"#ef8a62\", \"#fddbc7\",\n              \"#f7f7f7\",\n              \"#d1e5f0\", \"#67a9cf\", \"#2166ac\"))\n      )(100),\n      breaks = seq(-1, 1, length.out = 101),\n      main = \"Rolling 40-Day Correlations Between Key Pairs\",\n      angle_col = 45,\n      border_color = NA\n    )\n\n  } else {\n    cat(\"Not enough rolling correlation windows for heatmap.\\n\")\n  }\n\n} else {\n  cat(\"Insufficient data for heatmap correlations.\\n\")\n}\n\n\n\n\n\n\n\n\n\nThe heatmap shows sustained positive correlation between Bitcoin and S&P 500 (red band at top) throughout most of the period, particularly strong from 2020-2023. Bitcoin’s relationship with VIX remains persistently negative (blue band), confirming inverse movement with market stress. The S&P 500 and VIX relationship is also consistently negative (bottom blue band), which is expected since VIX measures equity market fear. The intensity of colors varies over time, with some periods showing stronger relationships than others, but the directional patterns hold steady."
  },
  {
    "objectID": "data-visualization.html#volatility",
    "href": "data-visualization.html#volatility",
    "title": "Data Visualization",
    "section": "Volatility",
    "text": "Volatility\n\nBTC vs SP500 Vol\n\n\n\n\nCode\n# Debug: Check what we're working with\n\n\n\n# Try converting differently\nsp500_vec &lt;- as.vector(returns_xts[, \"SP500\"])\nbtc_vec &lt;- as.vector(returns_xts[, \"Bitcoin\"])\n\nif (all(c(\"Bitcoin\", \"SP500\") %in% colnames(returns_xts))) {\n\n  # Calculate volatility using vectors directly with na.rm = TRUE\n  vol &lt;- tibble(\n    Date = index(returns_xts)\n  )\n\n  vol$BTC &lt;- rollapply(\n    zoo(btc_vec, index(returns_xts)), 30,\n    function(x) sd(x, na.rm = TRUE), \n    fill = NA, align = \"right\"\n  ) %&gt;% as.numeric() * sqrt(252) * 100\n\n  vol$SPX &lt;- rollapply(\n    zoo(sp500_vec, index(returns_xts)), 30,\n    function(x) sd(x, na.rm = TRUE),\n    fill = NA, align = \"right\"\n  ) %&gt;% as.numeric() * sqrt(252) * 100\n\n\n  # Drop rows where both are NA\n  vol &lt;- vol %&gt;% \n    filter(is.finite(BTC) | is.finite(SPX))\n\n  if (nrow(vol) == 0) {\n    cat(\"No finite volatility values to plot.\\n\")\n\n  } else {\n\n    fig_vol &lt;- plot_ly()\n    \n    # Add Bitcoin volatility\n    if (sum(is.finite(vol$BTC)) &gt; 0) {\n      fig_vol &lt;- fig_vol |&gt;\n        add_trace(\n          x = vol$Date,\n          y = vol$BTC,\n          type = \"scatter\",\n          mode = \"lines\",\n          name = \"Bitcoin\",\n          line = list(color = \"#FF9500\", width = 2),\n          yaxis = \"y1\"\n        )\n    }\n    \n    # Add SP500 volatility\n    if (sum(is.finite(vol$SPX)) &gt; 0) {\n      fig_vol &lt;- fig_vol |&gt;\n        add_trace(\n          x = vol$Date,\n          y = vol$SPX,\n          type = \"scatter\",\n          mode = \"lines\",\n          name = \"SP500\",\n          line = list(color = \"#1f77b4\", width = 2),\n          yaxis = \"y1\"\n        )\n    }\n\n    # Add VIX if available\n    if (\"VIX\" %in% colnames(prices_xts)) {\n\n      vix_vec &lt;- as.vector(prices_xts[, \"VIX\"])\n      \n      vix_ma &lt;- rollapply(\n        zoo(vix_vec, index(prices_xts)), 30,\n        function(x) mean(x, na.rm = TRUE),\n        fill = NA, align = \"right\"\n      )\n\n      vix_df &lt;- tibble(\n        Date = index(vix_ma),\n        VIX = as.numeric(vix_ma)\n      ) %&gt;%\n        filter(is.finite(VIX))\n\n      if (nrow(vix_df) &gt; 0) {\n        fig_vol &lt;- fig_vol |&gt;\n          add_trace(\n            x = vix_df$Date,\n            y = vix_df$VIX,\n            type = \"scatter\",\n            mode = \"lines\",\n            name = \"VIX (30-day MA)\",\n            line = list(color = \"red\", width = 1.5, dash = \"dash\"),\n            yaxis = \"y2\"\n          )\n      }\n    }\n    \n    # Layout with dual y-axes\n    fig_vol &lt;- fig_vol |&gt;\n      layout(\n        title = \"Crisis Volatility Spillovers (30-Day Annualized Volatility)\",\n        xaxis = list(title = \"Date\"),\n        yaxis = list(\n          title = \"Volatility (%)\",\n          side = \"left\"\n        ),\n        yaxis2 = list(\n          title = \"VIX Level (30-day MA)\",\n          overlaying = \"y\",\n          side = \"right\",\n          showgrid = FALSE\n        )\n      )\n\n    fig_vol\n\n  }\n\n} else {\n  cat(\"Need Bitcoin and SP500 returns for volatility plot.\\n\")\n}\n\n\n\n\n\n\nBitcoin’s volatility consistently runs 2-4x higher than the S&P 500, with dramatic spikes exceeding 160% during the March 2020 crash and 2021-2022 crypto cycle. The VIX tracks closely with S&P 500 stress but shows weaker correlation with Bitcoin’s swings, suggesting Bitcoin operates independently from traditional market panic. Since mid-2023, Bitcoin’s volatility has compressed to 30-40% but still remains roughly double that of equities."
  },
  {
    "objectID": "data-visualization.html#macro-effects",
    "href": "data-visualization.html#macro-effects",
    "title": "Data Visualization",
    "section": "Macro Effects",
    "text": "Macro Effects\n\nBTC & SP500 vs USD\n\n\n\n\nCode\nif (all(c(\"Bitcoin\", \"SP500\") %in% colnames(prices_xts))) {\n\n# Convert to monthly levels\n\nm_prices &lt;- tryCatch(\nxts::to.monthly(prices_xts[, c(\"Bitcoin\", \"SP500\", \"USD\")],\nindexAt = \"lastof\", OHLC = FALSE),\nerror = function(e) NULL\n)\n\nif (!is.null(m_prices)) {\nbtc_m &lt;- m_prices[, \"Bitcoin\"]\nspx_m &lt;- m_prices[, \"SP500\"]\nusd_m &lt;- if (\"USD\" %in% colnames(m_prices)) m_prices[, \"USD\"] else NULL\n\n\n\n\nm_ret &lt;- merge(diff(log(btc_m)), diff(log(spx_m)))\ncolnames(m_ret) &lt;- c(\"BTC_ret\", \"SPX_ret\")\n\ndf &lt;- tibble(\n  Date    = index(m_ret),\n  BTC_ret = as.numeric(m_ret[, \"BTC_ret\"]),\n  SPX_ret = as.numeric(m_ret[, \"SPX_ret\"])\n)\n\nif (!is.null(usd_m)) {\n  df &lt;- df |&gt;\n    left_join(\n      tibble(\n        Date = index(usd_m),\n        USD  = as.numeric(usd_m)\n      ),\n      by = \"Date\"\n    )\n}\n\nz &lt;- function(x) {\n  if (all(is.na(x)) || sd(x, na.rm = TRUE) == 0) return(rep(NA_real_, length(x)))\n  as.numeric(scale(x))\n}\n\ndf &lt;- df |&gt;\n  mutate(\n    BTC_z = z(BTC_ret),\n    SPX_z = z(SPX_ret),\n    USD_z = if (!is.null(usd_m)) z(USD) else NA_real_\n  )\n\nggplot(df, aes(Date)) +\n  geom_line(aes(y = BTC_z, color = \"BTC (z)\"), linewidth = 1) +\n  geom_line(aes(y = SPX_z, color = \"S&P 500 (z)\"), linewidth = 1, alpha = 0.8) +\n  geom_line(aes(y = USD_z, color = \"USD Index (z)\"),\n            linewidth = 0.9, linetype = \"dashed\", alpha = 0.8) +\n  labs(\n    title = \"Bitcoin & S&P vs USD Dollar Strength (Monthly, Z-scored)\",\n    subtitle = \"When the dollar strengthens, risk assets often struggle\",\n    x = NULL,\n    y = \"Z-score (standardized units)\",\n    color = NULL\n  ) +\n  scale_color_manual(\n    values = c(\n      \"BTC (z)\"        = \"#FF9500\",\n      \"S&P 500 (z)\"    = \"#1f77b4\",\n      \"USD Index (z)\"  = \"#7f7f7f\"\n    )\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"top\")\n\n\n} else {\ncat(\"Could not build monthly macro overlay.\\n\")\n}\n} else {\ncat(\"Need Bitcoin and SP500 price series for macro overlay.\\n\")\n}\n\n\n\n\n\n\n\n\n\nWhen the dollar strengthens (gray dashed line spikes upward), both Bitcoin and S&P 500 often experience downward pressure, visible in the synchronized drops during 2022 and late 2024. This makes sense since a strong dollar typically signals risk-off sentiment and tighter financial conditions globally. Both assets show similar sensitivity to dollar movements, reinforcing that Bitcoin still behaves somewhat like a risk asset responsive to macro liquidity conditions. The z-scored format (standardized units) makes it easier to compare movements across different scales."
  },
  {
    "objectID": "data-visualization.html#conclusion",
    "href": "data-visualization.html#conclusion",
    "title": "Data Visualization",
    "section": "Conclusion",
    "text": "Conclusion\n\nKey Findings from Market Behavior Analysis\nThis data visualization page reveals critical insights into how Bitcoin interacts with traditional financial markets across multiple dimensions. Bitcoin has delivered extraordinary returns since 2019, gaining over 3000% compared to roughly 300% for both S&P 500 and NASDAQ, but this outperformance comes with substantially higher risk. Bitcoin’s volatility consistently runs 2-4x higher than equities, with dramatic spikes exceeding 160% annualized volatility during the March 2020 crash and 2021-2022 crypto cycle, while the S&P 500 maintains relatively stable volatility between 10-30%.\n\n\nEvolution of Market Relationships\nThe correlation analysis demonstrates that Bitcoin’s relationship with traditional markets has undergone significant transformation. During 2020-2022, Bitcoin tracked closely with both NASDAQ and S&P 500 (correlations often above 0.5), behaving like a risk asset during the pandemic boom and subsequent Fed tightening. However, since late 2024, these correlations have weakened significantly, suggesting Bitcoin is transitioning from moving in lockstep with equities to establishing more independent price action. The VIX relationship remains consistently negative throughout, meaning Bitcoin tends to rise when market fear drops, though recent years show weaker correlation with Bitcoin’s swings compared to traditional market stress signals.\n\n\nMacro Sensitivity and Crisis Dynamics\nBitcoin demonstrates clear sensitivity to macroeconomic conditions, particularly dollar strength. When the dollar strengthens, both Bitcoin and S&P 500 often experience downward pressure, reinforcing that Bitcoin still behaves somewhat like a risk asset responsive to macro liquidity conditions. Major VIX spikes during crisis moments (COVID crash, Ukraine war, FTX collapse, SVB crisis) consistently trigger sharp selloffs across markets, but Bitcoin’s reaction to these traditional market fear signals has become more muted in 2024-2025 compared to earlier years. This pattern suggests possible market maturation or a shift in investor composition less spooked by traditional equity market stress.\n\n\nImplications for Spillover Analysis\nThese visualizations establish the empirical foundation for understanding volatility spillovers between crypto and traditional markets. Bitcoin’s high but declining volatility, evolving correlations with equities, persistent negative relationship with market fear indicators, and sensitivity to dollar strength all point to complex transmission mechanisms that warrant deeper investigation through formal time series modeling. The evidence suggests Bitcoin is neither fully independent nor perfectly correlated with traditional markets, occupying a dynamic middle ground where spillover effects likely vary by market regime, crisis type, and time horizon. This sets the stage for the subsequent univariate, multivariate, and volatility modeling work that will quantify these relationships more precisely."
  },
  {
    "objectID": "data-sources.html",
    "href": "data-sources.html",
    "title": "Data Sources",
    "section": "",
    "text": "Data Sources This project uses daily macro-financial data obtained directly from the Federal Reserve Economic Data (FRED) API through the R package quantmod. All datasets were downloaded programmatically to ensure reproducibility and consistent formatting.\n\nFederal Reserve Economic Data (FRED) All price and index series used in the analysis come from FRED, including:\n\n\n\n\n\n\n\n\n\nAsset / Variable\nFRED Code\nDescription\n\n\n\n\nS&P 500 Index\nSP500\nDaily closing levels of the S&P 500, representing broad U.S. equity market performance.\n\n\nNASDAQ Composite Index\nNASDAQCOM\nTech-heavy U.S. equity index capturing large-cap and growth-oriented stocks.\n\n\nVIX (CBOE Volatility Index)\nVIXCLS\nDaily closing value of implied volatility (“fear index”).\n\n\nBitcoin Price (USD)\nCBBTCUSD\nDaily Bitcoin–USD price from FRED’s digital asset database.\n\n\nU.S. Dollar Index\nDTWEXBGS\nNominal broad trade-weighted U.S. Dollar Index.\n\n\n\nThese were loaded using:\ngetSymbols(symbol, src = \"FRED\", from = start_date, to = end_date)\n\nPreprocessing & Derived Variables From the raw FRED price levels, the following were constructed:\n\n\nDaily log returns: r_t = log(P_t) - log(P_{t-1}) Used for ARIMA, SARIMA, GARCH, VAR/ARIMAX, and all deep learning models.s\nMerged time-aligned dataset All series were merged by date and na.omit() was applied to ensure clean modeling.\nFeature matrices Used in multivariate ARIMAX and deep learning models (SP500, NASDAQ, VIX, USD as predictors)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Soong Ping Hill. I am from San Francisco, California, and have a Bachelors Degree in Neuroscience and Minor in Data Science. I am currently pursuing a M.S degree in Data Science and Analytics at Georgetown University’s DSAN program.\nThis program has allowed me to develop a strong foundation in data-driven methodologies, machine learning, and advanced analytics while honing my skills in extracting meaningful insights from large datasets to solve real-world problems.\nI am passionate about leveraging data science to uncover patterns, drive decision-making, and contribute to impactful solutions across industries."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\nGeorgetown University | Washington, D.C.\n- Master’s in Data Science (DSAN)\n- GPA: 3.95\n- Academic Awards: Returning Student Scholarship\nBoston University College of Arts and Science | Boston, MA\n- Bachelor of Arts in Neuroscience, Minor in Data Science\n- GPA: 3.57\n- Academic Awards: Deans List"
  },
  {
    "objectID": "about.html#work-experience",
    "href": "about.html#work-experience",
    "title": "About Me",
    "section": "Work Experience",
    "text": "Work Experience\nSilkroll | Oakland, CA\nData Analyst | April 2025 – August 2025\n\nDesigned and executed MongoDB aggregation pipelines utilizing Metabase to analyze company-wide financial transactions, service fees, and inventory across cash and points-based orders.\n\nBuilt and optimized interactive dashboards to track sales, returns, and revenue trends, ensuring data accuracy and reliability across historical records.\n\nAutomated financial reporting processes, reducing manual effort and improving visibility for stakeholders.\n\nCenter for Retirement Initiatives | Washington, D.C.\nGraduate Student Research Assistant (Georgetown University) | October 2024 – March 2025\n\nAnalyzed state program data, creating monthly reports on financial metrics and retirement trends in Tableau.\n\nConducted data collection, cleaning, and dataset uploads using SQL and Python, ensuring data integrity.\n\nCollaborated with CRI stakeholders to identify new research inquiries and provide evidence-based insights.\n\nRESET.BUILD | Shanghai, China\nData Science Intern (BU Shanghai Internship Program) | June 2024 – August 2024\n\nDeveloped Python scripts to automate big data cleaning, extraction, format corrections, and air quality analysis, saving 8 hours of manual work per dataset.\n\nCollaborated with cross-functional teams to design and implement data dashboards in Google Looker Studio, improving data access and driving internal insights.\n\nEnhanced front-end UI using HTML and CSS, ensuring a professional and user-friendly experience.\n\nEcommerce Store | San Francisco, CA\nOwner and Manager | June 2023 – Present\n\nManaged e-commerce store with $9,000 in revenue, overseeing inventory, customer service, SEO, and marketing strategies.\n\nApplied business insights to adjust pricing strategies and product offerings, enhancing store profitability.\n\nRadboud University | Nijmegen, Netherlands\nMachine Learning Research Intern | May 2023 – July 2023\n\nProgrammed pipeline to cut, synchronize, and analyze over 2 TB of neuronal data and video.\n\nUtilized DeepLabCut pose-estimation to analyze cortico-hippocampal activity during memory consolidation.\n\nPartnered with a diverse research team and mentored new interns, creating a written guide for onboarding.\n\nUCSF Medical Center – Anesthesia | San Francisco, CA\nData Research Intern | May 2022 – August 2022\n\nContributed to a research study on pupillary unrest in ambient light in response to opioids.\n\nCleaned and visualized data for analysis, designing figures and reports.\n\nPublication: Merlin D. Larsson, Rachel McKay, Soong Ping Hill, Practical Guide to Portable Pupillometry"
  },
  {
    "objectID": "about.html#projects",
    "href": "about.html#projects",
    "title": "About Me",
    "section": "Projects",
    "text": "Projects\n\nVoting Rate Analysis and Predictive Modeling\n\nIntegrated U.S Census Bureau API to collect and process demographic and socioeconomic data related to voting rates\nApplied clustering techniques (K-Means, DBSCAN, Agglomerative Clustering) to segment voters by behavior\nBuilt and evaluated predictive models (Random Forest, Regression) to analyze key factors influencing voting rates and predict voter participation trends\n\n\n\nStatistical Analysis of Airbnb Listing Prices Across Cities\n\nConducted statistical analysis (t-tests, ANOVAs, correlation, chi-squared) to evaluate how location, host status, and other factors impact Airbnb pricing\nVisualized data patterns with ggplot and presented actionable insights to optimize pricing strategies for hosts\n\n\n\nCovid-19 Data Analysis and Policy Identification\n\nIntegrated COVID-19 data from three sources into data lake via Azure Data Factory, prepared for processing in Azure Synapse, and analyzed in Power BI to identify the top three policies for controlling COVID spread\n\n\n\nAnalysis of U.S Airline Operational Performance\n\nQueried Bureau of Transportation Statistics flight data using SQL to analyze delays and cancellations across airlines and airports\nCreated an R-based report with visualizations to assess operational efficiency and highlight opportunities for improving flight scheduling and customer experience\nIdentified key delay and cancellation factors, providing data-driven insights to enhance airline performance\n\n\n\nNBA Player Performance Model\n\nBuilt and optimized an LSTM deep learning model to forecast NBA player performance based on historical game data\nModel explained 68% of variation in player performance, improving predictive power over traditional methods\nProvided data-driven insights for player evaluation and strategy optimization in sports management"
  },
  {
    "objectID": "about.html#technical-skills",
    "href": "about.html#technical-skills",
    "title": "About Me",
    "section": "Technical Skills",
    "text": "Technical Skills\n\nProgramming & Data Science\nProficient: Python (pandas, numpy, scikit-learn, matplotlib, seaborn), R (ggplot2, dplyr, tidyverse), SQL, PyTorch, TensorFlow\nFamiliar: Java, C++, MATLAB, Swift, JavaScript, HTML, CSS\n\n\nMachine Learning & Analytics\nProficient: Supervised Learning (Random Forest, Regression, SVM), Unsupervised Learning (K-Means, DBSCAN, Hierarchical Clustering), Deep Learning (LSTM, Neural Networks), Feature Selection, Cross-Validation, Statistical Analysis\nFamiliar: NLP, Computer Vision, Time Series Analysis, A/B Testing, Bayesian Methods\n\n\nData Engineering & Cloud\nProficient: AWS (S3, EC2, Lambda), Microsoft Azure (Data Factory, Synapse), SQL Server, PostgreSQL, Git/GitHub, Hadoop, Snowflake\nFamiliar: Google Cloud Platform, Apache Spark, Docker, Kubernetes, DBT, Apache Airflow\n\n\nVisualization & BI Tools\nProficient: Tableau, Looker Studio, Power BI, Matplotlib, Seaborn, ggplot2, Plotly\nFamiliar: D3.js, Bokeh, ArcGIS,\n\n\nDevelopment & Collaboration\nProficient: Git/GitHub, Jupyter, RStudio, VS Code, Excel, PowerPoint, Visio\nFamiliar: Linux/Unix, Bash scripting\nSpoken Languages: English (Native), Mandarin (Fluent), Cantonese (Conversational)\nSpoken Languages: English, Mandarin, Cantonese\nDownload Resume (PDF)"
  },
  {
    "objectID": "data-visualization.html#key-findings",
    "href": "data-visualization.html#key-findings",
    "title": "Data Visualization",
    "section": "Key Findings",
    "text": "Key Findings\n\nMarket Behavior\nBitcoin has dramatically outperformed equities since 2019 (3000%+ vs. ~300% for S&P 500 and NASDAQ) but with far greater risk. Its volatility is consistently 2–4× higher and spikes sharply during crises (e.g., 160%+ during 2020 and 2021–22), whereas equity volatility remains far more stable.\n\n\nShifting Relationships\nCorrelations show that Bitcoin moved closely with equities from 2020–2022 (often &gt;0.5), behaving like a high-beta risk asset. Since late 2024, these correlations have weakened, indicating more independent behavior. Bitcoin’s correlation with the VIX remains negative—rising when fear falls—though this relationship has also softened recently.\n\n\nMacro Sensitivity & Crisis Patterns\nBitcoin responds meaningfully to macro conditions, especially dollar strength, which pressures both Bitcoin and equities. Historically, major VIX spikes triggered simultaneous selloffs across markets, but Bitcoin’s reactions in 2024–2025 appear more muted, suggesting market maturation or changing investor profiles.\n\n\nImplications for Spillover Analysis\nThese patterns set the foundation for formal spillover modeling. Bitcoin exhibits high but declining volatility, shifting equity correlations, persistent (but weakening) sensitivity to market stress, and clear macro-linkages. Collectively, these trends imply that spillover effects are dynamic, regime-dependent, and likely asymmetric—motivating the deeper univariate, multivariate, and volatility analyses that follow."
  },
  {
    "objectID": "multivariate-ts-models.html#data-perperation",
    "href": "multivariate-ts-models.html#data-perperation",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "Data Perperation",
    "text": "Data Perperation\n\nVisualizationData Loading\n\n\n\n\nCode\nsuppressPackageStartupMessages({\nlibrary(quantmod); library(zoo); library(xts)\nlibrary(tidyverse); library(forecast); library(tseries)\nlibrary(ggplot2)\n})\n\n\n\n\n\n\nCode\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\n\n\nload_fred_data &lt;- function(symbol, start, end) {\ntryCatch({\ngetSymbols(symbol, src = \"FRED\", from = start, to = end, auto.assign = FALSE)\n}, error = function(e) {\ncat(sprintf(\"Warning: Could not load %s (%s)\\n\", symbol, e$message))\nNULL\n})\n}\n\n# Load and merge \n\nif (!exists(\"price_data\") ||\n!all(c(\"Date\",\"SP500\",\"VIX\",\"Bitcoin\",\"USD\") %in% names(price_data))) {\n\nsp500_data &lt;- load_fred_data(\"SP500\",    start_date, end_date)\nvix_data   &lt;- load_fred_data(\"VIXCLS\",   start_date, end_date)\nbtc_data   &lt;- load_fred_data(\"CBBTCUSD\", start_date, end_date)\nusd_data   &lt;- load_fred_data(\"DTWEXBGS\", start_date, end_date)\nnasdaq_data &lt;- load_fred_data(\"NASDAQCOM\", start_date, end_date)  \n\nmerged &lt;- merge(\nSP500   = sp500_data,\nVIX     = vix_data,\nBitcoin = btc_data,\nUSD     = usd_data,\nNASDAQ  = nasdaq_data\n)\n\nprice_data &lt;- fortify.zoo(merged)\ncolnames(price_data) &lt;- c(\"Date\",\"SP500\",\"VIX\",\"Bitcoin\",\"USD\", \"NASDAQ\")\nprice_data &lt;- price_data |&gt; arrange(Date) |&gt; na.omit()\n}\n\n# Daily log-returns \n\nreturns &lt;- price_data |&gt;\nmutate(\nSP500_ret   = c(NA, diff(log(SP500))),\nVIX_ret     = c(NA, diff(log(VIX))),\nBitcoin_ret = c(NA, diff(log(Bitcoin))),\nUSD_ret     = c(NA, diff(log(USD))),\n NASDAQ_ret  = c(NA, diff(log(NASDAQ)))  \n) |&gt;\nna.omit()"
  },
  {
    "objectID": "multivariate-ts-models.html#data-preparation",
    "href": "multivariate-ts-models.html#data-preparation",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nData Loading\n\n\n\n\nCode\nsuppressPackageStartupMessages({\nlibrary(quantmod); library(zoo); library(xts)\nlibrary(tidyverse); library(forecast); library(tseries)\nlibrary(ggplot2)\n})\n\n\n\n\nCode\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\n\n\nload_fred_data &lt;- function(symbol, start, end) {\ntryCatch({\ngetSymbols(symbol, src = \"FRED\", from = start, to = end, auto.assign = FALSE)\n}, error = function(e) {\ncat(sprintf(\"Warning: Could not load %s (%s)\\n\", symbol, e$message))\nNULL\n})\n}\n\n# Load and merge \n\nif (!exists(\"price_data\") ||\n!all(c(\"Date\",\"SP500\",\"VIX\",\"Bitcoin\",\"USD\") %in% names(price_data))) {\n\nsp500_data &lt;- load_fred_data(\"SP500\",    start_date, end_date)\nvix_data   &lt;- load_fred_data(\"VIXCLS\",   start_date, end_date)\nbtc_data   &lt;- load_fred_data(\"CBBTCUSD\", start_date, end_date)\nusd_data   &lt;- load_fred_data(\"DTWEXBGS\", start_date, end_date)\nnasdaq_data &lt;- load_fred_data(\"NASDAQCOM\", start_date, end_date)  \n\nmerged &lt;- merge(\nSP500   = sp500_data,\nVIX     = vix_data,\nBitcoin = btc_data,\nUSD     = usd_data,\nNASDAQ  = nasdaq_data\n)\n\nprice_data &lt;- fortify.zoo(merged)\ncolnames(price_data) &lt;- c(\"Date\",\"SP500\",\"VIX\",\"Bitcoin\",\"USD\", \"NASDAQ\")\nprice_data &lt;- price_data |&gt; arrange(Date) |&gt; na.omit()\n}\n\n# Daily log-returns \n\nreturns &lt;- price_data |&gt;\nmutate(\nSP500_ret   = c(NA, diff(log(SP500))),\nVIX_ret     = c(NA, diff(log(VIX))),\nBitcoin_ret = c(NA, diff(log(Bitcoin))),\nUSD_ret     = c(NA, diff(log(USD))),\n NASDAQ_ret  = c(NA, diff(log(NASDAQ)))  \n) |&gt;\nna.omit()\n\ncat(\n  sprintf(\n    \"Data loaded — SP500: %d | VIX: %d | BTC: %d | USD: %d | NASDAQ: %d\\n\",\n    nrow(sp500_data),\n    nrow(vix_data),\n    nrow(btc_data),\n    nrow(usd_data),\n    nrow(nasdaq_data)\n  )\n)\n\n\nData loaded — SP500: 1753 | VIX: 1753 | BTC: 2453 | USD: 1753 | NASDAQ: 1753"
  },
  {
    "objectID": "deep-learning-ts.html#results-and-insights",
    "href": "deep-learning-ts.html#results-and-insights",
    "title": "Deep Learning for TS",
    "section": "Results and Insights:",
    "text": "Results and Insights:\nAcross both univariate and multivariate settings, the deep learning models exhibit clear and consistent performance patterns. Gated architectures (GRU and LSTM) outperform the vanilla RNN, confirming that mechanisms designed to control information flow are better suited for noisy, weakly predictable series such as Bitcoin returns. In the univariate case, LSTM achieves the lowest RMSE (≈ 0.719), followed closely by GRU (≈ 0.721), with the RNN trailing (≈ 0.727). Performance differences are modest but systematic, indicating diminishing returns from increased architectural complexity.\nIntroducing macro-financial variables (S&P 500, NASDAQ, VIX, and USD Index) leads to small but consistent improvements in forecast accuracy across all models. In the multivariate setting, the GRU performs best overall (RMSE ≈ 0.714), slightly outperforming the LSTM (≈ 0.716), while the RNN remains the weakest performer. This shift suggests that GRUs strike an effective balance between flexibility and regularization when additional predictors are present, capturing weak cross-market signals without overfitting.\nTraining and validation curves across all architectures are stable, with no evidence of divergence or overfitting. Forecasts from both univariate and multivariate models remain highly smoothed and mean-reverting, oscillating around zero rather than reacting to extreme price movements. This behavior reflects the combined effects of MSE loss, dropout, and early stopping, which prioritize conditional mean accuracy and penalize large, unpredictable shocks. While this improves RMSE, it limits the models’ ability to anticipate sudden crashes or rallies.\nCompared with classical time-series approaches such as ARIMA, the deep learning models demonstrate superior stability and a greater capacity to capture nonlinear dependencies and interaction effects. However, the absolute gains remain incremental. Multivariate deep learning improves short-term predictive performance but does not overcome the fundamental unpredictability of Bitcoin returns. As a result, GRU and LSTM models are best suited for short-horizon"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "A time series is any sequence of measurements taken at regular, equally spaced intervals—seconds, minutes, hours, days, months, quarters, or years. Common examples include weather (daily temperature or rainfall), financial markets (daily stock prices or returns), industry indicators (monthly production or sales), electricity demand, traffic counts, and hospital admissions. In time-series analysis we study how these values evolve: their level, trend, seasonal or calendar patterns (e.g., weekdays vs. weekends, holiday effects), cycles, and anomalies. Typical goals are to describe behavior clearly, forecast future values, and quantify the impact of events or policies.\nBecause observations are ordered in time, nearby points tend to be correlated (autocorrelation). This violates the independent-and-identically-distributed assumption behind many standard statistical methods, so naïve cross-sectional tools often mislead. Time-series work must explicitly handle dependence, trend, and seasonality—for example by differencing, seasonal adjustment, and models that use lagged values and errors (e.g., ARIMA/SARIMA, ARIMAX/SARIMAX with external drivers, VAR for multiple series, state-space/ETS, or GARCH when volatility changes over time). Analysts also watch for structural breaks (e.g., policy shifts, COVID), outliers, and missing periods, and they evaluate models with time-aware validation (rolling or blocked splits) rather than random shuffles."
  },
  {
    "objectID": "index.html#what-is-a-time-series",
    "href": "index.html#what-is-a-time-series",
    "title": "Time Series Analysis",
    "section": "",
    "text": "A time series is any sequence of measurements taken at regular, equally spaced intervals—seconds, minutes, hours, days, months, quarters, or years. Common examples include weather (daily temperature or rainfall), financial markets (daily stock prices or returns), industry indicators (monthly production or sales), electricity demand, traffic counts, and hospital admissions. In time-series analysis we study how these values evolve: their level, trend, seasonal or calendar patterns (e.g., weekdays vs. weekends, holiday effects), cycles, and anomalies. Typical goals are to describe behavior clearly, forecast future values, and quantify the impact of events or policies.\nBecause observations are ordered in time, nearby points tend to be correlated (autocorrelation). This violates the independent-and-identically-distributed assumption behind many standard statistical methods, so naïve cross-sectional tools often mislead. Time-series work must explicitly handle dependence, trend, and seasonality—for example by differencing, seasonal adjustment, and models that use lagged values and errors (e.g., ARIMA/SARIMA, ARIMAX/SARIMAX with external drivers, VAR for multiple series, state-space/ETS, or GARCH when volatility changes over time). Analysts also watch for structural breaks (e.g., policy shifts, COVID), outliers, and missing periods, and they evaluate models with time-aware validation (rolling or blocked splits) rather than random shuffles."
  },
  {
    "objectID": "index.html#volatility-spillovers-across-asset-classes",
    "href": "index.html#volatility-spillovers-across-asset-classes",
    "title": "Time Series Analysis",
    "section": "Volatility Spillovers Across Asset Classes",
    "text": "Volatility Spillovers Across Asset Classes\nBig Picture Goal\nThis project investigates how major financial markets interact, focusing on whether Bitcoin, the S&P 500, the VIX (fear index), and the U.S. Dollar Index influence each other’s returns and volatility. The goal is to understand whether crypto markets transmit risk to traditional finance or primarily react to it.\nAnalytical Framework\nTo answer the big-picture question, the analysis proceeds through four structured layers:\n\nExploratory Data Analysis (EDA)\n\nI begin by examining long-term price trends, return distributions, rolling volatilities, and pairwise correlations across Bitcoin, S&P 500, NASDAQ, VIX, and USD. Key diagnostic finding: Returns are stationary for all assets (post-differencing), but price levels are not.\n\nUnivariate Modeling (ARIMA / SARIMA)\n\nUsing daily returns, I estimate ARIMA models for each asset to capture their individual dynamics.\nFindings:\nBTC returns ≈ white noise with minimal predictability.\nSP500 and NASDAQ exhibit stronger autocorrelation, supporting ARIMA(2,0,2) and ARIMA(4,0,3).\nVIX is mean-reverting, best captured by ARIMA(3,0,1).\nUSD index behaves almost pure white noise.\nThese models serve as a benchmark for whether multivariate models add value.\n\nMultivariate Modeling (ARIMAX Spillovers)\n\nI then test for return spillovers by regressing each asset’s returns on the others:\nBitcoin is influenced by SP500 returns (positive) and VIX (slightly negative).\nS&P 500 is significantly driven by VIX (strong negative effect) and lightly by Bitcoin.\nVIX responds strongly to SP500 (negative), but barely to BTC.\nUSD shows no meaningful connection to BTC or SP500.\nForecast comparison shows that including other assets slightly improves accuracy, supporting mild cross-market influence.\n\nVolatility Modeling (ARCH–GARCH)\n\nTo analyze volatility clustering:\nSP500 volatility fits ARMA(2,1)–GARCH(2,1) → captures strong persistence and ARCH effects.\nBitcoin volatility fits ARMA(1,0)–GARCH(2,1) → weaker clustering but clear volatility persistence.\nThis framework identifies whether volatility in one market tends to spill into another.\n\nEvent Analysis (Interrupted Time Series – FTX Collapse)\n\nFinally, I examine whether the FTX collapse created a structural break in Bitcoin behavior.\nResult:\nNo statistically significant change in BTC return mean or trend after FTX.\nBTC experienced short-term turbulence, but no long-run shift.\nThis suggests crypto markets absorb shocks quickly, with no persistent transformation in return behavior."
  },
  {
    "objectID": "index.html#research-papers",
    "href": "index.html#research-papers",
    "title": "Time Series Analysis",
    "section": "Research Papers",
    "text": "Research Papers\nDiebold & Yilmaz (2012): Better to Give than to Receive: Predictive Directional Measurement of Volatility Spillovers — foundational connectedness index.\nEngle (2002): Dynamic Conditional Correlation: A Simple Class of Multivariate GARCH Models — for evolving correlations.\nEngle & Kroner (1995): Multivariate Simultaneous GARCH — BEKK parameterization for volatility spillovers.\nBaruník & Křehlík (2018): Measuring the Frequency Dynamics of Financial Connectedness — short-run vs long-run spillover methods.\nAntonakakis & Gabauer (2017, 2018): Time-Varying Parameter VAR-based Connectedness Measures — dynamic connectedness without rolling windows.\nRecent empirical studies show that crypto shocks spill into equities, commodities, bonds, and volatility indices, especially during stress periods (COVID, 2022 crashes, Fed rate hikes)."
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "Conclusions",
    "section": "",
    "text": "Across all analyses, the evidence indicates that daily financial returns are highly unpredictable, but their volatility and short-run interactions follow clear, structured patterns. ARIMA models showed that return dynamics for SP500 and Bitcoin are extremely limited, with only weak autocorrelation and very small cross-asset spillovers. Although the multivariate ARIMAX models detected statistically significant links—for example, equity returns responding weakly to VIX or Bitcoin—the magnitudes were tiny, implying minimal economic spillover in daily return behavior.\nVolatility, however, revealed more meaningful structure. GARCH modeling showed pronounced volatility clustering in both SP500 and Bitcoin, but with different regimes: SP500 volatility is slow-moving and highly persistent, while Bitcoin volatility responds sharply to shocks and fades more rapidly. These differences imply asymmetric volatility spillovers, where shocks do not propagate evenly across markets and where cryptocurrencies operate under a noisier, more idiosyncratic volatility process.\nDeep learning models improved forecasting modestly. Both univariate and multivariate LSTM/GRU networks stabilized predictions, captured nonlinearities, and outperformed ARIMA, though they still produced smoothed forecasts due to the dominance of noise. Adding macro-financial variables led to small RMSE gains, confirming weak but measurable cross-market influences, yet insufficient to overcome the fundamental unpredictability of returns.\nOverall, the results show that return spillovers are weak, volatility spillovers are asymmetric, and forecasting power remains limited across all models. Classical and deep learning methods each reveal different aspects of market behavior: ARIMA captures short-term memory, GARCH models volatility persistence, and deep learning captures nonlinear structure. Together, they demonstrate that while precise return forecasting is infeasible, understanding volatility dynamics and cross-market interactions provides meaningful insights for risk management, stress testing, and short-horizon decision support.\nThe interrupted time-series analysis shows that the FTX collapse did not create a meaningful structural break in Bitcoin’s daily returns. Both the pre- and post-event trends are nearly flat, regression coefficients for level and slope changes are statistically insignificant, and the distribution of returns remains almost identical before and after the event. While the collapse triggered a brief spike in volatility, Bitcoin quickly reverted to its typical noisy, mean-reverting behavior. This reinforces the broader conclusion: even major news events create only short-lived disturbances, not persistent shifts that improve predictability."
  },
  {
    "objectID": "univariate-ts-models.html#results-and-insights",
    "href": "univariate-ts-models.html#results-and-insights",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Results and Insights",
    "text": "Results and Insights\nAcross Bitcoin, the S&P 500, NASDAQ, VIX, and the USD Index, price levels are non-stationary while daily log returns are stationary with minimal autocorrelation—consistent with the stylized fact that financial returns behave like near–white noise.\nARIMA models pick up only small, short-lived dynamics: simple MA(1)/MA(2) or low-order ARMA structures for most assets, with NASDAQ fitting a higher-order ARIMA(4,0,3). These models slightly outperform naïve forecasts but provide only marginal predictive power. SARIMA adds no benefit, confirming that daily financial returns do not contain meaningful seasonal patterns.\nEquity indexes (SP500, NASDAQ) show modest autoregressive structure, VIX displays short-run mean reversion, and Bitcoin and USD behave closest to pure noise. Even so, predictive improvements remain limited and forecasts quickly revert toward zero.\nOverall, univariate ARIMA models help characterize return behavior but cannot meaningfully forecast price movements. Financial markets remain highly efficient at the daily horizon, leaving only tiny pockets of short-term predictability."
  },
  {
    "objectID": "financial-ts-models.html#data-preparation",
    "href": "financial-ts-models.html#data-preparation",
    "title": "Financial Time Series Models (ARCH/GARCH)",
    "section": "",
    "text": "Data Loading\n\n\n\n\nCode\nsuppressPackageStartupMessages({\nlibrary(tidyverse)\nlibrary(forecast)\nlibrary(tseries)\nlibrary(FinTS)\nlibrary(rugarch)\nlibrary(gridExtra)\n})\n\nsuppressPackageStartupMessages({\n  library(quantmod); library(zoo); library(xts)\n  library(tidyverse); library(forecast); library(tseries)\n})\n\nstart_date &lt;- as.Date(\"2019-01-01\")\nend_date   &lt;- as.Date(\"2025-09-18\")\n\nload_fred_data &lt;- function(symbol, start, end) {\n  tryCatch(\n    getSymbols(symbol, src=\"FRED\", from=start, to=end, auto.assign=FALSE, quiet = TRUE),\n    error = function(e) {\n      cat(\"FAILED to load:\", symbol, \"\\nUsing fallback dummy series...\\n\")\n      xts(rep(1, 1000), order.by=seq(start, length.out=1000, by=\"days\"))\n    }\n  )\n}\n\nsp500_data &lt;- load_fred_data(\"SP500\",    start_date, end_date)\nvix_data   &lt;- load_fred_data(\"VIXCLS\",   start_date, end_date)\nbtc_data   &lt;- load_fred_data(\"CBBTCUSD\", start_date, end_date)\n\nmerged &lt;- merge(SP500 = sp500_data, VIX = vix_data, Bitcoin = btc_data)\nprice_data &lt;- fortify.zoo(merged)\ncolnames(price_data) &lt;- c(\"Date\",\"SP500\",\"VIX\",\"Bitcoin\")\nprice_data &lt;- price_data |&gt; arrange(Date) |&gt; na.omit()\n\nreturns &lt;- price_data |&gt;\n  mutate(\n    SP500_ret   = c(NA, diff(log(SP500))),\n    VIX_ret     = c(NA, diff(log(VIX))),\n    Bitcoin_ret = c(NA, diff(log(Bitcoin)))\n  ) |&gt;\n  na.omit()\n\ncat(\"Loaded:\", nrow(returns), \"returns\\n\")\n\n\nLoaded: 1686 returns\n\n\n\n\nCode\n# S&P 500 returns\n\nspx_ret   &lt;- as.numeric(returns$SP500_ret)\nspx_dates &lt;- returns$Date\n\n# Bitcoin returns\n\nbtc_ret   &lt;- as.numeric(returns$Bitcoin_ret)\nbtc_dates &lt;- returns$Date\n\ncat(sprintf(\"Length of SPX returns: %d observations\\n\", length(spx_ret)))\n\n\nLength of SPX returns: 1686 observations\n\n\nCode\ncat(sprintf(\"Length of BTC returns: %d observations\\n\", length(btc_ret)))\n\n\nLength of BTC returns: 1686 observations"
  },
  {
    "objectID": "financial-ts-models.html#results-and-insights",
    "href": "financial-ts-models.html#results-and-insights",
    "title": "Financial Time Series Models (ARCH/GARCH)",
    "section": "Results and Insights",
    "text": "Results and Insights\nBoth SP500 and Bitcoin show standard financial behavior: price levels are non-stationary, but returns are stationary with almost no autocorrelation, leading to simple mean models (ARMA(2,1) for SP500, ARMA(1,0) for BTC). Despite minimal return predictability, both series exhibit strong volatility clustering, which the selected GARCH(2,1) models capture well. SP500 shows very persistent volatility (slow decay after shocks), while Bitcoin’s volatility is more reactive but less persistent, consistent with its higher risk profile. Overall, returns remain essentially unpredictable, but volatility is highly structured, and GARCH provides a realistic model of each asset’s risk dynamics."
  }
]