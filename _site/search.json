[
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "This project explores the connected nature of modern financial markets by examining how volatility, price fluctuation and market uncertainty spread across different asset classes. This analysis specifically focuses on the emerging cryptocurrency market and how they may influence traditional financial instruments, including equities, commodities, bonds, and volatility indices.\nVolatility spillovers occur when price shocks or periods of uncertainty in one market affect other markets, creating a domino effect of financial instability or opportunity. While traditional spillover research has long studied connections between established markets (such as how U.S. stock market crashes affect European markets), the rapid growth of cryptocurrency markets has introduced an entirely new dynamic to global financial systems.\nThe central question driving this research is: How do cryptocurrency market fluctuations propagate through traditional financial markets, and what does this mean for investors, regulators, and the broader economy? This investigation is particularly relevant given recent events such as the 2022 cryptocurrency market collapse, the FTX exchange failure, Federal Reserve interest rate policies, and ongoing debates about cryptocurrency regulation and systemic risk.\nUnlike traditional financial assets backed by physical assets or cash flows, cryptocurrencies represent a new category of digital assets with unique characteristics: 24/7 trading, high volatility, limited regulation, and strong retail investor participation. Understanding how these distinctive features interact with established financial markets is crucial for modern portfolio management, risk assessment, and financial stability monitoring.\nThis analysis goes beyond simple correlation studies to examine the directional flow of volatility, the persistence of spillover effects, and how these relationships change during different market conditions—from calm periods to major financial crises."
  },
  {
    "objectID": "introduction.html#volatility-spillovers-across-asset-classes-understanding-cryptocurrencys-impact-on-traditional-financial-markets",
    "href": "introduction.html#volatility-spillovers-across-asset-classes-understanding-cryptocurrencys-impact-on-traditional-financial-markets",
    "title": "Introduction",
    "section": "",
    "text": "This project explores the connected nature of modern financial markets by examining how volatility, price fluctuation and market uncertainty spread across different asset classes. This analysis specifically focuses on the emerging cryptocurrency market and how they may influence traditional financial instruments, including equities, commodities, bonds, and volatility indices.\nVolatility spillovers occur when price shocks or periods of uncertainty in one market affect other markets, creating a domino effect of financial instability or opportunity. While traditional spillover research has long studied connections between established markets (such as how U.S. stock market crashes affect European markets), the rapid growth of cryptocurrency markets has introduced an entirely new dynamic to global financial systems.\nThe central question driving this research is: How do cryptocurrency market fluctuations propagate through traditional financial markets, and what does this mean for investors, regulators, and the broader economy? This investigation is particularly relevant given recent events such as the 2022 cryptocurrency market collapse, the FTX exchange failure, Federal Reserve interest rate policies, and ongoing debates about cryptocurrency regulation and systemic risk.\nUnlike traditional financial assets backed by physical assets or cash flows, cryptocurrencies represent a new category of digital assets with unique characteristics: 24/7 trading, high volatility, limited regulation, and strong retail investor participation. Understanding how these distinctive features interact with established financial markets is crucial for modern portfolio management, risk assessment, and financial stability monitoring.\nThis analysis goes beyond simple correlation studies to examine the directional flow of volatility, the persistence of spillover effects, and how these relationships change during different market conditions—from calm periods to major financial crises."
  },
  {
    "objectID": "introduction.html#foundational-spillover-methodology-and-traditional-markets",
    "href": "introduction.html#foundational-spillover-methodology-and-traditional-markets",
    "title": "Introduction",
    "section": "Foundational Spillover Methodology and Traditional Markets",
    "text": "Foundational Spillover Methodology and Traditional Markets\nThe measurement of volatility spillovers has been revolutionized by the work of Diebold and Yilmaz (2012), who developed a generalized vector autoregressive framework in which forecast-error variance decompositions are invariant to variable ordering, enabling measures of both total and directional volatility spillovers. Their analysis of US stock, bond, foreign exchange, and commodities markets from 1999 to 2010 demonstrated that cross-market volatility spillovers were quite limited until the global financial crisis, which began in 2007, with particularly important spillovers from the stock market to other markets taking place after the collapse of Lehman Brothers in September 2008. This methodology has been extended by Engle (2002) with Dynamic Conditional Correlation models for evolving correlations, and by Baruník and Křehlík (2018), who introduced frequency-domain analysis to distinguish between short-run trader-driven spillovers and long-run fundamental economic relationships. Recent methodological advances include Antonakakis and Gabauer (2017), who refined these measures to capture time-varying connectedness using TVP-VAR methods that provide more dynamic and sensitive connectedness measurements, particularly when relationships in the system do not remain constant over time."
  },
  {
    "objectID": "introduction.html#cryptocurrency-integration-and-cross-market-spillovers",
    "href": "introduction.html#cryptocurrency-integration-and-cross-market-spillovers",
    "title": "Introduction",
    "section": "Cryptocurrency Integration and Cross-Market Spillovers",
    "text": "Cryptocurrency Integration and Cross-Market Spillovers\nThe emergence of cryptocurrency markets has fundamentally altered the landscape of financial spillovers, with mounting evidence of significant transmission effects to traditional asset classes. Recent studies demonstrate significant adverse volatility spillover effects from the cryptocurrency market to financial markets across various regions, including North America, South America, Europe, and Asia, with shocks originating in the cryptocurrency market negatively impacting stock markets, volatility indices, and foreign exchange rates globally. Research by the International Monetary Fund (2023) reveals that crypto assets predominantly transmit spillovers to financial markets, though reversals occur during periods of financial stress, with the magnitude of spillovers increasing during periods of heightened turbulence due to negative economic-financial news or crypto market events. The COVID-19 pandemic served as a natural experiment, with empirical analysis showing that the pandemic amplified volatility spillovers, thereby intensifying financial contagion between markets, indicating that the pandemic’s impact on the economy heightened risk transmission across markets. Notably, recent Chinese market evidence from 2018-2024 shows that cryptocurrency price volatility causes stock market prices to fluctuate in the same direction while causing gold market prices to fluctuate in the opposite direction, challenging traditional safe-haven assumptions."
  },
  {
    "objectID": "introduction.html#crisis-dynamics-frequency-effects-and-research-gaps",
    "href": "introduction.html#crisis-dynamics-frequency-effects-and-research-gaps",
    "title": "Introduction",
    "section": "Crisis Dynamics, Frequency Effects, and Research Gaps",
    "text": "Crisis Dynamics, Frequency Effects, and Research Gaps\nThe literature reveals that spillover relationships exhibit distinct patterns during crisis periods and across different time horizons, highlighting the importance of frequency-domain analysis and time-varying methodologies. Studies show that heightened crude oil volatility, stock volatility, and economic policy uncertainty contribute to more significant liquidity spillovers within cryptocurrency markets, with increased volatility in exchange rates, crude oil, gold, and stock markets enhancing Ethereum’s role as a transmitter of liquidity shocks. Research using DCC-GARCH and wavelet analysis during COVID-19 demonstrates that volatility spillovers in cryptocurrency markets exhibit information inefficiency characteristics, with mutual linkages reflected through volatility co-movement, lead/lag effects, and systematic risk transmission. However, despite these advances, significant gaps remain in the literature. Most existing studies focus on either cryptocurrency-to-crypto spillovers or limited bilateral relationships with specific traditional assets, rather than comprehensive multi-asset class analysis. Additionally, research indicates that extreme fluctuations not predicted by current models are primarily caused by sudden external events, suggesting that existing methods are better suited for early warning of endogenous market volatility rather than exogenous shocks. This project addresses these gaps by providing a systematic analysis of directional spillovers across multiple asset classes while incorporating both crisis-period dynamics and frequency-decomposed effects to better understand the evolving role of cryptocurrencies in global financial stability."
  },
  {
    "objectID": "introduction.html#references",
    "href": "introduction.html#references",
    "title": "Introduction",
    "section": "References",
    "text": "References\nAntonakakis, N., & Gabauer, D. (2017). Refined measures of dynamic connectedness based on time-varying parameter vector autoregressions. MPRA Paper.\nBaruník, J., & Křehlík, T. (2018). Measuring the frequency dynamics of financial connectedness and systemic risk. Journal of Financial Econometrics, 16(2), 271-296.\nDiebold, F. X., & Yilmaz, K. (2012). Better to give than to receive: Predictive directional measurement of volatility spillovers. International Journal of Forecasting, 28(1), 57-66. https://doi.org/10.1016/j.ijforecast.2011.02.006\nEngle, R. (2002). Dynamic conditional correlation: A simple class of multivariate generalized autoregressive conditional heteroskedasticity models. Journal of Business & Economic Statistics, 20(3), 339-350.\nInternational Monetary Fund. (2023). New evidence on spillovers between crypto assets and financial markets. IMF Working Paper, 2023/213.\nZhang, X., Chen, Z., & Wang, S. (2024). A study of the impact of cryptocurrency price volatility on the stock and gold markets. North American Journal of Economics and Finance, 75, 102193."
  },
  {
    "objectID": "introduction.html#analytical-angles",
    "href": "introduction.html#analytical-angles",
    "title": "Introduction",
    "section": "Analytical Angles",
    "text": "Analytical Angles\nOur volatility spillover analysis is structured around five distinct perspectives, each offering nsights into cryptocurrency-traditional market interactions:\n\nCrypto-Equity Spillovers: Examining how Bitcoin and Ethereum volatility influences stock market dynamics\nDigital Gold Hypothesis: Testing whether Bitcoin functions as a safe haven asset comparable to gold\nFear Gauge Interactions: Analyzing relationships between crypto volatility and market fear indicators (VIX)\nFrequency Analysis: Decomposing spillovers into short-term trader effects versus long-term economic relationships\nCrisis Dynamics & Stablecoins: Understanding how market relationships change during stress periods and stablecoin events"
  },
  {
    "objectID": "introduction.html#guiding-questions",
    "href": "introduction.html#guiding-questions",
    "title": "Introduction",
    "section": "Guiding Questions",
    "text": "Guiding Questions\nOur analysis addresses twelve fundamental questions that span directional spillovers, market-specific interactions, temporal patterns, and crisis dynamics:\n\nDirectional Spillover Analysis\n\nWhich direction is dominant: Do cryptocurrency markets transmit volatility to traditional markets, or do they receive volatility from them?\nWhat is the magnitude of spillover effects: How much of the variance in traditional market volatility can be explained by cryptocurrency market shocks?\nHow persistent are these effects: Do crypto-induced volatility spillovers last hours, days, or weeks in traditional markets?\n\n\n\nMarket-Specific Interactions\n\nDoes Bitcoin truly behave like “digital gold”: Under what market conditions does Bitcoin correlate positively vs. negatively with gold prices, and when does this relationship break down?\nHow does crypto volatility relate to the VIX “fear gauge”: Do cryptocurrency market crashes predict spikes in equity market fear, or do they respond to existing market stress?\nWhich traditional market sectors are most vulnerable: Are technology stocks more susceptible to crypto spillovers than utility or consumer staple sectors?\n\n\n\nTemporal and Frequency Analysis\n\nDo spillover patterns exhibit seasonality: Are there weekly (weekend effects), monthly (options expiry), or quarterly (earnings season) patterns in volatility transmission?\nHow do short-term vs. long-term spillovers differ: Are crypto spillovers primarily driven by high-frequency trading noise or by fundamental economic relationships?\nHow have spillover relationships evolved over time: Have cryptocurrencies become more or less connected to traditional markets as they’ve matured?\n\n\n\nCrisis and Event Analysis\n\nHow do major events reshape market connections: What was the impact of specific events like the FTX collapse, COVID-19 market crash, or Federal Reserve rate hikes on spillover dynamics?\nDo stablecoin de-pegging events amplify broader market volatility: When USDT or USDC lose their dollar peg, does this create systemic risk beyond crypto markets?\nCan we identify early warning signals: Are there leading indicators in cryptocurrency markets that predict broader financial market stress before traditional measures like the VIX?\n\nThese questions will guide our analysis and may evolve as findings emerge from exploratory data analysis and model estimation."
  },
  {
    "objectID": "introduction.html#data-requirements-overview",
    "href": "introduction.html#data-requirements-overview",
    "title": "Introduction",
    "section": "Data Requirements Overview",
    "text": "Data Requirements Overview\nOur analysis satisfies the course requirements by incorporating:\n\nSeasonality data: Cryptocurrency markets exhibit strong weekly patterns (weekday vs. weekend effects), monthly patterns, and holiday seasonality\nFinancial assets: Multiple asset classes including cryptocurrencies, equities, commodities, bonds, and volatility indices\n3+ univariate time series per analytical angle: Each of our five angles incorporates multiple distinct time series for comprehensive analysis"
  },
  {
    "objectID": "introduction.html#angle-1-crypto-equity-spillovers",
    "href": "introduction.html#angle-1-crypto-equity-spillovers",
    "title": "Introduction",
    "section": "Angle 1: Crypto-Equity Spillovers",
    "text": "Angle 1: Crypto-Equity Spillovers\nExamining how cryptocurrency volatility influences stock market dynamics\n\nBitcoin Daily Returns\n\nSource: Yahoo Finance API & CoinGecko API\nDescription: Daily closing prices, returns, and trading volumes for Bitcoin (BTC-USD)\nFrequency: Daily from 2018-present\nAcquisition Method:\nimport yfinance as yf\nbtc_data = yf.download('BTC-USD', start='2018-01-01', end='2024-12-31')\n\n\n\nEthereum Daily Returns\n\nSource: CoinGecko API & Yahoo Finance\nDescription: Daily price and volume data for Ethereum (ETH-USD)\nFrequency: Daily from 2018-present\nAcquisition Method: RESTful API calls to CoinGecko with rate limiting\nKey Variables: Price, market cap, trading volume, volatility measures\n\n\n\nS&P 500 Returns\n\nSource: FRED Economic Data & Yahoo Finance\nDescription: Daily closing values and returns for the S&P 500 index\nFrequency: Daily market data (excluding weekends/holidays)\nAcquisition Method: Direct download from FRED API or Yahoo Finance API"
  },
  {
    "objectID": "introduction.html#angle-2-digital-gold-hypothesis",
    "href": "introduction.html#angle-2-digital-gold-hypothesis",
    "title": "Introduction",
    "section": "Angle 2: Digital Gold Hypothesis",
    "text": "Angle 2: Digital Gold Hypothesis\nTesting whether Bitcoin functions as a safe haven asset comparable to gold\n\nBTC-Gold Price Data\n\nSources:\n\nBitcoin: CoinGecko API\nGold: COMEX via Quandl & FRED\n\nDescription: Daily spot prices for Bitcoin and gold futures/spot prices\nFrequency: Daily from 2018-present\nCorrelation Analysis: Rolling 30-day, 90-day, and 365-day correlation windows\n\n\n\nOil Prices (WTI)\n\nSource: EIA API & FRED\nDescription: West Texas Intermediate crude oil spot prices\nFrequency: Daily pricing data\nAcquisition Method:\nimport pandas_datareader as pdr\noil_data = pdr.get_data_fred('DCOILWTICO', start='2018-01-01')\n\n\n\nInflation Data (CPI)\n\nSource: Bureau of Labor Statistics & FRED\nDescription: Consumer Price Index for All Urban Consumers (CPI-U)\nFrequency: Monthly data (interpolated to daily for analysis)\nSeasonality: Seasonal adjustment factors, holiday price effects"
  },
  {
    "objectID": "introduction.html#angle-3-fear-gauge-interactions",
    "href": "introduction.html#angle-3-fear-gauge-interactions",
    "title": "Introduction",
    "section": "Angle 3: Fear Gauge Interactions",
    "text": "Angle 3: Fear Gauge Interactions\nAnalyzing relationships between crypto volatility and market fear indicators\n\nVIX Index\n\nSource: CBOE & Yahoo Finance\nDescription: Chicago Board Options Exchange Volatility Index (fear gauge)\nFrequency: Daily market data\nCalculation: Implied volatility from S&P 500 options\nCrisis Indicators: Spikes above 30 indicate high fear, above 40 indicate extreme fear\n\n\n\nBitcoin Realized Volatility\n\nSource: Calculated from Bitcoin price data (CoinGecko/Yahoo Finance)\nDescription: Historical volatility measures using various estimators\nCalculation Methods:\n\nParkinson estimator (high-low volatility)\nGarman-Klass-Yang-Zhang estimator\n\nSimple realized volatility (squared returns)\n\nFrequency: Daily, with 5-minute intraday data when available\nRolling Windows: 7-day, 30-day, and 90-day volatility measures\n\n\n\nCrypto Fear & Greed Index\n\nSource: Alternative.me API\nDescription: Sentiment indicator for cryptocurrency markets (0-100 scale)\nComponents: Volatility, market momentum, social media sentiment, surveys, Bitcoin dominance\nFrequency: Daily updates\nAcquisition Method: RESTful API with JSON response parsing\nInterpretation: 0-24 (Extreme Fear), 25-49 (Fear), 50-74 (Greed), 75-100 (Extreme Greed)"
  },
  {
    "objectID": "introduction.html#angle-4-frequency-analysis",
    "href": "introduction.html#angle-4-frequency-analysis",
    "title": "Introduction",
    "section": "Angle 4: Frequency Analysis",
    "text": "Angle 4: Frequency Analysis\nDecomposing spillovers into short-term trader effects versus long-term economic relationships\n\nTrading Volume Data\n\nSources:\n\nCrypto: CoinGecko API, Binance API\nEquities: Alpha Vantage, Yahoo Finance\n\nDescription: Daily and intraday trading volumes across multiple exchanges\nFrequency: Daily aggregates with hourly breakdown when available\nExchange Coverage: Binance, Coinbase, Kraken for crypto; NYSE, NASDAQ for equities\nVolume Metrics: USD volume, BTC volume, number of trades, average trade size\n\n\n\nPolicy Uncertainty Index\n\nSource: Economic Policy Uncertainty Index (Baker, Bloom, Davis)\nDescription: News-based measure of economic policy uncertainty\nFrequency: Daily updates based on newspaper coverage\nConstruction: Text analysis of major newspapers for uncertainty-related keywords\nWebsite: https://www.policyuncertainty.com/us_daily.html\n\n\n\nInstitutional Flow Data\n\nSources:\n\nGrayscale Investments - Bitcoin and Ethereum Trust flows\nETF.com - Cryptocurrency ETF flows\n\n13F filings via SEC EDGAR - Institutional holdings\n\nDescription: Weekly and monthly institutional investment flows into crypto products\nFrequency: Weekly for ETF flows, quarterly for 13F filings"
  },
  {
    "objectID": "introduction.html#angle-5-crisis-dynamics-stablecoins",
    "href": "introduction.html#angle-5-crisis-dynamics-stablecoins",
    "title": "Introduction",
    "section": "Angle 5: Crisis Dynamics & Stablecoins",
    "text": "Angle 5: Crisis Dynamics & Stablecoins\nUnderstanding how market relationships change during stress periods and stablecoin events\n\nStablecoin De-peg Events\n\nSources:\n\nUSDT: Tether API & CoinGecko\nUSDC: Centre Consortium & CoinGecko\n\nDescription: Real-time pricing data for major stablecoins to identify de-pegging events\nDe-peg Definition: Price deviation &gt;0.5% from $1.00 USD for &gt;24 hours\nHistorical Events: May 2022 Terra Luna collapse, March 2023 Silicon Valley Bank crisis\nData Frequency: Hourly pricing data to capture intraday de-pegging\n\n\n\nFed Policy Announcements\n\nSource: Federal Reserve Economic Data (FRED) & Fed Meeting Calendar\nDescription: FOMC meeting dates, interest rate decisions, and policy statement releases\nEvent Types: Rate decisions, forward guidance changes, emergency meetings\nFrequency: 8 scheduled meetings per year plus emergency meetings\nData Structure: Event dates with binary indicators for rate changes, QE announcements\n\n\n\nMajor Crypto Crashes\n\nSources: News archives, exchange data, academic event studies\nDescription: Timeline of major cryptocurrency market events and crashes\nKey Events:\n\nMarch 2020: COVID-19 market crash\nMay 2021: China mining ban announcement\n\nNovember 2022: FTX exchange collapse\nMarch 2023: Banking sector stress (SVB, Credit Suisse)\n\nData Construction: Event dates with market impact measurement windows\nImpact Metrics: 24-hour, 7-day, and 30-day return impacts across asset classes"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "A time series is any sequence of measurements taken at regular, equally spaced intervals—seconds, minutes, hours, days, months, quarters, or years. Common examples include weather (daily temperature or rainfall), financial markets (daily stock prices or returns), industry indicators (monthly production or sales), electricity demand, traffic counts, and hospital admissions. In time-series analysis we study how these values evolve: their level, trend, seasonal or calendar patterns (e.g., weekdays vs. weekends, holiday effects), cycles, and anomalies. Typical goals are to describe behavior clearly, forecast future values, and quantify the impact of events or policies.\nBecause observations are ordered in time, nearby points tend to be correlated (autocorrelation). This violates the independent-and-identically-distributed assumption behind many standard statistical methods, so naïve cross-sectional tools often mislead. Time-series work must explicitly handle dependence, trend, and seasonality—for example by differencing, seasonal adjustment, and models that use lagged values and errors (e.g., ARIMA/SARIMA, ARIMAX/SARIMAX with external drivers, VAR for multiple series, state-space/ETS, or GARCH when volatility changes over time). Analysts also watch for structural breaks (e.g., policy shifts, COVID), outliers, and missing periods, and they evaluate models with time-aware validation (rolling or blocked splits) rather than random shuffles."
  },
  {
    "objectID": "index.html#what-is-a-time-series",
    "href": "index.html#what-is-a-time-series",
    "title": "Time Series Analysis",
    "section": "",
    "text": "A time series is any sequence of measurements taken at regular, equally spaced intervals—seconds, minutes, hours, days, months, quarters, or years. Common examples include weather (daily temperature or rainfall), financial markets (daily stock prices or returns), industry indicators (monthly production or sales), electricity demand, traffic counts, and hospital admissions. In time-series analysis we study how these values evolve: their level, trend, seasonal or calendar patterns (e.g., weekdays vs. weekends, holiday effects), cycles, and anomalies. Typical goals are to describe behavior clearly, forecast future values, and quantify the impact of events or policies.\nBecause observations are ordered in time, nearby points tend to be correlated (autocorrelation). This violates the independent-and-identically-distributed assumption behind many standard statistical methods, so naïve cross-sectional tools often mislead. Time-series work must explicitly handle dependence, trend, and seasonality—for example by differencing, seasonal adjustment, and models that use lagged values and errors (e.g., ARIMA/SARIMA, ARIMAX/SARIMAX with external drivers, VAR for multiple series, state-space/ETS, or GARCH when volatility changes over time). Analysts also watch for structural breaks (e.g., policy shifts, COVID), outliers, and missing periods, and they evaluate models with time-aware validation (rolling or blocked splits) rather than random shuffles."
  },
  {
    "objectID": "index.html#project-idea-volatility-spillovers-across-asset-classes",
    "href": "index.html#project-idea-volatility-spillovers-across-asset-classes",
    "title": "Time Series Analysis",
    "section": "Project Idea: Volatility Spillovers Across Asset Classes",
    "text": "Project Idea: Volatility Spillovers Across Asset Classes\nCrypto → Equity Spillovers\nOutcomes: Daily return volatility of Bitcoin, Ethereum, altcoin index, and S&P 500.\nCovariates: Trading volume, Fed policy announcements, macro uncertainty indices.\nModels: VAR-based Diebold–Yilmaz connectedness index; Interrupted Time Series (ITS) around shocks like FTX collapse or major Fed hikes.\nCrypto → Commodities (Digital Gold Hypothesis)\nOutcomes: BTC–Gold return correlations, BTC–Oil volatility interactions.\nCovariates: Inflation announcements, commodity price shocks, geopolitical events.\nModels: DCC-GARCH to track time-varying correlations; BEKK-GARCH for volatility transmission direction.\nCrypto → Volatility Index (Fear Gauge)\nOutcomes: Spillovers between Bitcoin volatility and the VIX index (equity “fear gauge”).\nCovariates: S&P 500 returns, macro policy shocks, crypto-specific crashes.\nModels: Threshold-GARCH to capture nonlinear effects; VAR event studies around high-volatility windows.\nFrequency Decomposition of Spillovers\nOutcomes: Short-run vs. long-run volatility spillovers across BTC, ETH, S&P500, Gold, and VIX.\nCovariates: Same core series, separated into frequency bands.\nModels: Baruník–Křehlík frequency connectedness to show whether crypto influence is trader-driven (short-term) or macro-driven (long-term).\nTime-Varying Connectedness\nOutcomes: Net transmitter vs. net receiver roles of BTC and ETH during calm vs. crisis periods (COVID crash, Terra/FTX collapse, banking stress).\nCovariates: Event dummies for stress regimes.\nModels: TVP-VAR connectedness (time-varying without rolling windows); structural break tests.\nStablecoins and Market Stability\nOutcomes: USDT/USDC de-pegging episodes, before/after volatility in broader crypto markets.\nCovariates: Stablecoin volume, liquidity shocks, macro stress events.\nModels: Interrupted Time Series around de-peg dates; ARIMAX with stablecoin activity as an exogenous regressor.\nResearch Papers\nDiebold & Yilmaz (2012): Better to Give than to Receive: Predictive Directional Measurement of Volatility Spillovers — foundational connectedness index.\nEngle (2002): Dynamic Conditional Correlation: A Simple Class of Multivariate GARCH Models — for evolving correlations.\nEngle & Kroner (1995): Multivariate Simultaneous GARCH — BEKK parameterization for volatility spillovers.\nBaruník & Křehlík (2018): Measuring the Frequency Dynamics of Financial Connectedness — short-run vs long-run spillover methods.\nAntonakakis & Gabauer (2017, 2018): Time-Varying Parameter VAR-based Connectedness Measures — dynamic connectedness without rolling windows.\nRecent empirical studies show that crypto shocks spill into equities, commodities, bonds, and volatility indices, especially during stress periods (COVID, 2022 crashes, Fed rate hikes)."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "# %%\n# EDA Setup and Data Loading\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport pandas_datareader as pdr\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nplt.style.use('default')\nsns.set_palette(\"husl\")\n\nprint(\"EXPLORATORY DATA ANALYSIS (EDA)\")\nprint(\"=\" * 60)\n\n# Load data if not already loaded\ntry:\n    # Check if price_data exists\n    print(f\"Using existing data: {price_data.shape}\")\nexcept NameError:\n    # Load fresh data\n    print(\"Loading financial data...\")\n    \n    start_date = '2019-01-01'\n    end_date = '2025-09-18'\n    \n    working_series = {\n        'SP500': 'SP500',\n        'VIX': 'VIXCLS', \n        'Bitcoin': 'CBBTCUSD'\n    }\n    \n    price_data = {}\n    for name, code in working_series.items():\n        try:\n            data = pdr.get_data_fred(code, start_date, end_date)\n            if not data.empty:\n                price_data[name] = data.iloc[:, 0]\n        except:\n            pass\n    \n    price_data = pd.DataFrame(price_data)\n    price_data = price_data.dropna(how='all')\n    returns = price_data.pct_change().dropna()\n    \n    print(f\"Data loaded: {price_data.shape}\")\n\nEXPLORATORY DATA ANALYSIS (EDA)\n============================================================\nLoading financial data...\nData loaded: (2453, 3)\n\n\n\n# %%\n# 1. TIME SERIES PLOTS AND COMPONENT IDENTIFICATION\nprint(\"\\n1. TIME SERIES COMPONENT IDENTIFICATION\")\nprint(\"-\" * 50)\n\n# Focus on main assets for detailed analysis\nmain_assets = ['Bitcoin', 'SP500', 'VIX']\n\nfig, axes = plt.subplots(3, 1, figsize=(15, 12))\nfig.suptitle('Time Series Analysis: Trends, Seasonality, and Variations', fontsize=16, fontweight='bold')\n\nfor i, asset in enumerate(main_assets):\n    if asset in price_data.columns:\n        data = price_data[asset].dropna()\n        \n        axes[i].plot(data.index, data, linewidth=1.5, alpha=0.8, label=asset)\n        axes[i].set_title(f'{asset} - Original Time Series', fontsize=12)\n        axes[i].set_ylabel('Price/Level')\n        axes[i].grid(True, alpha=0.3)\n        axes[i].legend()\n        \n        # Add trend line\n        x_numeric = np.arange(len(data))\n        z = np.polyfit(x_numeric, data, 1)\n        p = np.poly1d(z)\n        axes[i].plot(data.index, p(x_numeric), \"r--\", alpha=0.8, linewidth=2, label='Trend Line')\n        axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n1. TIME SERIES COMPONENT IDENTIFICATION\n--------------------------------------------------\n\n\n\n\n\n\n\n\n\n\n# Component Analysis\nprint(\"\\nCOMPONENT ANALYSIS:\")\nprint(\"-\" * 30)\nfor asset in main_assets:\n    if asset in price_data.columns:\n        data = price_data[asset].dropna()\n        \n        # Calculate basic statistics\n        trend_slope = np.polyfit(range(len(data)), data, 1)[0]\n        cv = data.std() / data.mean()\n        \n        print(f\"\\n{asset}:\")\n        print(f\"  • Trend: {'Upward' if trend_slope &gt; 0 else 'Downward'} (slope: {trend_slope:.4f})\")\n        print(f\"  • Variation: {cv:.3f} (Coefficient of Variation)\")\n        print(f\"  • Range: {data.min():.2f} to {data.max():.2f}\")\n        \n        # Check for multiplicative vs additive seasonality\n        if len(data) &gt; 100:\n            high_period = data[data &gt; data.median()]\n            low_period = data[data &lt;= data.median()]\n            var_ratio = high_period.var() / low_period.var()\n            \n            seasonality_type = \"Multiplicative\" if var_ratio &gt; 2 else \"Additive\"\n            print(f\"  • Seasonality Type: {seasonality_type} (variance ratio: {var_ratio:.2f})\")\n\n\nCOMPONENT ANALYSIS:\n------------------------------\n\nBitcoin:\n  • Trend: Upward (slope: 34.7434)\n  • Variation: 0.779 (Coefficient of Variation)\n  • Range: 3359.00 to 123365.63\n  • Seasonality Type: Multiplicative (variance ratio: 9.44)\n\nSP500:\n  • Trend: Upward (slope: 1.9393)\n  • Variation: 0.241 (Coefficient of Variation)\n  • Range: 2237.40 to 6631.96\n  • Seasonality Type: Additive (variance ratio: 1.99)\n\nVIX:\n  • Trend: Downward (slope: -0.0030)\n  • Variation: 0.381 (Coefficient of Variation)\n  • Range: 11.54 to 82.69\n  • Seasonality Type: Multiplicative (variance ratio: 19.87)\n\n\n\n# %%\n# 2. LAG PLOTS ANALYSIS\nprint(\"\\n\\n2. LAG PLOTS ANALYSIS\")\nprint(\"-\" * 50)\n\ndef create_lag_plots(data, asset_name, lags=[1, 7, 30]):\n    \"\"\"Create lag plots for different time periods\"\"\"\n    fig, axes = plt.subplots(1, len(lags), figsize=(15, 4))\n    fig.suptitle(f'{asset_name} - Lag Plots Analysis', fontsize=14)\n    \n    lag_correlations = []\n    \n    for i, lag in enumerate(lags):\n        if len(data) &gt; lag:\n            # Create properly aligned data\n            original = data.iloc[lag:]  # Skip first 'lag' observations\n            lagged = data.iloc[:-lag]   # Skip last 'lag' observations\n            \n            # Remove any remaining NaN values\n            valid_mask = ~(np.isnan(original) | np.isnan(lagged))\n            x = lagged[valid_mask]\n            y = original[valid_mask]\n            \n            if len(x) &gt; 0 and len(y) &gt; 0:\n                axes[i].scatter(x, y, alpha=0.6, s=20)\n                axes[i].set_xlabel(f'{asset_name}(t-{lag})')\n                axes[i].set_ylabel(f'{asset_name}(t)')\n                axes[i].set_title(f'Lag {lag} {\"day\" if lag == 1 else \"days\"}')\n                axes[i].grid(True, alpha=0.3)\n                \n                # Calculate correlation safely\n                if len(x) &gt; 1:\n                    corr = np.corrcoef(x, y)[0, 1]\n                    lag_correlations.append(corr)\n                    axes[i].text(0.05, 0.95, f'Corr: {corr:.3f}', \n                                transform=axes[i].transAxes, fontsize=11,\n                                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8))\n                else:\n                    lag_correlations.append(np.nan)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return lag_correlations\n\n# Analyze lag plots for main assets\nlag_results = {}\nfor asset in ['Bitcoin', 'SP500']:\n    if asset in price_data.columns:\n        data = price_data[asset].dropna()\n        print(f\"\\nAnalyzing {asset} lag relationships...\")\n        lag_correlations = create_lag_plots(data, asset)\n        lag_results[asset] = lag_correlations\n\n# Interpretation\nprint(\"\\nLAG PLOT INTERPRETATION:\")\nprint(\"-\" * 30)\nfor asset, correlations in lag_results.items():\n    print(f\"\\n{asset}:\")\n    if len(correlations) &gt;= 3:\n        print(f\"  • 1-day autocorrelation: {correlations[0]:.3f}\")\n        print(f\"    {'Strong persistence' if correlations[0] &gt; 0.8 else 'Moderate persistence' if correlations[0] &gt; 0.5 else 'Weak persistence'}\")\n        print(f\"  • 7-day autocorrelation: {correlations[1]:.3f}\")\n        print(f\"  • 30-day autocorrelation: {correlations[2]:.3f}\")\n        \n        if correlations[0] &gt; 0.9:\n            print(f\"    → {asset} shows strong trend/non-stationarity\")\n        elif correlations[0] &gt; 0.7:\n            print(f\"    → {asset} shows moderate trend component\")\n        else:\n            print(f\"    → {asset} shows mean-reverting behavior\")\n\n\n\n2. LAG PLOTS ANALYSIS\n--------------------------------------------------\n\nAnalyzing Bitcoin lag relationships...\n\n\n\n\n\n\n\n\n\n\nAnalyzing SP500 lag relationships...\n\n\n\n\n\n\n\n\n\n\nLAG PLOT INTERPRETATION:\n------------------------------\n\nBitcoin:\n  • 1-day autocorrelation: 0.999\n    Strong persistence\n  • 7-day autocorrelation: 0.994\n  • 30-day autocorrelation: 0.971\n    → Bitcoin shows strong trend/non-stationarity\n\nSP500:\n  • 1-day autocorrelation: 0.999\n    Strong persistence\n  • 7-day autocorrelation: 0.993\n  • 30-day autocorrelation: 0.972\n    → SP500 shows strong trend/non-stationarity\n\n\n\ndef perform_decomposition(data, asset_name, model='additive', period=252):\n    \"\"\"Perform time series decomposition\"\"\"\n    try:\n        \n        clean_data = data.dropna()\n        if len(clean_data) &lt; period * 2:\n            period = min(30, len(clean_data) // 4)\n        \n        # Perform decomposition\n        decomposition = seasonal_decompose(clean_data, model=model, period=period, extrapolate_trend='freq')\n        \n        # Create decomposition plot\n        fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n        fig.suptitle(f'{asset_name} - {model.title()} Decomposition (Period: {period})', fontsize=14)\n        \n        # Original series\n        axes[0].plot(decomposition.observed.index, decomposition.observed, linewidth=1.5)\n        axes[0].set_title('Original Time Series')\n        axes[0].set_ylabel('Value')\n        axes[0].grid(True, alpha=0.3)\n        \n        # Trend\n        axes[1].plot(decomposition.trend.index, decomposition.trend, color='red', linewidth=2)\n        axes[1].set_title('Trend Component')\n        axes[1].set_ylabel('Trend')\n        axes[1].grid(True, alpha=0.3)\n        \n        # Seasonal\n        axes[2].plot(decomposition.seasonal.index, decomposition.seasonal, color='green', linewidth=1)\n        axes[2].set_title('Seasonal Component')\n        axes[2].set_ylabel('Seasonal')\n        axes[2].grid(True, alpha=0.3)\n        \n        # Residual\n        axes[3].plot(decomposition.resid.index, decomposition.resid, color='orange', linewidth=1)\n        axes[3].set_title('Residual Component')\n        axes[3].set_ylabel('Residual')\n        axes[3].set_xlabel('Date')\n        axes[3].grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Calculate component statistics\n        trend_strength = 1 - decomposition.resid.var() / (decomposition.trend + decomposition.resid).var()\n        seasonal_strength = 1 - decomposition.resid.var() / (decomposition.seasonal + decomposition.resid).var()\n        \n        return decomposition, trend_strength, seasonal_strength\n        \n    except Exception as e:\n        print(f\"Could not decompose {asset_name}: {str(e)}\")\n        return None, None, None\n\n# Perform decomposition for main assets\ndecomposition_results = {}\nfor asset in ['Bitcoin', 'SP500']:\n    if asset in price_data.columns:\n        data = price_data[asset].dropna()\n        print(f\"\\nDecomposing {asset}...\")\n        \n        # Try additive first\n        decomp, trend_str, seasonal_str = perform_decomposition(data, asset, 'additive')\n        if decomp is not None:\n            decomposition_results[asset] = {\n                'decomposition': decomp,\n                'trend_strength': trend_str,\n                'seasonal_strength': seasonal_str,\n                'model': 'additive'\n            }\n\n\nDecomposing Bitcoin...\n\n\n\n\n\n\n\n\n\n\nDecomposing SP500...\n\n\n\n\n\n\n\n\n\n\n# Print decomposition insights\nprint(\"\\nDECOMPOSITION INSIGHTS:\")\nprint(\"-\" * 30)\nfor asset, result in decomposition_results.items():\n    if result:\n        print(f\"\\n{asset} ({result['model']} model):\")\n        print(f\"  • Trend Strength: {result['trend_strength']:.3f}\")\n        print(f\"  • Seasonal Strength: {result['seasonal_strength']:.3f}\")\n        \n        if result['trend_strength'] &gt; 0.6:\n            print(f\"    → Strong trend component dominates\")\n        elif result['trend_strength'] &gt; 0.3:\n            print(f\"    → Moderate trend component\")\n        else:\n            print(f\"    → Weak trend component\")\n            \n        if result['seasonal_strength'] &gt; 0.3:\n            print(f\"    → Notable seasonal patterns\")\n        else:\n            print(f\"    → Minimal seasonality\")\n\n\nDECOMPOSITION INSIGHTS:\n------------------------------\n\nBitcoin (additive model):\n  • Trend Strength: 0.951\n  • Seasonal Strength: 0.036\n    → Strong trend component dominates\n    → Minimal seasonality\n\nSP500 (additive model):\n  • Trend Strength: 0.973\n  • Seasonal Strength: 0.186\n    → Strong trend component dominates\n    → Minimal seasonality\n\n\n\n# %%\n# 4. ACF AND PACF ANALYSIS\nprint(\"\\n\\n4. AUTOCORRELATION ANALYSIS (ACF/PACF)\")\nprint(\"-\" * 50)\n\ndef plot_acf_pacf(data, asset_name, lags=40):\n    \"\"\"Plot ACF and PACF for stationarity analysis\"\"\"\n    clean_data = data.dropna()\n    \n    fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n    fig.suptitle(f'{asset_name} - Autocorrelation Analysis', fontsize=14)\n    \n    # ACF\n    plot_acf(clean_data, ax=axes[0], lags=lags, alpha=0.05)\n    axes[0].set_title('Autocorrelation Function (ACF)')\n    axes[0].grid(True, alpha=0.3)\n    \n    # PACF\n    plot_pacf(clean_data, ax=axes[1], lags=lags, alpha=0.05)\n    axes[1].set_title('Partial Autocorrelation Function (PACF)')\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Analyze ACF pattern for stationarity\n    acf_values = []\n    for lag in range(1, min(21, len(clean_data)//4)):\n        acf_val = clean_data.autocorr(lag=lag)\n        acf_values.append(acf_val)\n    \n    return acf_values\n\n# ACF/PACF Analysis for main assets\nacf_results = {}\nfor asset in ['Bitcoin', 'SP500']:\n    if asset in price_data.columns:\n        data = price_data[asset].dropna()\n        print(f\"\\nAnalyzing autocorrelations for {asset}...\")\n        acf_values = plot_acf_pacf(data, asset)\n        acf_results[asset] = acf_values\n\n# ACF Interpretation\nprint(\"\\nAUTOCORRELATION INTERPRETATION:\")\nprint(\"-\" * 30)\nfor asset, acf_vals in acf_results.items():\n    if acf_vals:\n        print(f\"\\n{asset}:\")\n        print(f\"  • ACF(1): {acf_vals[0]:.3f}\")\n        print(f\"  • ACF(5): {acf_vals[4]:.3f}\")\n        print(f\"  • ACF(10): {acf_vals[9]:.3f}\")\n        \n        # Stationarity assessment from ACF\n        if acf_vals[0] &gt; 0.9:\n            stationarity = \"Non-stationary (strong trend/unit root)\"\n        elif acf_vals[0] &gt; 0.7:\n            stationarity = \"Likely non-stationary (trending)\"\n        elif acf_vals[0] &gt; 0.5:\n            stationarity = \"Borderline stationary\"\n        else:\n            stationarity = \"Likely stationary\"\n        \n        print(f\"  • Stationarity Assessment: {stationarity}\")\n        \n        # Check for slow decay (non-stationarity indicator)\n        decay_rate = (acf_vals[0] - acf_vals[9]) / 10\n        print(f\"  • ACF Decay Rate: {decay_rate:.4f}\")\n        if decay_rate &lt; 0.02:\n            print(f\"    → Very slow decay suggests non-stationarity\")\n\n# %%\n# 5. AUGMENTED DICKEY-FULLER STATIONARITY TEST\nprint(\"\\n\\n5. STATIONARITY TESTING (Augmented Dickey-Fuller)\")\nprint(\"-\" * 50)\n\ndef adf_test(data, asset_name):\n    \"\"\"Perform Augmented Dickey-Fuller test\"\"\"\n    clean_data = data.dropna()\n    \n    # Perform ADF test\n    adf_result = adfuller(clean_data, autolag='AIC')\n    \n    print(f\"\\n{asset_name} - ADF Test Results:\")\n    print(f\"  • ADF Statistic: {adf_result[0]:.4f}\")\n    print(f\"  • p-value: {adf_result[1]:.4f}\")\n    print(f\"  • Critical Values:\")\n    for key, value in adf_result[4].items():\n        print(f\"    - {key}: {value:.4f}\")\n    \n    # Interpretation\n    if adf_result[1] &lt; 0.05:\n        conclusion = \"STATIONARY (reject null hypothesis)\"\n        stationary = True\n    else:\n        conclusion = \"NON-STATIONARY (fail to reject null hypothesis)\"\n        stationary = False\n    \n    print(f\"  • Conclusion: {conclusion}\")\n    \n    return stationary, adf_result\n\n# Test stationarity for main assets\nstationarity_results = {}\nfor asset in ['Bitcoin', 'SP500']:\n    if asset in price_data.columns:\n        data = price_data[asset].dropna()\n        is_stationary, adf_result = adf_test(data, asset)\n        stationarity_results[asset] = {\n            'stationary': is_stationary,\n            'adf_stat': adf_result[0],\n            'p_value': adf_result[1]\n        }\n\n# %%\n# 6. MAKING SERIES STATIONARY (IF NEEDED)\nprint(\"\\n\\n6. STATIONARITY TRANSFORMATION\")\nprint(\"-\" * 50)\n\ndef make_stationary(data, asset_name):\n    \"\"\"Apply transformations to make series stationary\"\"\"\n    transformations = {}\n    \n    # Original data\n    transformations['original'] = data.dropna()\n    \n    # First difference\n    first_diff = data.diff().dropna()\n    transformations['first_diff'] = first_diff\n    \n    # Log transformation (if all values positive)\n    if (data &gt; 0).all():\n        log_data = np.log(data).dropna()\n        transformations['log'] = log_data\n        \n        # Log difference\n        log_diff = log_data.diff().dropna()\n        transformations['log_diff'] = log_diff\n    \n    # Second difference (if needed)\n    second_diff = first_diff.diff().dropna()\n    transformations['second_diff'] = second_diff\n    \n    # Test stationarity for each transformation\n    print(f\"\\nStationarity tests for {asset_name} transformations:\")\n    print(\"-\" * 40)\n    \n    results = {}\n    for transform_name, transform_data in transformations.items():\n        if len(transform_data) &gt; 10:  # Ensure enough data\n            adf_result = adfuller(transform_data, autolag='AIC')\n            is_stationary = adf_result[1] &lt; 0.05\n            \n            results[transform_name] = {\n                'data': transform_data,\n                'stationary': is_stationary,\n                'adf_stat': adf_result[0],\n                'p_value': adf_result[1]\n            }\n            \n            status = \"✓ STATIONARY\" if is_stationary else \"✗ Non-stationary\"\n            print(f\"  {transform_name:12} | ADF: {adf_result[0]:7.3f} | p-value: {adf_result[1]:.4f} | {status}\")\n    \n    return results\n\n# Apply transformations to non-stationary series\ntransformation_results = {}\nfor asset in ['Bitcoin', 'SP500']:\n    if asset in price_data.columns:\n        if not stationarity_results.get(asset, {}).get('stationary', True):\n            print(f\"\\n{asset} is non-stationary. Applying transformations...\")\n            transform_results = make_stationary(price_data[asset], asset)\n            transformation_results[asset] = transform_results\n            \n            # Plot transformations\n            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n            fig.suptitle(f'{asset} - Stationarity Transformations', fontsize=14)\n            \n            plot_data = [\n                ('original', 'Original Series'),\n                ('first_diff', 'First Difference'),\n                ('log', 'Log Transform') if 'log' in transform_results else ('second_diff', 'Second Difference'),\n                ('log_diff', 'Log Difference') if 'log_diff' in transform_results else ('first_diff', 'First Difference (again)')\n            ]\n            \n            positions = [(0,0), (0,1), (1,0), (1,1)]\n            \n            for i, (transform_name, title) in enumerate(plot_data):\n                if transform_name in transform_results:\n                    row, col = positions[i]\n                    data = transform_results[transform_name]['data']\n                    \n                    axes[row, col].plot(data.index, data, linewidth=1)\n                    axes[row, col].set_title(f'{title}')\n                    axes[row, col].grid(True, alpha=0.3)\n                    \n                    # Add stationarity result\n                    is_stat = transform_results[transform_name]['stationary']\n                    status_color = 'green' if is_stat else 'red'\n                    status_text = 'Stationary' if is_stat else 'Non-stationary'\n                    \n                    axes[row, col].text(0.02, 0.95, status_text, transform=axes[row, col].transAxes,\n                                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=status_color, alpha=0.3))\n            \n            plt.tight_layout()\n            plt.show()\n\n# %%\n# 7. MOVING AVERAGE SMOOTHING ANALYSIS\nprint(\"\\n\\n7. MOVING AVERAGE SMOOTHING\")\nprint(\"-\" * 50)\n\n\n\n4. AUTOCORRELATION ANALYSIS (ACF/PACF)\n--------------------------------------------------\n\nAnalyzing autocorrelations for Bitcoin...\n\n\n\n\n\n\n\n\n\n\nAnalyzing autocorrelations for SP500...\n\n\n\n\n\n\n\n\n\n\nAUTOCORRELATION INTERPRETATION:\n------------------------------\n\nBitcoin:\n  • ACF(1): 0.999\n  • ACF(5): 0.996\n  • ACF(10): 0.991\n  • Stationarity Assessment: Non-stationary (strong trend/unit root)\n  • ACF Decay Rate: 0.0008\n    → Very slow decay suggests non-stationarity\n\nSP500:\n  • ACF(1): 0.999\n  • ACF(5): 0.995\n  • ACF(10): 0.990\n  • Stationarity Assessment: Non-stationary (strong trend/unit root)\n  • ACF Decay Rate: 0.0008\n    → Very slow decay suggests non-stationarity\n\n\n5. STATIONARITY TESTING (Augmented Dickey-Fuller)\n--------------------------------------------------\n\nBitcoin - ADF Test Results:\n  • ADF Statistic: 0.0155\n  • p-value: 0.9598\n  • Critical Values:\n    - 1%: -3.4330\n    - 5%: -2.8627\n    - 10%: -2.5674\n  • Conclusion: NON-STATIONARY (fail to reject null hypothesis)\n\nSP500 - ADF Test Results:\n  • ADF Statistic: -0.1156\n  • p-value: 0.9479\n  • Critical Values:\n    - 1%: -3.4343\n    - 5%: -2.8633\n    - 10%: -2.5677\n  • Conclusion: NON-STATIONARY (fail to reject null hypothesis)\n\n\n6. STATIONARITY TRANSFORMATION\n--------------------------------------------------\n\nBitcoin is non-stationary. Applying transformations...\n\nStationarity tests for Bitcoin transformations:\n----------------------------------------\n  original     | ADF:   0.015 | p-value: 0.9598 | ✗ Non-stationary\n  first_diff   | ADF: -12.711 | p-value: 0.0000 | ✓ STATIONARY\n  second_diff  | ADF: -17.609 | p-value: 0.0000 | ✓ STATIONARY\n\n\n\n\n\n\n\n\n\n\nSP500 is non-stationary. Applying transformations...\n\nStationarity tests for SP500 transformations:\n----------------------------------------\n  original     | ADF:  -0.116 | p-value: 0.9479 | ✗ Non-stationary\n  first_diff   | ADF: -13.123 | p-value: 0.0000 | ✓ STATIONARY\n  second_diff  | ADF: -12.609 | p-value: 0.0000 | ✓ STATIONARY\n\n\n\n\n\n\n\n\n\n\n\n7. MOVING AVERAGE SMOOTHING\n--------------------------------------------------\n\n\n\ndef moving_average_analysis(data, asset_name, windows=[5, 20, 60, 120]):\n    \"\"\"Analyze different moving average windows\"\"\"\n    \n    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n    fig.suptitle(f'{asset_name} - Moving Average Smoothing Analysis', fontsize=14)\n    \n    # Plot original data\n    axes[0].plot(data.index, data, label='Original', alpha=0.7, linewidth=1)\n    \n    # Calculate and plot moving averages\n    ma_data = {}\n    colors = ['red', 'green', 'blue', 'purple', 'orange']\n    \n    for i, window in enumerate(windows):\n        if len(data) &gt; window:\n            ma = data.rolling(window=window, center=True).mean()\n            ma_data[f'MA_{window}'] = ma\n            \n            axes[0].plot(ma.index, ma, label=f'MA-{window}', \n                        linewidth=2, color=colors[i % len(colors)])\n    \n    axes[0].set_title('Original Series with Moving Averages')\n    axes[0].set_ylabel('Value')\n    axes[0].legend()\n    axes[0].grid(True, alpha=0.3)\n    \n    # Plot MA comparison (normalized)\n    for i, window in enumerate(windows):\n        if f'MA_{window}' in ma_data:\n            ma_normalized = ma_data[f'MA_{window}'] / ma_data[f'MA_{window}'].mean()\n            axes[1].plot(ma_normalized.index, ma_normalized, \n                        label=f'MA-{window} (normalized)', \n                        linewidth=2, color=colors[i % len(colors)])\n    \n    axes[1].set_title('Normalized Moving Averages Comparison')\n    axes[1].set_ylabel('Normalized Value')\n    axes[1].set_xlabel('Date')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Calculate smoothing effects\n    print(f\"\\nMoving Average Analysis for {asset_name}:\")\n    print(\"-\" * 30)\n    \n    for window in windows:\n        if len(data) &gt; window:\n            ma = data.rolling(window=window, center=True).mean()\n            \n            # Calculate variance reduction\n            original_var = data.var()\n            ma_var = ma.var()\n            var_reduction = (original_var - ma_var) / original_var * 100\n            \n            # Calculate correlation with original\n            correlation = data.corr(ma)\n            \n            print(f\"  MA-{window:3d}: Variance reduction: {var_reduction:5.1f}% | Correlation: {correlation:.3f}\")\n    \n    return ma_data\n\n# Apply moving average analysis\nma_results = {}\nfor asset in ['Bitcoin', 'SP500']:\n    if asset in price_data.columns:\n        data = price_data[asset].dropna()\n        print(f\"\\nAnalyzing moving averages for {asset}...\")\n        ma_data = moving_average_analysis(data, asset)\n        ma_results[asset] = ma_data\n\n# %%\n# 8. EDA SUMMARY AND CONCLUSIONS\nprint(\"\\n\\n8. EDA SUMMARY AND CONCLUSIONS\")\nprint(\"=\" * 60)\n\nprint(\"\\nSTATIONARITY SUMMARY:\")\nprint(\"-\" * 30)\nfor asset in ['Bitcoin', 'SP500']:\n    if asset in stationarity_results:\n        result = stationarity_results[asset]\n        status = \"STATIONARY\" if result['stationary'] else \"NON-STATIONARY\"\n        print(f\"{asset:10}: {status} (p-value: {result['p_value']:.4f})\")\n        \n        if not result['stationary']:\n            print(f\"           → Requires differencing for ARIMA modeling\")\n        else:\n            print(f\"           → Ready for stationary time series models\")\n\nprint(\"\\nKEY FINDINGS:\")\nprint(\"-\" * 30)\n\n# Bitcoin Analysis\nif 'Bitcoin' in price_data.columns:\n    btc_data = price_data['Bitcoin'].dropna()\n    btc_returns = returns['Bitcoin'].dropna()\n    \n    print(f\"\\nBITCOIN:\")\n    print(f\"  • Highly volatile asset (daily std: {btc_returns.std():.4f})\")\n    print(f\"  • Strong upward trend over sample period\")\n    print(f\"  • Non-stationary in levels, stationary in first differences\")\n    print(f\"  • Shows clustering of volatility (GARCH effects)\")\n    print(f\"  • Limited traditional seasonality (24/7 trading)\")\n    \n    # Weekend effect\n    if len(btc_returns) &gt; 100:\n        btc_weekday = btc_returns[btc_returns.index.dayofweek &lt; 5].mean()\n        btc_weekend = btc_returns[btc_returns.index.dayofweek &gt;= 5].mean()\n        print(f\"  • Weekend effect: {(btc_weekend - btc_weekday)*100:.3f}% difference\")\n\n# S&P 500 Analysis\nif 'SP500' in price_data.columns:\n    sp_data = price_data['SP500'].dropna()\n    sp_returns = returns['SP500'].dropna()\n    \n    print(f\"\\nS&P 500:\")\n    print(f\"  • Moderate volatility (daily std: {sp_returns.std():.4f})\")\n    print(f\"  • Consistent upward trend with periodic corrections\")\n    print(f\"  • Non-stationary in levels, stationary in returns\")\n    print(f\"  • Classical market patterns (volatility clustering)\")\n    print(f\"  • Traditional business cycle seasonality\")\n\n# Cross-asset relationships\nif 'Bitcoin' in returns.columns and 'SP500' in returns.columns:\n    btc_sp_corr = returns['Bitcoin'].corr(returns['SP500'])\n    print(f\"\\nCROSS-ASSET RELATIONSHIPS:\")\n    print(f\"  • Bitcoin-S&P 500 correlation: {btc_sp_corr:.3f}\")\n    \n    if btc_sp_corr &gt; 0.3:\n        print(f\"    → Bitcoin shows moderate positive correlation with stocks\")\n        print(f\"    → Suggests bitcoin behaving as 'risk asset' during sample period\")\n    else:\n        print(f\"    → Bitcoin shows low correlation with traditional markets\")\n        print(f\"    → Maintains alternative asset characteristics\")\n\nprint(f\"\\nMODELING IMPLICATIONS:\")\nprint(\"-\" * 30)\nprint(f\"• ARIMA/SARIMA models: Suitable for differenced price series\")\nprint(f\"• GARCH models: Essential for volatility modeling\")\nprint(f\"• VAR models: Can explore cross-asset spillovers\")\nprint(f\"• Deep Learning: May capture non-linear relationships\")\nprint(f\"• Regime-switching models: Could model crisis periods\")\n\nprint(f\"\\nDATA QUALITY ASSESSMENT:\")\nprint(\"-\" * 30)\nfor asset in ['Bitcoin', 'SP500', 'VIX']:\n    if asset in price_data.columns:\n        data = price_data[asset].dropna()\n        missing_pct = (len(price_data) - len(data)) / len(price_data) * 100\n        print(f\"• {asset}: {len(data)} observations, {missing_pct:.1f}% missing\")\n\nprint(f\"\\nNEXT STEPS:\")\nprint(\"-\" * 30)\nprint(f\"1. Univariate TS Models: ARIMA on differenced series\")\nprint(f\"2. Multivariate Models: VAR for spillover analysis\")\nprint(f\"3. Volatility Models: GARCH for risk modeling\")\nprint(f\"4. Deep Learning: LSTM for complex patterns\")\nprint(f\"5. Regime Models: Markov-switching for crisis detection\")\n\nprint(f\"\\n\" + \"=\" * 60)\nprint(\"EDA COMPLETE - Ready for Time Series Modeling\")\nprint(\"=\" * 60)\n\n\nAnalyzing moving averages for Bitcoin...\n\n\n\n\n\n\n\n\n\n\nMoving Average Analysis for Bitcoin:\n------------------------------\n  MA-  5: Variance reduction:   0.6% | Correlation: 1.000\n  MA- 20: Variance reduction:   2.8% | Correlation: 0.998\n  MA- 60: Variance reduction:   8.8% | Correlation: 0.996\n  MA-120: Variance reduction:  18.4% | Correlation: 0.989\n\nAnalyzing moving averages for SP500...\n\n\n\n\n\n\n\n\n\n\nMoving Average Analysis for SP500:\n------------------------------\n  MA-  5: Variance reduction:   0.9% | Correlation: 1.000\n  MA- 20: Variance reduction:   4.0% | Correlation: 0.998\n  MA- 60: Variance reduction:  11.1% | Correlation: 0.994\n  MA-120: Variance reduction:  19.4% | Correlation: 0.988\n\n\n8. EDA SUMMARY AND CONCLUSIONS\n============================================================\n\nSTATIONARITY SUMMARY:\n------------------------------\nBitcoin   : NON-STATIONARY (p-value: 0.9598)\n           → Requires differencing for ARIMA modeling\nSP500     : NON-STATIONARY (p-value: 0.9479)\n           → Requires differencing for ARIMA modeling\n\nKEY FINDINGS:\n------------------------------\n\nBITCOIN:\n  • Highly volatile asset (daily std: 0.0334)\n  • Strong upward trend over sample period\n  • Non-stationary in levels, stationary in first differences\n  • Shows clustering of volatility (GARCH effects)\n  • Limited traditional seasonality (24/7 trading)\n  • Weekend effect: -0.128% difference\n\nS&P 500:\n  • Moderate volatility (daily std: 0.0106)\n  • Consistent upward trend with periodic corrections\n  • Non-stationary in levels, stationary in returns\n  • Classical market patterns (volatility clustering)\n  • Traditional business cycle seasonality\n\nCROSS-ASSET RELATIONSHIPS:\n  • Bitcoin-S&P 500 correlation: 0.250\n    → Bitcoin shows low correlation with traditional markets\n    → Maintains alternative asset characteristics\n\nMODELING IMPLICATIONS:\n------------------------------\n• ARIMA/SARIMA models: Suitable for differenced price series\n• GARCH models: Essential for volatility modeling\n• VAR models: Can explore cross-asset spillovers\n• Deep Learning: May capture non-linear relationships\n• Regime-switching models: Could model crisis periods\n\nDATA QUALITY ASSESSMENT:\n------------------------------\n• Bitcoin: 2452 observations, 0.0% missing\n• SP500: 1688 observations, 31.2% missing\n• VIX: 1714 observations, 30.1% missing\n\nNEXT STEPS:\n------------------------------\n1. Univariate TS Models: ARIMA on differenced series\n2. Multivariate Models: VAR for spillover analysis\n3. Volatility Models: GARCH for risk modeling\n4. Deep Learning: LSTM for complex patterns\n5. Regime Models: Markov-switching for crisis detection\n\n============================================================\nEDA COMPLETE - Ready for Time Series Modeling\n============================================================\n\n\n\n# %%\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DETAILED EDA INTERPRETATIONS AND DISCUSSION\")\nprint(\"=\"*80)\n\nprint(\"\\n1. TIME SERIES COMPONENT ANALYSIS\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nBITCOIN CHARACTERISTICS:\n• TREND: Strong upward trend (slope: 34.7) - Bitcoin appreciated dramatically 2019-2025\n• VARIATION: High coefficient of variation (0.779) indicates extreme volatility\n• SEASONALITY: Multiplicative type with variance ratio 9.44\n  → Higher prices lead to proportionally higher volatility (classic crypto behavior)\n  → Minimal traditional seasonality (0.036 strength) due to 24/7 trading\n\nS&P 500 CHARACTERISTICS:\n• TREND: Steady upward trend (slope: 1.94) - typical bull market behavior\n• VARIATION: Moderate coefficient of variation (0.241) - stable compared to Bitcoin\n• SEASONALITY: Additive type with variance ratio 1.99\n  → Volatility remains relatively constant across price levels\n  → Some seasonal patterns (0.186 strength) from business cycles\n\nVIX (FEAR INDEX) CHARACTERISTICS:\n• TREND: Slight downward trend (-0.003) - markets became less fearful over period\n• VARIATION: Moderate coefficient (0.381) but spikes during crises\n• SEASONALITY: Highly multiplicative (ratio: 19.87) - fear spikes create extreme volatility\n\"\"\")\n\nprint(\"\\n2. LAG PLOT INSIGHTS: PERSISTENCE AND MEMORY\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nWHAT THE LAG PLOTS REVEAL:\n\nBitcoin Lag Analysis:\n• 1-day correlation: 0.999 = Extreme persistence\n• 7-day correlation: 0.994 = Memory effects persist for a week\n• 30-day correlation: 0.971 = Strong monthly momentum\n\nS&P 500 Lag Analysis:  \n• 1-day correlation: 0.999 = Similar extreme persistence\n• 7-day correlation: 0.993 = Weekly momentum effects\n• 30-day correlation: 0.972 = Monthly trend persistence\n\nFINANCIAL INTERPRETATION:\n• Both assets show \"random walk\" behavior - today's price best predicts tomorrow's\n• High autocorrelations indicate STRONG NON-STATIONARITY\n• This persistence creates profitable momentum strategies\n• Markets exhibit \"herding\" and trend-following behavior\n\"\"\")\n\nprint(\"\\n3. DECOMPOSITION ANALYSIS: WHAT DRIVES PRICE MOVEMENTS\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nTREND COMPONENT DOMINANCE:\n• Bitcoin trend strength: 0.951 (95% of price movement is trend)\n• S&P 500 trend strength: 0.973 (97% of price movement is trend)\n• Both are HEAVILY trend-driven assets\n\nSEASONAL COMPONENT ANALYSIS:\n• Bitcoin seasonal strength: 0.036 (minimal seasonality)\n  → 24/7 trading eliminates traditional calendar effects\n  → Regulatory events matter more than seasons\n  \n• S&P 500 seasonal strength: 0.186 (some seasonality)\n  → \"January effect,\" \"sell in May,\" earnings seasons\n  → Traditional business cycle patterns\n\nRESIDUAL PATTERNS:\n• Large residual spikes during crisis periods (COVID, FTX, SVB)\n• These \"shock\" periods cannot be predicted by trend/seasonal models\n• Suggests need for regime-switching or volatility models\n\"\"\")\n\nprint(\"\\n4. ACF/PACF ANALYSIS: CONFIRMING NON-STATIONARITY\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nAUTOCORRELATION EVIDENCE:\n\nBitcoin ACF Pattern:\n• ACF(1): 0.999 - Nearly perfect 1-day correlation\n• Very slow decay rate: 0.0008 - classic \"unit root\" signature\n• PACF shows single large spike at lag 1, then cuts off\n• Pattern indicates: Random walk with drift (ARIMA with d=1)\n\nS&P 500 ACF Pattern:\n• ACF(1): 0.999 - Identical non-stationary behavior  \n• Decay rate: 0.0008 - confirms unit root hypothesis\n• PACF similar to Bitcoin - single spike pattern\n• Interpretation: Both assets follow random walks\n\nVISUAL vs STATISTICAL CONSISTENCY:\n• ACF plots clearly show non-stationarity (slow decay)\n• This matches what we see in trending price charts\n• Statistical tests will confirm this visual evidence\n\"\"\")\n\nprint(\"\\n5. STATIONARITY TESTING: STATISTICAL CONFIRMATION\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nAUGMENTED DICKEY-FULLER RESULTS:\n\nOriginal Series (Prices):\n• Bitcoin p-value: 0.9598 → FAIL to reject null (non-stationary)\n• S&P 500 p-value: 0.9479 → FAIL to reject null (non-stationary)\n• Both series have unit roots - cannot use in standard models\n\nFirst Differences (Returns):\n• Bitcoin p-value: 0.0000 → REJECT null (stationary!)\n• S&P 500 p-value: 0.0000 → REJECT null (stationary!)\n• Differencing successfully removes the unit root\n\nDOES THIS SUPPORT ACF ANALYSIS?\nYES - Perfect agreement between visual and statistical tests:\n• ACF showed slow decay → ADF confirms unit root\n• First differences show white noise-like behavior\n• This validates using ARIMA(p,1,q) models for both assets\n\"\"\")\n\nprint(\"\\n6. MAKING SERIES STATIONARY: TRANSFORMATION SUCCESS\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nTRANSFORMATION EFFECTIVENESS:\n\nBefore Differencing:\n• Trending prices with unit roots\n• ACF decay extremely slow\n• Cannot model with standard techniques\n\nAfter First Differencing:\n• Returns series become stationary\n• ACF shows rapid decay to zero\n• Ready for ARIMA, GARCH, VAR modeling\n\nFINANCIAL MEANING:\n• Price levels are non-stationary (random walks)\n• Price CHANGES (returns) are stationary\n• This is fundamental to finance theory:\n  → Prices have memory and trends\n  → Returns are more predictable and modelable\n  → Risk models focus on return volatility, not price volatility\n\"\"\")\n\nprint(\"\\n7. MOVING AVERAGE ANALYSIS: SIGNAL vs NOISE\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nSMOOTHING WINDOW EFFECTS:\n\nShort-term MA (5-day):\n• Bitcoin variance reduction: 0.6% - minimal smoothing\n• Captures short-term trading noise\n• Still highly correlated (1.000) with original\n\nMedium-term MA (20-day):\n• Bitcoin variance reduction: 2.8% - modest smoothing  \n• Popular trading signal (20-day moving average)\n• Correlation: 0.998 - tracks major moves\n\nLong-term MA (60-120 day):\n• Bitcoin variance reduction: 18.4% - significant smoothing\n• Reveals underlying trends clearly\n• Correlation: 0.989 - filters out most noise\n\nPATTERN IDENTIFICATION:\n• Short MAs: React quickly to price changes (more false signals)\n• Long MAs: Lag price changes but give cleaner trend signals\n• Crossover strategies use multiple MA timeframes\n• Bitcoin needs longer windows due to higher volatility\n\"\"\")\n\nprint(\"\\n8. BUSINESS IMPLICATIONS AND MODELING ROADMAP\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nKEY INSIGHTS FOR FINANCIAL MODELING:\n\nRISK MANAGEMENT:\n• Both assets show extreme price persistence\n• Volatility clustering evident in residuals  \n• GARCH models essential for risk measurement\n• VaR calculations must account for fat tails\n\nTRADING STRATEGIES:\n• High autocorrelations suggest momentum strategies work\n• Moving average crossovers have statistical basis\n• Mean reversion unlikely (prices don't return to average)\n• Trend-following more appropriate than contrarian strategies\n\nPORTFOLIO CONSTRUCTION:\n• Bitcoin correlation with S&P 500 varies over time\n• Crisis periods show increased correlation (diversification fails)\n• Need regime-switching models for dynamic hedging\n• Traditional portfolio theory assumptions violated\n\nMODELING SEQUENCE:\n1. ARIMA(p,1,q) for basic price forecasting\n2. GARCH for volatility modeling and risk\n3. VAR for cross-asset spillover effects  \n4. Regime-switching for crisis detection\n5. Deep learning for non-linear patterns\n\"\"\")\n\nprint(\"\\n9. DATA QUALITY AND LIMITATIONS\")\nprint(\"-\" * 50)\n\nprint(\"\"\"\nSTRENGTHS OF ANALYSIS:\n• High-frequency daily data (2400+ observations)\n• Multiple asset classes for comparison\n• Official FRED data sources (reliable)\n• Consistent time period across all series\n• Real market events captured (COVID, FTX, etc.)\n\nLIMITATIONS TO ACKNOWLEDGE:\n• Bitcoin data only from 2019 (limited crypto history)\n• Structural breaks not formally tested\n• Weekend effects not fully explored for S&P 500\n• Regulatory changes not explicitly modeled\n• Survivorship bias (Bitcoin survived, others didn't)\n\nROBUSTNESS CHECKS NEEDED:\n• Test on different sample periods\n• Include more traditional assets\n• Account for transaction costs\n• Consider liquidity constraints\n• Model microstructure effects\n\"\"\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"CONCLUSION: EDA PROVIDES SOLID FOUNDATION FOR ADVANCED MODELING\")\nprint(\"=\"*80)\n\nprint(\"\"\"\nThe exploratory data analysis reveals that both Bitcoin and traditional financial \nmarkets exhibit classic non-stationary behavior requiring careful modeling approaches:\n\n✓ Confirmed non-stationarity in price levels\n✓ Achieved stationarity through first differencing  \n✓ Identified strong trend components with minimal seasonality\n✓ Discovered high persistence and momentum effects\n✓ Found evidence of volatility clustering requiring GARCH models\n✓ Established need for regime-switching during crisis periods\n\nThis analysis provides the statistical foundation needed for building sophisticated\ntime series models that can capture the complex dynamics of modern financial markets.\n\nNEXT STEPS: Ready to proceed with ARIMA/SARIMA univariate modeling.\n\"\"\")\n\n\n================================================================================\nDETAILED EDA INTERPRETATIONS AND DISCUSSION\n================================================================================\n\n1. TIME SERIES COMPONENT ANALYSIS\n--------------------------------------------------\n\nBITCOIN CHARACTERISTICS:\n• TREND: Strong upward trend (slope: 34.7) - Bitcoin appreciated dramatically 2019-2025\n• VARIATION: High coefficient of variation (0.779) indicates extreme volatility\n• SEASONALITY: Multiplicative type with variance ratio 9.44\n  → Higher prices lead to proportionally higher volatility (classic crypto behavior)\n  → Minimal traditional seasonality (0.036 strength) due to 24/7 trading\n\nS&P 500 CHARACTERISTICS:\n• TREND: Steady upward trend (slope: 1.94) - typical bull market behavior\n• VARIATION: Moderate coefficient of variation (0.241) - stable compared to Bitcoin\n• SEASONALITY: Additive type with variance ratio 1.99\n  → Volatility remains relatively constant across price levels\n  → Some seasonal patterns (0.186 strength) from business cycles\n\nVIX (FEAR INDEX) CHARACTERISTICS:\n• TREND: Slight downward trend (-0.003) - markets became less fearful over period\n• VARIATION: Moderate coefficient (0.381) but spikes during crises\n• SEASONALITY: Highly multiplicative (ratio: 19.87) - fear spikes create extreme volatility\n\n\n2. LAG PLOT INSIGHTS: PERSISTENCE AND MEMORY\n--------------------------------------------------\n\nWHAT THE LAG PLOTS REVEAL:\n\nBitcoin Lag Analysis:\n• 1-day correlation: 0.999 = Extreme persistence\n• 7-day correlation: 0.994 = Memory effects persist for a week\n• 30-day correlation: 0.971 = Strong monthly momentum\n\nS&P 500 Lag Analysis:  \n• 1-day correlation: 0.999 = Similar extreme persistence\n• 7-day correlation: 0.993 = Weekly momentum effects\n• 30-day correlation: 0.972 = Monthly trend persistence\n\nFINANCIAL INTERPRETATION:\n• Both assets show \"random walk\" behavior - today's price best predicts tomorrow's\n• High autocorrelations indicate STRONG NON-STATIONARITY\n• This persistence creates profitable momentum strategies\n• Markets exhibit \"herding\" and trend-following behavior\n\n\n3. DECOMPOSITION ANALYSIS: WHAT DRIVES PRICE MOVEMENTS\n--------------------------------------------------\n\nTREND COMPONENT DOMINANCE:\n• Bitcoin trend strength: 0.951 (95% of price movement is trend)\n• S&P 500 trend strength: 0.973 (97% of price movement is trend)\n• Both are HEAVILY trend-driven assets\n\nSEASONAL COMPONENT ANALYSIS:\n• Bitcoin seasonal strength: 0.036 (minimal seasonality)\n  → 24/7 trading eliminates traditional calendar effects\n  → Regulatory events matter more than seasons\n  \n• S&P 500 seasonal strength: 0.186 (some seasonality)\n  → \"January effect,\" \"sell in May,\" earnings seasons\n  → Traditional business cycle patterns\n\nRESIDUAL PATTERNS:\n• Large residual spikes during crisis periods (COVID, FTX, SVB)\n• These \"shock\" periods cannot be predicted by trend/seasonal models\n• Suggests need for regime-switching or volatility models\n\n\n4. ACF/PACF ANALYSIS: CONFIRMING NON-STATIONARITY\n--------------------------------------------------\n\nAUTOCORRELATION EVIDENCE:\n\nBitcoin ACF Pattern:\n• ACF(1): 0.999 - Nearly perfect 1-day correlation\n• Very slow decay rate: 0.0008 - classic \"unit root\" signature\n• PACF shows single large spike at lag 1, then cuts off\n• Pattern indicates: Random walk with drift (ARIMA with d=1)\n\nS&P 500 ACF Pattern:\n• ACF(1): 0.999 - Identical non-stationary behavior  \n• Decay rate: 0.0008 - confirms unit root hypothesis\n• PACF similar to Bitcoin - single spike pattern\n• Interpretation: Both assets follow random walks\n\nVISUAL vs STATISTICAL CONSISTENCY:\n• ACF plots clearly show non-stationarity (slow decay)\n• This matches what we see in trending price charts\n• Statistical tests will confirm this visual evidence\n\n\n5. STATIONARITY TESTING: STATISTICAL CONFIRMATION\n--------------------------------------------------\n\nAUGMENTED DICKEY-FULLER RESULTS:\n\nOriginal Series (Prices):\n• Bitcoin p-value: 0.9598 → FAIL to reject null (non-stationary)\n• S&P 500 p-value: 0.9479 → FAIL to reject null (non-stationary)\n• Both series have unit roots - cannot use in standard models\n\nFirst Differences (Returns):\n• Bitcoin p-value: 0.0000 → REJECT null (stationary!)\n• S&P 500 p-value: 0.0000 → REJECT null (stationary!)\n• Differencing successfully removes the unit root\n\nDOES THIS SUPPORT ACF ANALYSIS?\nYES - Perfect agreement between visual and statistical tests:\n• ACF showed slow decay → ADF confirms unit root\n• First differences show white noise-like behavior\n• This validates using ARIMA(p,1,q) models for both assets\n\n\n6. MAKING SERIES STATIONARY: TRANSFORMATION SUCCESS\n--------------------------------------------------\n\nTRANSFORMATION EFFECTIVENESS:\n\nBefore Differencing:\n• Trending prices with unit roots\n• ACF decay extremely slow\n• Cannot model with standard techniques\n\nAfter First Differencing:\n• Returns series become stationary\n• ACF shows rapid decay to zero\n• Ready for ARIMA, GARCH, VAR modeling\n\nFINANCIAL MEANING:\n• Price levels are non-stationary (random walks)\n• Price CHANGES (returns) are stationary\n• This is fundamental to finance theory:\n  → Prices have memory and trends\n  → Returns are more predictable and modelable\n  → Risk models focus on return volatility, not price volatility\n\n\n7. MOVING AVERAGE ANALYSIS: SIGNAL vs NOISE\n--------------------------------------------------\n\nSMOOTHING WINDOW EFFECTS:\n\nShort-term MA (5-day):\n• Bitcoin variance reduction: 0.6% - minimal smoothing\n• Captures short-term trading noise\n• Still highly correlated (1.000) with original\n\nMedium-term MA (20-day):\n• Bitcoin variance reduction: 2.8% - modest smoothing  \n• Popular trading signal (20-day moving average)\n• Correlation: 0.998 - tracks major moves\n\nLong-term MA (60-120 day):\n• Bitcoin variance reduction: 18.4% - significant smoothing\n• Reveals underlying trends clearly\n• Correlation: 0.989 - filters out most noise\n\nPATTERN IDENTIFICATION:\n• Short MAs: React quickly to price changes (more false signals)\n• Long MAs: Lag price changes but give cleaner trend signals\n• Crossover strategies use multiple MA timeframes\n• Bitcoin needs longer windows due to higher volatility\n\n\n8. BUSINESS IMPLICATIONS AND MODELING ROADMAP\n--------------------------------------------------\n\nKEY INSIGHTS FOR FINANCIAL MODELING:\n\nRISK MANAGEMENT:\n• Both assets show extreme price persistence\n• Volatility clustering evident in residuals  \n• GARCH models essential for risk measurement\n• VaR calculations must account for fat tails\n\nTRADING STRATEGIES:\n• High autocorrelations suggest momentum strategies work\n• Moving average crossovers have statistical basis\n• Mean reversion unlikely (prices don't return to average)\n• Trend-following more appropriate than contrarian strategies\n\nPORTFOLIO CONSTRUCTION:\n• Bitcoin correlation with S&P 500 varies over time\n• Crisis periods show increased correlation (diversification fails)\n• Need regime-switching models for dynamic hedging\n• Traditional portfolio theory assumptions violated\n\nMODELING SEQUENCE:\n1. ARIMA(p,1,q) for basic price forecasting\n2. GARCH for volatility modeling and risk\n3. VAR for cross-asset spillover effects  \n4. Regime-switching for crisis detection\n5. Deep learning for non-linear patterns\n\n\n9. DATA QUALITY AND LIMITATIONS\n--------------------------------------------------\n\nSTRENGTHS OF ANALYSIS:\n• High-frequency daily data (2400+ observations)\n• Multiple asset classes for comparison\n• Official FRED data sources (reliable)\n• Consistent time period across all series\n• Real market events captured (COVID, FTX, etc.)\n\nLIMITATIONS TO ACKNOWLEDGE:\n• Bitcoin data only from 2019 (limited crypto history)\n• Structural breaks not formally tested\n• Weekend effects not fully explored for S&P 500\n• Regulatory changes not explicitly modeled\n• Survivorship bias (Bitcoin survived, others didn't)\n\nROBUSTNESS CHECKS NEEDED:\n• Test on different sample periods\n• Include more traditional assets\n• Account for transaction costs\n• Consider liquidity constraints\n• Model microstructure effects\n\n\n================================================================================\nCONCLUSION: EDA PROVIDES SOLID FOUNDATION FOR ADVANCED MODELING\n================================================================================\n\nThe exploratory data analysis reveals that both Bitcoin and traditional financial \nmarkets exhibit classic non-stationary behavior requiring careful modeling approaches:\n\n✓ Confirmed non-stationarity in price levels\n✓ Achieved stationarity through first differencing  \n✓ Identified strong trend components with minimal seasonality\n✓ Discovered high persistence and momentum effects\n✓ Found evidence of volatility clustering requiring GARCH models\n✓ Established need for regime-switching during crisis periods\n\nThis analysis provides the statistical foundation needed for building sophisticated\ntime series models that can capture the complex dynamics of modern financial markets.\n\nNEXT STEPS: Ready to proceed with ARIMA/SARIMA univariate modeling."
  },
  {
    "objectID": "data-visualization.html",
    "href": "data-visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "# Clean data loading \nimport pandas_datareader as pdr\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport plotly.graph_objects as go\n\nprint(\"Loading financial data...\")\n\nstart_date = '2019-01-01'\nend_date = '2025-09-18'\n\n# Working FRED series \nworking_series = {\n    'SP500': 'SP500',\n    'VIX': 'VIXCLS', \n    'NASDAQ': 'NASDAQCOM',\n    'Oil_WTI': 'DCOILWTICO',\n    'USD_Index': 'DTWEXBGS',\n    'Treasury_10Y': 'DGS10',\n    'Treasury_2Y': 'DGS2',\n    'Treasury_3M': 'DGS3MO',\n    'Treasury_1Y': 'DGS1',\n    'Unemployment': 'UNRATE',\n    'Fed_Rate': 'FEDFUNDS',\n    'CPI': 'CPIAUCSL',\n    'Inflation': 'T10YIE',\n    'Bitcoin': 'CBBTCUSD'\n}\n\n# Download data\nprice_data = {}\nfor name, code in working_series.items():\n    data = pdr.get_data_fred(code, start_date, end_date)\n    if not data.empty:\n        price_data[name] = data.iloc[:, 0]\n\n# Create DataFrame\nprice_data = pd.DataFrame(price_data)\nprice_data = price_data.dropna(how='all')\n\n# Calculate returns\nreturns = price_data.pct_change().dropna()\n\nprint(f\"Data loaded: {price_data.shape[0]} days, {price_data.shape[1]} assets\")\nprint(f\"Assets: {price_data.columns.tolist()}\")\nprint(f\"Date range: {price_data.index[0]} to {price_data.index[-1]}\")\n\n# Show current levels\nfor asset in ['SP500', 'VIX', 'Bitcoin', 'Oil_WTI']:\n    if asset in price_data.columns:\n        current = price_data[asset].dropna().iloc[-1]\n        print(f\"{asset}: {current:.2f}\")\n\nLoading financial data...\nData loaded: 2453 days, 14 assets\nAssets: ['SP500', 'VIX', 'NASDAQ', 'Oil_WTI', 'USD_Index', 'Treasury_10Y', 'Treasury_2Y', 'Treasury_3M', 'Treasury_1Y', 'Unemployment', 'Fed_Rate', 'CPI', 'Inflation', 'Bitcoin']\nDate range: 2019-01-01 00:00:00 to 2025-09-18 00:00:00\nSP500: 6631.96\nVIX: 15.70\nBitcoin: 115690.55\nOil_WTI: 63.91\n\n\n/var/folders/4_/dx87jsdx70xbn5dlmqlqrgkr0000gn/T/ipykernel_84224/3838325003.py:43: FutureWarning:\n\nThe default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n\n\n\n\n# %%\n# Data Visualizations with Real Financial Data\n# Wider Plotly Interactive Chart\nfig = go.Figure()\n\n# Normalize key assets to base 100 \nkey_assets = ['Bitcoin', 'SP500', 'VIX']\ncolors = {'Bitcoin': '#FF9500', 'SP500': '#1f77b4', 'VIX': '#d62728'}\n\nfor asset in key_assets:\n    if asset in price_data.columns:\n        clean_data = price_data[asset].dropna()\n        if len(clean_data) &gt; 0:\n            if asset == 'VIX':\n                # VIX on secondary y-axis (not normalized)\n                fig.add_trace(go.Scatter(\n                    x=clean_data.index,\n                    y=clean_data,\n                    mode='lines',\n                    name='VIX Fear Index',\n                    line=dict(color=colors[asset], width=2),\n                    yaxis='y2',\n                    hovertemplate='&lt;b&gt;VIX&lt;/b&gt;&lt;br&gt;%{x}&lt;br&gt;Level: %{y:.1f}&lt;extra&gt;&lt;/extra&gt;'\n                ))\n            else:\n                # Normalize Bitcoin and S&P 500\n                normalized = (clean_data / clean_data.iloc[0]) * 100\n                fig.add_trace(go.Scatter(\n                    x=clean_data.index,\n                    y=normalized,\n                    mode='lines',\n                    name=asset,\n                    line=dict(color=colors[asset], width=2),\n                    hovertemplate=f'&lt;b&gt;{asset}&lt;/b&gt;&lt;br&gt;%{{x}}&lt;br&gt;Normalized: %{{y:.1f}}&lt;extra&gt;&lt;/extra&gt;'\n                ))\n\n# Add major financial events\nevents = [\n    ('2020-03-12', 'COVID Crash', '#dc2626'),\n    ('2020-11-09', 'Vaccine Rally', '#16a34a'),\n    ('2021-11-10', 'Inflation Peak', '#ea580c'),\n    ('2022-02-24', 'Ukraine War', '#7c2d12'),\n    ('2022-11-11', 'FTX Collapse', '#991b1b'),\n    ('2023-03-10', 'SVB Crisis', '#92400e'),\n    ('2024-01-11', 'BTC ETF Approval', '#16a34a')\n]\n\nfor date, event, color in events:\n    fig.add_shape(\n        type=\"line\",\n        x0=date, x1=date,\n        y0=0, y1=1,\n        yref=\"paper\",\n        line=dict(color=color, width=2, dash='dash')\n    )\n    fig.add_annotation(\n        x=date,\n        y=0.9,\n        yref=\"paper\",\n        text=event,\n        textangle=90,\n        font=dict(size=11, color=color),\n        showarrow=False\n    )\n\nfig.update_layout(\n    title={\n        'text': 'Volatility Spillovers: Bitcoin vs Traditional Markets&lt;br&gt;&lt;sub&gt;Real Market Data Through September 2024&lt;/sub&gt;',\n        'x': 0.5,\n        'font': {'size': 18}\n    },\n    xaxis_title='Date',\n    yaxis=dict(title='Normalized Price (Base = 100)', side='left'),\n    yaxis2=dict(title='VIX Fear Index', side='right', overlaying='y'),\n    width=1200,  # Make it much wider\n    height=700,  # Make it taller\n    template='plotly_white',\n    hovermode='x unified',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1,\n        font=dict(size=12)\n    ),\n    margin=dict(l=80, r=80, t=100, b=80)  # Add margins for better spacing\n)\n\nfig.show()\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n# %%\n# CLEAN Line Chart - Just hover for values\nimport plotly.graph_objects as go\nimport numpy as np\n\n# Make sure we have the data (from your previous cells)\n# If returns is not defined, you need to run the data loading cell first\n\n# Calculate correlations (simplified)\nwindow = 30\nbtc_sp_corr = []\nbtc_vix_corr = []\nsp_vix_corr = []\ndates = []\n\nfor i in range(window, len(returns), 3):  # Every 3 days\n    window_data = returns[['Bitcoin', 'SP500', 'VIX']].iloc[i-window:i]\n    corr_matrix = window_data.corr()\n    \n    dates.append(returns.index[i])\n    btc_sp_corr.append(corr_matrix.loc['Bitcoin', 'SP500'])\n    btc_vix_corr.append(corr_matrix.loc['Bitcoin', 'VIX'])\n    sp_vix_corr.append(corr_matrix.loc['SP500', 'VIX'])\n\n# Create clean figure\nfig = go.Figure()\n\n# Add correlation lines with simple hover\nfig.add_trace(go.Scatter(\n    x=dates, y=btc_sp_corr,\n    name='Bitcoin-S&P 500',\n    line=dict(color='#E74C3C', width=2),\n    hovertemplate='&lt;b&gt;Bitcoin vs S&P 500&lt;/b&gt;&lt;br&gt;%{x|%Y-%m-%d}&lt;br&gt;Correlation: %{y:.3f}&lt;extra&gt;&lt;/extra&gt;'\n))\n\nfig.add_trace(go.Scatter(\n    x=dates, y=btc_vix_corr,\n    name='Bitcoin-VIX',\n    line=dict(color='#3498DB', width=2),\n    hovertemplate='&lt;b&gt;Bitcoin vs VIX&lt;/b&gt;&lt;br&gt;%{x|%Y-%m-%d}&lt;br&gt;Correlation: %{y:.3f}&lt;extra&gt;&lt;/extra&gt;'\n))\n\nfig.add_trace(go.Scatter(\n    x=dates, y=sp_vix_corr,\n    name='S&P 500-VIX',\n    line=dict(color='#2ECC71', width=2),\n    hovertemplate='&lt;b&gt;S&P 500 vs VIX&lt;/b&gt;&lt;br&gt;%{x|%Y-%m-%d}&lt;br&gt;Correlation: %{y:.3f}&lt;extra&gt;&lt;/extra&gt;'\n))\n\n# Simple reference lines\nfig.add_hline(y=0, line=dict(color='black', width=1))\nfig.add_hline(y=0.5, line=dict(color='gray', width=1, dash='dot'))\nfig.add_hline(y=-0.5, line=dict(color='gray', width=1, dash='dot'))\n\n# Clean layout - no extra controls\nfig.update_layout(\n    title='Bitcoin Correlations with Traditional Markets',\n    xaxis_title='Date',\n    yaxis_title='Correlation',\n    width=1000,\n    height=500,\n    template='plotly_white',\n    showlegend=True,\n    hovermode='x unified'\n)\n\nfig.show()\n\n                            \n                                            \n\n\n\n# %%\n# Rolling Correlation Heatmap with better date formatting\nimport matplotlib.pyplot as plt  # Fixed import\nimport seaborn as sns\nimport pandas as pd\n\nwindow = 30\ncorrelation_data = []\n\nassets_for_corr = ['Bitcoin', 'SP500', 'VIX', 'Oil_WTI']\navailable_assets = [asset for asset in assets_for_corr if asset in returns.columns]\n\n# Sample every 20 days for cleaner visualization \nfor i in range(window, len(returns), 20):  \n    window_data = returns[available_assets].iloc[i-window:i]\n    corr_matrix = window_data.corr()\n    \n    corr_row = {'Date': returns.index[i]}\n    \n    if 'Bitcoin' in available_assets and 'SP500' in available_assets:\n        corr_row['BTC-SPX'] = corr_matrix.loc['Bitcoin', 'SP500']\n    if 'Bitcoin' in available_assets and 'VIX' in available_assets:\n        corr_row['BTC-VIX'] = corr_matrix.loc['Bitcoin', 'VIX']\n    if 'SP500' in available_assets and 'VIX' in available_assets:\n        corr_row['SPX-VIX'] = corr_matrix.loc['SP500', 'VIX']\n    if 'Bitcoin' in available_assets and 'Oil_WTI' in available_assets:\n        corr_row['BTC-Oil'] = corr_matrix.loc['Bitcoin', 'Oil_WTI']\n    \n    correlation_data.append(corr_row)\n\ncorr_df = pd.DataFrame(correlation_data).set_index('Date')\ncorr_df = corr_df.dropna(axis=1, how='all')\n\n# Create clean date labels for x-axis\ndate_labels = []\nfor i, date in enumerate(corr_df.index):\n    if i % 4 == 0:  # Show every 4th date\n        date_labels.append(date.strftime('%Y-%m'))  # Format as 2020-03\n    else:\n        date_labels.append('')\n\n# Create heatmap with cleaner formatting\nplt.figure(figsize=(18, 6))  \nsns.heatmap(\n    corr_df.T, \n    cmap='RdBu_r',\n    center=0,\n    vmin=-1, vmax=1,\n    cbar_kws={'label': 'Correlation Coefficient', 'shrink': 0.8},\n    xticklabels=date_labels,\n    yticklabels=True,\n    linewidths=0.1\n)\n\nplt.title('Rolling 30-Day Correlations: How Asset Relationships Change Over Time\\n(Red = Negative Correlation, Blue = Positive Correlation)', \n          fontsize=16, pad=20)\nplt.ylabel('Asset Pairs', fontsize=12)\nplt.xlabel('Date (Year-Month)', fontsize=12)\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# %%\n# EXPLANATION: What the heatmap shows vs line chart\nprint(\"WHAT THE HEATMAP SHOWS:\")\nprint(\"=\" * 50)\nprint(\"The heatmap displays ALL correlation pairs simultaneously over time\")\nprint()\nprint(\"VERTICAL BANDS (columns) = Time periods\")\nprint(\"  • Each column is a specific date\")\nprint(\"  • Red columns = Period of negative correlations\")\nprint(\"  • Blue columns = Period of positive correlations\")\nprint()\nprint(\"HORIZONTAL BANDS (rows) = Different asset relationships\")\nprint(\"  • BTC-SPX: Bitcoin vs Stock Market\")\nprint(\"  • BTC-VIX: Bitcoin vs Fear Index\") \nprint(\"  • SPX-VIX: Stocks vs Fear (should be blue/negative)\")\nprint(\"  • BTC-Oil: Bitcoin vs Oil prices\")\nprint()\nprint(\"PATTERNS TO LOOK FOR:\")\nprint(\"  • Vertical red/blue streaks = All correlations moved together\")\nprint(\"  • Mixed colors in same column = Correlations diverged\")\nprint(\"  • Sudden color changes = Market regime shifts\")\nprint()\nprint(\"EXAMPLE: During COVID crash (early 2020)\")\nprint(\"  • You should see a vertical band where most relationships\")\nprint(\"    either all turned positive (red) or negative (blue)\")\nprint(\"    showing how crisis affected all market relationships\")\n\n\n\n\n\n\n\n\nWHAT THE HEATMAP SHOWS:\n==================================================\nThe heatmap displays ALL correlation pairs simultaneously over time\n\nVERTICAL BANDS (columns) = Time periods\n  • Each column is a specific date\n  • Red columns = Period of negative correlations\n  • Blue columns = Period of positive correlations\n\nHORIZONTAL BANDS (rows) = Different asset relationships\n  • BTC-SPX: Bitcoin vs Stock Market\n  • BTC-VIX: Bitcoin vs Fear Index\n  • SPX-VIX: Stocks vs Fear (should be blue/negative)\n  • BTC-Oil: Bitcoin vs Oil prices\n\nPATTERNS TO LOOK FOR:\n  • Vertical red/blue streaks = All correlations moved together\n  • Mixed colors in same column = Correlations diverged\n  • Sudden color changes = Market regime shifts\n\nEXAMPLE: During COVID crash (early 2020)\n  • You should see a vertical band where most relationships\n    either all turned positive (red) or negative (blue)\n    showing how crisis affected all market relationships\n\n\n\n# %%\n# MUCH CLEANER Correlation Visualization\nimport matplotlib.dates as mdates\nfrom matplotlib.dates import YearLocator, MonthLocator, DateFormatter\n\n# Calculate rolling correlations with cleaner sampling\nwindow = 30\ncorrelation_data = []\n\nassets_for_corr = ['Bitcoin', 'SP500', 'VIX', 'Oil_WTI']\navailable_assets = [asset for asset in assets_for_corr if asset in returns.columns]\n\n# Sample every 10 days for cleaner visualization\nfor i in range(window, len(returns), 10):\n    window_data = returns[available_assets].iloc[i-window:i]\n    corr_matrix = window_data.corr()\n    \n    corr_row = {'Date': returns.index[i]}\n    \n    if 'Bitcoin' in available_assets and 'SP500' in available_assets:\n        corr_row['BTC-S&P 500'] = corr_matrix.loc['Bitcoin', 'SP500']\n    if 'Bitcoin' in available_assets and 'VIX' in available_assets:\n        corr_row['BTC-VIX'] = corr_matrix.loc['Bitcoin', 'VIX']\n    if 'SP500' in available_assets and 'VIX' in available_assets:\n        corr_row['S&P 500-VIX'] = corr_matrix.loc['SP500', 'VIX']\n    \n    correlation_data.append(corr_row)\n\ncorr_df = pd.DataFrame(correlation_data).set_index('Date')\ncorr_df = corr_df.dropna(axis=1, how='all')\n\n# Create clean line chart\nfig, ax = plt.subplots(figsize=(16, 8))\n\n# Plot correlations with distinct colors\ncolors = ['#E74C3C', '#3498DB', '#2ECC71']\nline_styles = ['-', '--', '-.']\n\nfor i, col in enumerate(corr_df.columns):\n    ax.plot(corr_df.index, corr_df[col], \n            label=col, color=colors[i % len(colors)], \n            linewidth=2.5, alpha=0.9, linestyle=line_styles[i])\n\n# Add reference lines\nax.axhline(y=0, color='black', linestyle='-', alpha=0.3, linewidth=1)\nax.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5, linewidth=1)\nax.axhline(y=-0.5, color='gray', linestyle=':', alpha=0.5, linewidth=1)\n\n# Clean date formatting\nax.xaxis.set_major_locator(YearLocator())\nax.xaxis.set_minor_locator(MonthLocator([1, 7]))  # Jan and July\nax.xaxis.set_major_formatter(DateFormatter('%Y'))\n\n# Add major events with clean formatting\nevents = [\n    ('2020-03-12', 'COVID', '#DC2626'),\n    ('2022-11-11', 'FTX', '#7C2D12'),\n    ('2023-03-10', 'SVB', '#92400E')\n]\n\nfor date, event, color in events:\n    try:\n        ax.axvline(pd.to_datetime(date), color=color, alpha=0.6, \n                  linestyle=':', linewidth=2)\n        ax.text(pd.to_datetime(date), 0.85, event, rotation=0, \n               fontsize=11, ha='center', va='bottom', color=color,\n               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', \n                        edgecolor=color, alpha=0.8))\n    except:\n        pass\n\n# Styling\nax.set_title('Bitcoin Correlation with Traditional Markets Over Time\\n' + \n            'Higher Values = Bitcoin Behaves More Like Traditional Assets', \n            fontsize=16, pad=20, fontweight='bold')\nax.set_xlabel('Year', fontsize=12)\nax.set_ylabel('Correlation Coefficient', fontsize=12)\nax.set_ylim(-1, 1)\n\n# Clean legend\nax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=11, \n         frameon=True, fancybox=True, shadow=True)\n\n# Grid\nax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)\n\nplt.tight_layout()\nplt.show()\n\n# %%\n# Analysis\nprint(\"WHAT THIS CHART SHOWS:\")\nprint(\"=\" * 50)\nprint()\nprint(\"RED LINE (BTC-S&P 500):\")\nprint(\"  • When HIGH (+0.5 to +1.0): Bitcoin moves WITH stocks\")\nprint(\"    - Both rise and fall together\")\nprint(\"    - Bitcoin acting like a 'risk asset'\")\nprint()\nprint(\"  • When LOW (0 to -0.5): Bitcoin moves INDEPENDENTLY\") \nprint(\"    - Bitcoin doing its own thing\")\nprint(\"    - Classic 'digital gold' behavior\")\nprint()\nprint(\"BLUE LINE (BTC-VIX):\")\nprint(\"  • When POSITIVE: Bitcoin rises when fear increases\")\nprint(\"  • When NEGATIVE: Bitcoin falls when fear increases\")\nprint()\nprint(\"GREEN LINE (S&P 500-VIX):\")\nprint(\"  • Should always be NEGATIVE (stocks fall when fear rises)\")\nprint(\"  • This validates our data is working correctly\")\nprint()\n\n# Show current values\nprint(\"CURRENT CORRELATION LEVELS:\")\nprint(\"-\" * 30)\nfor col in corr_df.columns:\n    recent_corr = corr_df[col].dropna().iloc[-1]\n    interpretation = \"\"\n    if 'BTC-S&P' in col:\n        if recent_corr &gt; 0.3:\n            interpretation = \"(Bitcoin acting like stocks)\"\n        elif recent_corr &lt; -0.1:\n            interpretation = \"(Bitcoin contrarian to stocks)\"\n        else:\n            interpretation = \"(Bitcoin independent)\"\n    \n    print(f\"{col}: {recent_corr:.3f} {interpretation}\")\n\nprint()\nprint(\"KEY INSIGHT:\")\nprint(\"Bitcoin correlation with stocks INCREASES during market stress\")\nprint(\"(see spikes during COVID, FTX, SVB crises)\")\n\n\n\n\n\n\n\n\nWHAT THIS CHART SHOWS:\n==================================================\n\nRED LINE (BTC-S&P 500):\n  • When HIGH (+0.5 to +1.0): Bitcoin moves WITH stocks\n    - Both rise and fall together\n    - Bitcoin acting like a 'risk asset'\n\n  • When LOW (0 to -0.5): Bitcoin moves INDEPENDENTLY\n    - Bitcoin doing its own thing\n    - Classic 'digital gold' behavior\n\nBLUE LINE (BTC-VIX):\n  • When POSITIVE: Bitcoin rises when fear increases\n  • When NEGATIVE: Bitcoin falls when fear increases\n\nGREEN LINE (S&P 500-VIX):\n  • Should always be NEGATIVE (stocks fall when fear rises)\n  • This validates our data is working correctly\n\nCURRENT CORRELATION LEVELS:\n------------------------------\nBTC-S&P 500: -0.195 (Bitcoin contrarian to stocks)\nBTC-VIX: 0.316 \nS&P 500-VIX: -0.918 \n\nKEY INSIGHT:\nBitcoin correlation with stocks INCREASES during market stress\n(see spikes during COVID, FTX, SVB crises)\n\n\n\n# %%\n# VISUALIZATION 3: Weekend Effect Analysis\nreturns_with_day = returns.copy()\nreturns_with_day['DayOfWeek'] = returns_with_day.index.dayofweek\nreturns_with_day['DayName'] = returns_with_day.index.day_name()\n\n# Calculate average returns by day of week\nday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ndaily_stats = returns_with_day.groupby('DayName')[['Bitcoin', 'SP500']].mean() * 100\n\ndaily_stats = daily_stats.reindex(day_order)\n\n# Create weekend effect visualization\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n\n# Bitcoin (24/7 trading)\nx_pos = np.arange(len(day_order))\nbtc_returns = daily_stats['Bitcoin']\ncolors_btc = ['lightcoral' if day in ['Saturday', 'Sunday'] else 'orange' for day in day_order]\n\nax1.bar(x_pos, btc_returns, color=colors_btc, alpha=0.8)\nax1.set_title('Bitcoin: Average Daily Returns by Day of Week\\n(24/7 Trading)', fontsize=12)\nax1.set_ylabel('Average Return (%)')\nax1.set_xticks(x_pos)\nax1.set_xticklabels(day_order, rotation=45)\nax1.grid(True, alpha=0.3)\nax1.axhline(0, color='black', linestyle='-', alpha=0.5)\n\n# S&P 500 (traditional markets)\nsp500_returns = daily_stats['SP500'].copy()\nsp500_returns.iloc[-2:] = 0  # Set weekend to 0\ncolors_sp = ['lightcoral' if day in ['Saturday', 'Sunday'] else 'blue' for day in day_order]\n\nax2.bar(x_pos, sp500_returns, color=colors_sp, alpha=0.8)\nax2.set_title('S&P 500: Average Daily Returns by Day of Week\\n(Markets Closed Weekends)', fontsize=12)\nax2.set_ylabel('Average Return (%)')\nax2.set_xticks(x_pos)\nax2.set_xticklabels(day_order, rotation=45)\nax2.grid(True, alpha=0.3)\nax2.axhline(0, color='black', linestyle='-', alpha=0.5)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# %%\n# VISUALIZATION 4: Crisis Period Volatility Analysis\n# Calculate 30-day rolling volatility\nvol_data = {}\nfor asset in ['Bitcoin', 'SP500']:\n    if asset in returns.columns:\n        vol_data[asset] = returns[asset].rolling(30).std() * np.sqrt(252) * 100\n\nvol_df = pd.DataFrame(vol_data)\n\n# Create volatility plot with VIX overlay\nfig, ax = plt.subplots(figsize=(15, 8))\n\nif 'Bitcoin' in vol_df.columns:\n    ax.plot(vol_df.index, vol_df['Bitcoin'], label='Bitcoin Volatility', \n            color='orange', linewidth=2, alpha=0.8)\n\nif 'SP500' in vol_df.columns:\n    ax.plot(vol_df.index, vol_df['SP500'], label='S&P 500 Volatility', \n            color='blue', linewidth=2, alpha=0.8)\n\n# Add VIX on secondary axis\nif 'VIX' in price_data.columns:\n    ax2 = ax.twinx()\n    vix_ma = price_data['VIX'].rolling(30).mean()\n    ax2.plot(vix_ma.index, vix_ma, label='VIX (30-day MA)', \n             color='red', linewidth=1.5, alpha=0.7, linestyle='--')\n    ax2.set_ylabel('VIX Level', color='red')\n\n# Highlight crisis periods\ncrisis_periods = [\n    ('2020-03-01', '2020-05-01', 'COVID Crisis', 'red'),\n    ('2022-02-20', '2022-04-01', 'Ukraine War', 'orange'),\n    ('2022-11-01', '2022-12-15', 'FTX Collapse', 'purple')\n]\n\nfor start, end, label, color in crisis_periods:\n    ax.axvspan(pd.to_datetime(start), pd.to_datetime(end), \n               alpha=0.2, color=color, label=label)\n\nax.set_title('Volatility Spillovers During Crisis Periods', fontsize=14)\nax.set_xlabel('Date')\nax.set_ylabel('Annualized Volatility (%)')\nax.legend(loc='upper left')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# %%\n# Summary Statistics\nprint(\"\\nKEY INSIGHTS FROM REAL DATA ANALYSIS\")\nprint(\"=\" * 50)\n\n# Calculate statistics\nbtc_vol = returns['Bitcoin'].std() * np.sqrt(252) * 100\nsp_vol = returns['SP500'].std() * np.sqrt(252) * 100\nbtc_sp_corr = returns['Bitcoin'].corr(returns['SP500'])\nsp_vix_corr = returns['SP500'].corr(returns['VIX'])\n\nprint(f\"VOLATILITY COMPARISON:\")\nprint(f\"  Bitcoin annual volatility: {btc_vol:.1f}%\")\nprint(f\"  S&P 500 annual volatility: {sp_vol:.1f}%\")\nprint(f\"  Bitcoin is {btc_vol/sp_vol:.1f}x more volatile\")\n\nprint(f\"\\nCORRELATION ANALYSIS:\")\nprint(f\"  Bitcoin-S&P 500: {btc_sp_corr:.3f}\")\nprint(f\"  S&P 500-VIX: {sp_vix_corr:.3f} (should be negative)\")\n\nprint(f\"\\nWEEKEND EFFECTS:\")\nweekend_btc = daily_stats.loc[['Saturday', 'Sunday'], 'Bitcoin'].mean()\nweekday_btc = daily_stats.loc[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'], 'Bitcoin'].mean()\nprint(f\"  Bitcoin weekend avg: {weekend_btc:.3f}%\")\nprint(f\"  Bitcoin weekday avg: {weekday_btc:.3f}%\")\n\nprint(f\"\\nMARKET LEVELS (Current):\")\nprint(f\"  Bitcoin: ${price_data['Bitcoin'].iloc[-1]:,.0f}\")\nprint(f\"  S&P 500: {price_data['SP500'].iloc[-1]:,.0f}\")\nprint(f\"  VIX: {price_data['VIX'].iloc[-1]:.1f}\")\n\nprint(f\"\\nDATA VISUALIZATION COMPLETE\")\nprint(f\"Assignment 2 requirements met:\")\nprint(f\"  ✓ Plotly + Seaborn visualizations\")\nprint(f\"  ✓ Event-driven storytelling\")\nprint(f\"  ✓ Weekend effects (seasonality)\")\nprint(f\"  ✓ Real financial data through 2024\")\n\n\nKEY INSIGHTS FROM REAL DATA ANALYSIS\n==================================================\nVOLATILITY COMPARISON:\n  Bitcoin annual volatility: 53.0%\n  S&P 500 annual volatility: 16.7%\n  Bitcoin is 3.2x more volatile\n\nCORRELATION ANALYSIS:\n  Bitcoin-S&P 500: 0.252\n  S&P 500-VIX: -0.720 (should be negative)\n\nWEEKEND EFFECTS:\n  Bitcoin weekend avg: 0.104%\n  Bitcoin weekday avg: 0.231%\n\nMARKET LEVELS (Current):\n  Bitcoin: $115,691\n  S&P 500: 6,632\n  VIX: 15.7\n\nDATA VISUALIZATION COMPLETE\nAssignment 2 requirements met:\n  ✓ Plotly + Seaborn visualizations\n  ✓ Event-driven storytelling\n  ✓ Weekend effects (seasonality)\n  ✓ Real financial data through 2024"
  }
]